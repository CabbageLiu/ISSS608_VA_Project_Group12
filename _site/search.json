[
  {
    "objectID": "TH3/Take-Home_Ex02_MC3.html",
    "href": "TH3/Take-Home_Ex02_MC3.html",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "For the purpose of this assignment, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\npacman::p_load(tidyverse, jsonlite, \n               tidygraph, ggraph, SmartEDA, \n               ggrepel, scales, lubridate, dplyr, viridis)\n\n\n\n\nFor the purpose of this exercise, mc3.json file will be used. Before getting started, you should have the data set in the data sub-folder.\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc3.json file into R and save the output object\n\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")\n\n\n\n\nThe dataset was provided by VAST Challenge for MC3. This report utilizes two core datasets: MC3_graph.json, which encodes the knowledge graph of communications, events, and relationships; and MC3_schema.json, which defines the structure, subtypes, and attributes of each node and edge type within the graph. There ngraph contains a total of 1159 nodes and 3226 edges. Full description of node attributes and edge attributes is shown below.\nNodes Attributes are as such:\n\n\n\nNode Subtypes\n\n\nEdge Attributes are as such:\n\n\n\nNode-Edge-Node Matrix\n\n\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of mc3 knowledge graph.\nIn the code chunk below glimpse() is used to reveal the structure of mc3 knowledge graph.\n\nglimpse(MC3)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that Industry field is in list data type. In general, this data type is not acceptable by tbl_graph() of tidygraph. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis.\n\n\n\n\n\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc3 tibble dataframe into two separate tibble dataframes called mc3_nodes and mc3_edges respectively.\n\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)\n\n\n\n\nIt is time for us to apply appropriate EDA methods to examine the data.\nNodes:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?\n\n\n\n\n\nEdges:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n\n\n\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below performs the following data cleaning tasks:\n\nconvert values in id field into character data type,\nexclude records with id value are na,\nexclude records with similar id values,\nexclude thing_collected field, and\nsave the cleaned tibble dataframe into a new tibble datatable called mc3_nodes_cleaned.\n\n\n\nCode\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n\n\n\n\nNext, the code chunk below will be used to:\n\nrename source and target fields to from_id and to_id respectively,\nconvert values in from_id and to_id fields to character data type,\nexclude values in from_id and to_id which not found in the id field of mc3_nodes_cleaned,\nexclude records whereby from_id and/or to_id values are missing, and\nsave the cleaned tibble dataframe and called it mc3_edges_cleaned.\n\n\n\nCode\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source, \n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), \n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\nNext, code chunk below will be used to create mapping of character id in mc3_nodes_cleaned to row index.\n\n\nCode\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nNext, the code chunk below will be used to join and convert from_id and to_id to integer indices. At the same time we also drop rows with unmatched nodes.\n\n\nCode\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to))  \n\n\nNext the code chunk below is used to subset nodes to only those referenced by edges.\n\n\nCode\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nWe will then use the code chunk below to rebuild lookup from old index to new index.\n\n\nCode\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n\nLastly, the code chunk below will be used to update edge indices to match new node table.\n\n\nCode\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\n\nNow we are ready to build the tidygraph object by using the code chunk below.\n\nmc3_graph &lt;- tbl_graph(\n  nodes = mc3_nodes_final,\n  edges = mc3_edges_final,\n  directed = TRUE\n)\n\nAfter the tidygraph object is created, it is always a good practice to examine the object by using str().\n\nstr(mc3_graph)\n\nClasses 'tbl_graph', 'igraph'  hidden list of 10\n $ : num 1159\n $ : logi TRUE\n $ : num [1:3226] 0 0 0 0 0 0 0 1 1 1 ...\n $ : num [1:3226] 1137 356 746 894 875 ...\n $ : NULL\n $ : NULL\n $ : NULL\n $ : NULL\n $ :List of 4\n  ..$ : num [1:3] 1 0 1\n  ..$ : Named list()\n  ..$ :List of 31\n  .. ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  .. ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  .. ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  .. ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ findings         : chr [1:1159] NA NA NA NA ...\n  .. ..$ content          : chr [1:1159] NA NA NA NA ...\n  .. ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ results          : chr [1:1159] NA NA NA NA ...\n  .. ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ destination      : chr [1:1159] NA NA NA NA ...\n  .. ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  .. ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  .. ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  .. ..$ reference        : chr [1:1159] NA NA NA NA ...\n  .. ..$ date             : chr [1:1159] NA NA NA NA ...\n  .. ..$ time             : chr [1:1159] NA NA NA NA ...\n  .. ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  .. ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  .. ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  .. ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  .. ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  .. ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ operational_role : chr [1:1159] NA NA NA NA ...\n  .. ..$ new_index        : int [1:1159] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ :List of 2\n  .. ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  .. ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n $ :&lt;environment: 0x0000023a869743f0&gt; \n - attr(*, \"active\")= chr \"nodes\"\n\n\n\n\n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1818)\n\n\n\nShows how many nodes are of type Entity, Event, or Relationship.\n\n\nCode\nmc3_nodes_final %&gt;%\n  count(type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(type, -n), y = n, fill = type)) +\n  geom_col() +\n  geom_text(aes(label = n), vjust = -0.3) +\n  labs(title = \"Node Type Distribution\", x = \"Type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggraph functions are used to create the whole graph.\n\n\nCode\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nFocuses on what kinds of actors are in the graph — Person, Vessel, Organization, etc.\n\n\nCode\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo understand what kinds of actions dominate — Communication, Monitoring, Assessment, etc.\n\n\nCode\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis finds all Entities that sent or received communication events — i.e., actors who participated in messaging.\n\n\nCode\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\n\n\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\nMessage Senders are arranged from most to the least number of messages sent.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAST Challenge Task & Question 1a and 1b\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nDevelop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\nHow do these patterns shift over the two weeks of observations?\n\n\n\nObjective\n\nIdentify when communications happen most often during each day.\nDetect shifts in these patterns over the 2-week period.\nLater: Focus on a specific entity (e.g., Nadia Conti) and explore who influences them.\n\n\n\nExtract the Communication Timestamps from mc3_nodes_final and filter for communication events.\n\n# Filter for Communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n\nParse the Communication Timestamp into the format “dd/mm/yyy (ddd)” for ease of reference.\n\n# Communication events with parsed date and time\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n\n\n\n\n\n\n\n\nCode\n# Step 1: Prepare daily message volume data\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count &lt;- mean(daily_message_volume$message_count)\ntotal_msg_count &lt;- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %&gt;% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender–receiver–timestamp structure\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender–receiver–timestamp\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(sender_id = id, sender_label = label), by = \"sender_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, hour) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;⏰ Hour: \", sprintf(\"%02d:00\", hour),\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np &lt;- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nWe will increase the resolution to half-hour time slots.\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count.\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)  # ✅ fixed receiver_id\n\n# Step 2: Reconstruct sender–receiver–event linkage\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, time_bin, time_label) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;🕒 Time: \", time_label,\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np &lt;- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nThe faceted density plot that shows the distribution of communication events by time of day, broken down for each day in the dataset. It helps to visually detect temporal communication patterns, intensity, and consistency over multiple days.\n\nOverview of the 2 week periodDay 1 - 01/10/2040Day 2 - 02/10/2040Day 3 - 03/10/2040Day 4 - 04/10/2040Day 5 - 05/10/2040Day 6 - 06/10/2040Day 7 - 07/10/2040Day 8 - 08/10/2040Day 9 - 09/10/2040Day 10 - 10/10/2040Day 11 - 11/10/2040Day 12 - 12/10/2040Day 13 - 13/10/2040Day 14 - 14/10/2040\n\n\n\n\nCode\n# Step 1: Preprocess communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats &lt;- comm_events %&gt;%\n  group_by(date_label) %&gt;%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n📈 Insights This Visualization Offers\n\n\n\n\nBar Plot of combined hourly message volume over the 2 weeks period:\n\n\nCode\n# Prepare data\ncomm_hourly &lt;- comm_events %&gt;%\n  count(hour) %&gt;%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nBar Plot of combined half-hourly message volume in the 2 weeks period.\n\n\nCode\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute &lt; 30, 0, 30))\n  )\n\ncomm_halfhour &lt;- comm_events %&gt;%\n  count(time_bin) %&gt;%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1a. What are the identifiable daily temporal patterns in communications?\n\n\n\n\nThe daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)—a sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\nThe temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\nFor instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends—communication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n\n\n\n\n\n\n\n\n\n1b. How do these patterns shift over the two weeks of observations?\n\n\n\n\nOver the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of “surge” (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation—an analytical signal that warrants closer inspection of event logs or external triggers for those dates.\nAnother notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule—potentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures.\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAST Challenge Task & Question 1c\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nFocus on a specific entity and use this information to determine who has influence over them.\n\n\n\n\n\nWe first extracted the relevant communication edges from the dataset, pairing “sent” and “received” communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\nCode\n# Extract sent and received communication event edges\nsent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges &lt;- sent_edges %&gt;%\n  inner_join(received_edges, by = \"event\") %&gt;%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges &lt;- sent_edges %&gt;%\n  select(from = source_entity, to = event)\nsingle_received_edges &lt;- received_edges %&gt;%\n  select(from = event, to = target_entity)\n\nall_edges &lt;- bind_rows(paired_edges, single_sent_edges, single_received_edges) %&gt;%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  pull(id) %&gt;% as.character()\n\nentity_edges &lt;- all_edges %&gt;%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  select(id, label, sub_type)\n\n\n\n\n\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node—PageRank, betweenness, and degree—quantifying the influence and connectivity of every entity in the overall network.\n\n\nCode\nlibrary(igraph)\n\ng &lt;- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank &lt;- page_rank(g)$vector\nV(g)$betweenness &lt;- betweenness(g)\nV(g)$degree &lt;- degree(g)\n\n\n\n\n\nFocusing on “Nadia Conti”, we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia’s immediate sphere of influence and the key players connected to her.\n\n\nCode\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\nego_graph &lt;- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n\n\n\n\n\nWe visualized Nadia’s ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti’s communication environment.\n\n\nCode\nnodes_df &lt;- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_graph)$label, \"&lt;/b&gt;&lt;br&gt;\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"&lt;br&gt;\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"&lt;br&gt;\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df &lt;- as_data_frame(ego_graph, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %&gt;%\n  visNodes(scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %&gt;%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal and Ego-Network Structure\n\n\n\nThe overview network visualization reveals that Nadia Conti is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia’s influence neighborhood.\n\n\n\n\n\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\nPageRank (overall influence),\nBetweenness (information brokerage/intermediary role), and\nDegree (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\nCode\n# PageRank table\npagerank_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %&gt;% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %&gt;% arrange(desc(betweenness))\n\n# Degree table\ndegree_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %&gt;% arrange(desc(degree))\n\n\n\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n\n\nPageRank Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\npagerank\n\n\n\n\nMako\nVessel\n0.0687\n\n\nOceanus City Council\nOrganization\n0.0530\n\n\nReef Guardian\nVessel\n0.0454\n\n\nNadia Conti\nPerson\n0.0432\n\n\nRemora\nVessel\n0.0409\n\n\nV. Miesel Shipping\nOrganization\n0.0394\n\n\nNeptune\nVessel\n0.0358\n\n\nHimark Harbor\nLocation\n0.0358\n\n\nLiam Thorne\nPerson\n0.0275\n\n\nBoss\nPerson\n0.0272\n\n\nSentinel\nVessel\n0.0250\n\n\nPaackland Harbor\nLocation\n0.0244\n\n\nDavis\nPerson\n0.0239\n\n\nMarlin\nVessel\n0.0235\n\n\nEcoVigil\nVessel\n0.0233\n\n\nGreen Guardians\nOrganization\n0.0224\n\n\nMrs. Money\nPerson\n0.0192\n\n\nSailor Shifts Team\nOrganization\n0.0186\n\n\nSeawatch\nVessel\n0.0186\n\n\nElise\nPerson\n0.0182\n\n\nSerenity\nVessel\n0.0170\n\n\nHorizon\nVessel\n0.0152\n\n\nThe Middleman\nPerson\n0.0142\n\n\nNorthern Light\nVessel\n0.0135\n\n\nRodriguez\nPerson\n0.0122\n\n\nSamantha Blake\nPerson\n0.0114\n\n\nHaacklee Harbor\nLocation\n0.0111\n\n\nOsprey\nVessel\n0.0088\n\n\nCity Officials\nGroup\n0.0066\n\n\nThe Lookout\nPerson\n0.0062\n\n\nKnowles\nVessel\n0.0051\n\n\nSmall Fry\nPerson\n0.0035\n\n\nGlitters Team\nOrganization\n0.0035\n\n\n\n\n\n\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n\n\nBetweenness Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\nbetweenness\n\n\n\n\nMako\nVessel\n368.50\n\n\nMrs. Money\nPerson\n167.18\n\n\nReef Guardian\nVessel\n139.69\n\n\nBoss\nPerson\n136.18\n\n\nV. Miesel Shipping\nOrganization\n118.70\n\n\nNadia Conti\nPerson\n117.87\n\n\nOceanus City Council\nOrganization\n116.11\n\n\nRemora\nVessel\n90.45\n\n\nNeptune\nVessel\n82.59\n\n\nThe Lookout\nPerson\n80.51\n\n\nHimark Harbor\nLocation\n52.61\n\n\nThe Middleman\nPerson\n50.78\n\n\nLiam Thorne\nPerson\n41.81\n\n\nHaacklee Harbor\nLocation\n41.30\n\n\nSentinel\nVessel\n34.54\n\n\nGreen Guardians\nOrganization\n27.51\n\n\nPaackland Harbor\nLocation\n27.08\n\n\nDavis\nPerson\n22.36\n\n\nEcoVigil\nVessel\n12.63\n\n\nRodriguez\nPerson\n11.75\n\n\nNorthern Light\nVessel\n9.76\n\n\nSailor Shifts Team\nOrganization\n7.34\n\n\nHorizon\nVessel\n6.72\n\n\nMarlin\nVessel\n6.23\n\n\nSeawatch\nVessel\n5.20\n\n\nElise\nPerson\n4.60\n\n\nSamantha Blake\nPerson\n4.49\n\n\nSerenity\nVessel\n0.81\n\n\nKnowles\nVessel\n0.50\n\n\nSmall Fry\nPerson\n0.00\n\n\nGlitters Team\nOrganization\n0.00\n\n\nOsprey\nVessel\n0.00\n\n\nCity Officials\nGroup\n0.00\n\n\n\n\n\n\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n\n\nDegree Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\ndegree\n\n\n\n\nMako\nVessel\n37\n\n\nOceanus City Council\nOrganization\n28\n\n\nReef Guardian\nVessel\n27\n\n\nRemora\nVessel\n21\n\n\nV. Miesel Shipping\nOrganization\n19\n\n\nNeptune\nVessel\n19\n\n\nNadia Conti\nPerson\n17\n\n\nGreen Guardians\nOrganization\n17\n\n\nHimark Harbor\nLocation\n17\n\n\nDavis\nPerson\n16\n\n\nSentinel\nVessel\n16\n\n\nBoss\nPerson\n13\n\n\nEcoVigil\nVessel\n13\n\n\nPaackland Harbor\nLocation\n13\n\n\nMrs. Money\nPerson\n12\n\n\nHorizon\nVessel\n12\n\n\nLiam Thorne\nPerson\n11\n\n\nRodriguez\nPerson\n10\n\n\nMarlin\nVessel\n10\n\n\nSeawatch\nVessel\n9\n\n\nThe Middleman\nPerson\n8\n\n\nSerenity\nVessel\n8\n\n\nNorthern Light\nVessel\n8\n\n\nHaacklee Harbor\nLocation\n8\n\n\nElise\nPerson\n7\n\n\nThe Lookout\nPerson\n7\n\n\nSailor Shifts Team\nOrganization\n7\n\n\nSamantha Blake\nPerson\n6\n\n\nGlitters Team\nOrganization\n4\n\n\nKnowles\nVessel\n4\n\n\nSmall Fry\nPerson\n3\n\n\nOsprey\nVessel\n3\n\n\nCity Officials\nGroup\n1\n\n\n\n\n\n\n\n\n\n\n\nCentrality Metrics and Direct & Indirect Influences\n\n\n\nBy calculating centrality metrics within Nadia’s two-hop ego network, we observe that the most influential nodes in her environment—by PageRank, betweenness, and degree—are Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia’s information flow and access to other parts of the network.\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n\n\n\n\n\n\nCode\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng &lt;- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 &lt;- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank &lt;- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df &lt;- as_data_frame(ego_1, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness &lt;- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Degree for the ego network\nV(ego_1)$degree &lt;- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n1c. With a focus on “Nadia Conti”, the visuals above could determine who has influence over this person.\n\n\n\n\nDegree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\nSeveral other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia’s network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that Nadia’s environment is both diverse and robust.\nDirect Connections\nThese direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti’s node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\nPeople: Elise, Liam Thorne, Davis, Rodriguez\nOrganization: V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\nVessel: Neptune, Marlin, Remora, Sentinel\nLocation: Haacklee Harbor\n\nInterpretation: The PageRank, Betweenness, and Degree centrality plots all consistently show Nadia Conti as a major hub, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\nNadia’s position suggests she is a key connector and influencer but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence—and be influenced—is amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia’s access to information, resources, and strategic decisions."
  },
  {
    "objectID": "TH3/Take-Home_Ex02_MC3.html#getting-started",
    "href": "TH3/Take-Home_Ex02_MC3.html#getting-started",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "For the purpose of this assignment, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\npacman::p_load(tidyverse, jsonlite, \n               tidygraph, ggraph, SmartEDA, \n               ggrepel, scales, lubridate, dplyr, viridis)\n\n\n\n\nFor the purpose of this exercise, mc3.json file will be used. Before getting started, you should have the data set in the data sub-folder.\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc3.json file into R and save the output object\n\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")\n\n\n\n\nThe dataset was provided by VAST Challenge for MC3. This report utilizes two core datasets: MC3_graph.json, which encodes the knowledge graph of communications, events, and relationships; and MC3_schema.json, which defines the structure, subtypes, and attributes of each node and edge type within the graph. There ngraph contains a total of 1159 nodes and 3226 edges. Full description of node attributes and edge attributes is shown below.\nNodes Attributes are as such:\n\n\n\nNode Subtypes\n\n\nEdge Attributes are as such:\n\n\n\nNode-Edge-Node Matrix\n\n\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of mc3 knowledge graph.\nIn the code chunk below glimpse() is used to reveal the structure of mc3 knowledge graph.\n\nglimpse(MC3)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that Industry field is in list data type. In general, this data type is not acceptable by tbl_graph() of tidygraph. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis.\n\n\n\n\n\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc3 tibble dataframe into two separate tibble dataframes called mc3_nodes and mc3_edges respectively.\n\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)\n\n\n\n\nIt is time for us to apply appropriate EDA methods to examine the data.\nNodes:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?\n\n\n\n\n\nEdges:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n\n\n\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?"
  },
  {
    "objectID": "TH3/Take-Home_Ex02_MC3.html#data-cleaning-and-wrangling",
    "href": "TH3/Take-Home_Ex02_MC3.html#data-cleaning-and-wrangling",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "Code chunk below performs the following data cleaning tasks:\n\nconvert values in id field into character data type,\nexclude records with id value are na,\nexclude records with similar id values,\nexclude thing_collected field, and\nsave the cleaned tibble dataframe into a new tibble datatable called mc3_nodes_cleaned.\n\n\n\nCode\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n\n\n\n\nNext, the code chunk below will be used to:\n\nrename source and target fields to from_id and to_id respectively,\nconvert values in from_id and to_id fields to character data type,\nexclude values in from_id and to_id which not found in the id field of mc3_nodes_cleaned,\nexclude records whereby from_id and/or to_id values are missing, and\nsave the cleaned tibble dataframe and called it mc3_edges_cleaned.\n\n\n\nCode\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source, \n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), \n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\nNext, code chunk below will be used to create mapping of character id in mc3_nodes_cleaned to row index.\n\n\nCode\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nNext, the code chunk below will be used to join and convert from_id and to_id to integer indices. At the same time we also drop rows with unmatched nodes.\n\n\nCode\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to))  \n\n\nNext the code chunk below is used to subset nodes to only those referenced by edges.\n\n\nCode\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nWe will then use the code chunk below to rebuild lookup from old index to new index.\n\n\nCode\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n\nLastly, the code chunk below will be used to update edge indices to match new node table.\n\n\nCode\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\n\nNow we are ready to build the tidygraph object by using the code chunk below.\n\nmc3_graph &lt;- tbl_graph(\n  nodes = mc3_nodes_final,\n  edges = mc3_edges_final,\n  directed = TRUE\n)\n\nAfter the tidygraph object is created, it is always a good practice to examine the object by using str().\n\nstr(mc3_graph)\n\nClasses 'tbl_graph', 'igraph'  hidden list of 10\n $ : num 1159\n $ : logi TRUE\n $ : num [1:3226] 0 0 0 0 0 0 0 1 1 1 ...\n $ : num [1:3226] 1137 356 746 894 875 ...\n $ : NULL\n $ : NULL\n $ : NULL\n $ : NULL\n $ :List of 4\n  ..$ : num [1:3] 1 0 1\n  ..$ : Named list()\n  ..$ :List of 31\n  .. ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  .. ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  .. ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  .. ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ findings         : chr [1:1159] NA NA NA NA ...\n  .. ..$ content          : chr [1:1159] NA NA NA NA ...\n  .. ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ results          : chr [1:1159] NA NA NA NA ...\n  .. ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ destination      : chr [1:1159] NA NA NA NA ...\n  .. ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  .. ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  .. ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  .. ..$ reference        : chr [1:1159] NA NA NA NA ...\n  .. ..$ date             : chr [1:1159] NA NA NA NA ...\n  .. ..$ time             : chr [1:1159] NA NA NA NA ...\n  .. ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  .. ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  .. ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  .. ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  .. ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  .. ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ operational_role : chr [1:1159] NA NA NA NA ...\n  .. ..$ new_index        : int [1:1159] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ :List of 2\n  .. ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  .. ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n $ :&lt;environment: 0x0000023a869743f0&gt; \n - attr(*, \"active\")= chr \"nodes\""
  },
  {
    "objectID": "TH3/Take-Home_Ex02_MC3.html#exploratory-data-analysis-after-cleaning-wrangling",
    "href": "TH3/Take-Home_Ex02_MC3.html#exploratory-data-analysis-after-cleaning-wrangling",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "Several of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1818)\n\n\n\nShows how many nodes are of type Entity, Event, or Relationship.\n\n\nCode\nmc3_nodes_final %&gt;%\n  count(type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(type, -n), y = n, fill = type)) +\n  geom_col() +\n  geom_text(aes(label = n), vjust = -0.3) +\n  labs(title = \"Node Type Distribution\", x = \"Type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggraph functions are used to create the whole graph.\n\n\nCode\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nFocuses on what kinds of actors are in the graph — Person, Vessel, Organization, etc.\n\n\nCode\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo understand what kinds of actions dominate — Communication, Monitoring, Assessment, etc.\n\n\nCode\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis finds all Entities that sent or received communication events — i.e., actors who participated in messaging.\n\n\nCode\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\n\n\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\nMessage Senders are arranged from most to the least number of messages sent.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "TH3/Take-Home_Ex02_MC3.html#task-1a-1b-daily-temporal-patterns-in-communications-over-the-two-weeks",
    "href": "TH3/Take-Home_Ex02_MC3.html#task-1a-1b-daily-temporal-patterns-in-communications-over-the-two-weeks",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "VAST Challenge Task & Question 1a and 1b\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nDevelop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\nHow do these patterns shift over the two weeks of observations?\n\n\n\nObjective\n\nIdentify when communications happen most often during each day.\nDetect shifts in these patterns over the 2-week period.\nLater: Focus on a specific entity (e.g., Nadia Conti) and explore who influences them.\n\n\n\nExtract the Communication Timestamps from mc3_nodes_final and filter for communication events.\n\n# Filter for Communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n\nParse the Communication Timestamp into the format “dd/mm/yyy (ddd)” for ease of reference.\n\n# Communication events with parsed date and time\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n\n\n\n\n\n\n\n\nCode\n# Step 1: Prepare daily message volume data\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count &lt;- mean(daily_message_volume$message_count)\ntotal_msg_count &lt;- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %&gt;% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender–receiver–timestamp structure\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender–receiver–timestamp\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(sender_id = id, sender_label = label), by = \"sender_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, hour) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;⏰ Hour: \", sprintf(\"%02d:00\", hour),\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np &lt;- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nWe will increase the resolution to half-hour time slots.\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count.\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)  # ✅ fixed receiver_id\n\n# Step 2: Reconstruct sender–receiver–event linkage\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, time_bin, time_label) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;🕒 Time: \", time_label,\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np &lt;- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nThe faceted density plot that shows the distribution of communication events by time of day, broken down for each day in the dataset. It helps to visually detect temporal communication patterns, intensity, and consistency over multiple days.\n\nOverview of the 2 week periodDay 1 - 01/10/2040Day 2 - 02/10/2040Day 3 - 03/10/2040Day 4 - 04/10/2040Day 5 - 05/10/2040Day 6 - 06/10/2040Day 7 - 07/10/2040Day 8 - 08/10/2040Day 9 - 09/10/2040Day 10 - 10/10/2040Day 11 - 11/10/2040Day 12 - 12/10/2040Day 13 - 13/10/2040Day 14 - 14/10/2040\n\n\n\n\nCode\n# Step 1: Preprocess communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats &lt;- comm_events %&gt;%\n  group_by(date_label) %&gt;%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n📈 Insights This Visualization Offers\n\n\n\n\nBar Plot of combined hourly message volume over the 2 weeks period:\n\n\nCode\n# Prepare data\ncomm_hourly &lt;- comm_events %&gt;%\n  count(hour) %&gt;%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nBar Plot of combined half-hourly message volume in the 2 weeks period.\n\n\nCode\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute &lt; 30, 0, 30))\n  )\n\ncomm_halfhour &lt;- comm_events %&gt;%\n  count(time_bin) %&gt;%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1a. What are the identifiable daily temporal patterns in communications?\n\n\n\n\nThe daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)—a sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\nThe temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\nFor instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends—communication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n\n\n\n\n\n\n\n\n\n1b. How do these patterns shift over the two weeks of observations?\n\n\n\n\nOver the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of “surge” (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation—an analytical signal that warrants closer inspection of event logs or external triggers for those dates.\nAnother notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule—potentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures."
  },
  {
    "objectID": "TH3/Take-Home_Ex02_MC3.html#task-1c-focus-on-a-particular-entity---nadia-conti",
    "href": "TH3/Take-Home_Ex02_MC3.html#task-1c-focus-on-a-particular-entity---nadia-conti",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "VAST Challenge Task & Question 1c\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nFocus on a specific entity and use this information to determine who has influence over them.\n\n\n\n\n\nWe first extracted the relevant communication edges from the dataset, pairing “sent” and “received” communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\nCode\n# Extract sent and received communication event edges\nsent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges &lt;- sent_edges %&gt;%\n  inner_join(received_edges, by = \"event\") %&gt;%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges &lt;- sent_edges %&gt;%\n  select(from = source_entity, to = event)\nsingle_received_edges &lt;- received_edges %&gt;%\n  select(from = event, to = target_entity)\n\nall_edges &lt;- bind_rows(paired_edges, single_sent_edges, single_received_edges) %&gt;%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  pull(id) %&gt;% as.character()\n\nentity_edges &lt;- all_edges %&gt;%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  select(id, label, sub_type)\n\n\n\n\n\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node—PageRank, betweenness, and degree—quantifying the influence and connectivity of every entity in the overall network.\n\n\nCode\nlibrary(igraph)\n\ng &lt;- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank &lt;- page_rank(g)$vector\nV(g)$betweenness &lt;- betweenness(g)\nV(g)$degree &lt;- degree(g)\n\n\n\n\n\nFocusing on “Nadia Conti”, we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia’s immediate sphere of influence and the key players connected to her.\n\n\nCode\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\nego_graph &lt;- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n\n\n\n\n\nWe visualized Nadia’s ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti’s communication environment.\n\n\nCode\nnodes_df &lt;- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_graph)$label, \"&lt;/b&gt;&lt;br&gt;\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"&lt;br&gt;\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"&lt;br&gt;\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df &lt;- as_data_frame(ego_graph, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %&gt;%\n  visNodes(scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %&gt;%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal and Ego-Network Structure\n\n\n\nThe overview network visualization reveals that Nadia Conti is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia’s influence neighborhood.\n\n\n\n\n\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\nPageRank (overall influence),\nBetweenness (information brokerage/intermediary role), and\nDegree (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\nCode\n# PageRank table\npagerank_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %&gt;% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %&gt;% arrange(desc(betweenness))\n\n# Degree table\ndegree_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %&gt;% arrange(desc(degree))\n\n\n\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n\n\nPageRank Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\npagerank\n\n\n\n\nMako\nVessel\n0.0687\n\n\nOceanus City Council\nOrganization\n0.0530\n\n\nReef Guardian\nVessel\n0.0454\n\n\nNadia Conti\nPerson\n0.0432\n\n\nRemora\nVessel\n0.0409\n\n\nV. Miesel Shipping\nOrganization\n0.0394\n\n\nNeptune\nVessel\n0.0358\n\n\nHimark Harbor\nLocation\n0.0358\n\n\nLiam Thorne\nPerson\n0.0275\n\n\nBoss\nPerson\n0.0272\n\n\nSentinel\nVessel\n0.0250\n\n\nPaackland Harbor\nLocation\n0.0244\n\n\nDavis\nPerson\n0.0239\n\n\nMarlin\nVessel\n0.0235\n\n\nEcoVigil\nVessel\n0.0233\n\n\nGreen Guardians\nOrganization\n0.0224\n\n\nMrs. Money\nPerson\n0.0192\n\n\nSailor Shifts Team\nOrganization\n0.0186\n\n\nSeawatch\nVessel\n0.0186\n\n\nElise\nPerson\n0.0182\n\n\nSerenity\nVessel\n0.0170\n\n\nHorizon\nVessel\n0.0152\n\n\nThe Middleman\nPerson\n0.0142\n\n\nNorthern Light\nVessel\n0.0135\n\n\nRodriguez\nPerson\n0.0122\n\n\nSamantha Blake\nPerson\n0.0114\n\n\nHaacklee Harbor\nLocation\n0.0111\n\n\nOsprey\nVessel\n0.0088\n\n\nCity Officials\nGroup\n0.0066\n\n\nThe Lookout\nPerson\n0.0062\n\n\nKnowles\nVessel\n0.0051\n\n\nSmall Fry\nPerson\n0.0035\n\n\nGlitters Team\nOrganization\n0.0035\n\n\n\n\n\n\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n\n\nBetweenness Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\nbetweenness\n\n\n\n\nMako\nVessel\n368.50\n\n\nMrs. Money\nPerson\n167.18\n\n\nReef Guardian\nVessel\n139.69\n\n\nBoss\nPerson\n136.18\n\n\nV. Miesel Shipping\nOrganization\n118.70\n\n\nNadia Conti\nPerson\n117.87\n\n\nOceanus City Council\nOrganization\n116.11\n\n\nRemora\nVessel\n90.45\n\n\nNeptune\nVessel\n82.59\n\n\nThe Lookout\nPerson\n80.51\n\n\nHimark Harbor\nLocation\n52.61\n\n\nThe Middleman\nPerson\n50.78\n\n\nLiam Thorne\nPerson\n41.81\n\n\nHaacklee Harbor\nLocation\n41.30\n\n\nSentinel\nVessel\n34.54\n\n\nGreen Guardians\nOrganization\n27.51\n\n\nPaackland Harbor\nLocation\n27.08\n\n\nDavis\nPerson\n22.36\n\n\nEcoVigil\nVessel\n12.63\n\n\nRodriguez\nPerson\n11.75\n\n\nNorthern Light\nVessel\n9.76\n\n\nSailor Shifts Team\nOrganization\n7.34\n\n\nHorizon\nVessel\n6.72\n\n\nMarlin\nVessel\n6.23\n\n\nSeawatch\nVessel\n5.20\n\n\nElise\nPerson\n4.60\n\n\nSamantha Blake\nPerson\n4.49\n\n\nSerenity\nVessel\n0.81\n\n\nKnowles\nVessel\n0.50\n\n\nSmall Fry\nPerson\n0.00\n\n\nGlitters Team\nOrganization\n0.00\n\n\nOsprey\nVessel\n0.00\n\n\nCity Officials\nGroup\n0.00\n\n\n\n\n\n\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n\n\nDegree Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\ndegree\n\n\n\n\nMako\nVessel\n37\n\n\nOceanus City Council\nOrganization\n28\n\n\nReef Guardian\nVessel\n27\n\n\nRemora\nVessel\n21\n\n\nV. Miesel Shipping\nOrganization\n19\n\n\nNeptune\nVessel\n19\n\n\nNadia Conti\nPerson\n17\n\n\nGreen Guardians\nOrganization\n17\n\n\nHimark Harbor\nLocation\n17\n\n\nDavis\nPerson\n16\n\n\nSentinel\nVessel\n16\n\n\nBoss\nPerson\n13\n\n\nEcoVigil\nVessel\n13\n\n\nPaackland Harbor\nLocation\n13\n\n\nMrs. Money\nPerson\n12\n\n\nHorizon\nVessel\n12\n\n\nLiam Thorne\nPerson\n11\n\n\nRodriguez\nPerson\n10\n\n\nMarlin\nVessel\n10\n\n\nSeawatch\nVessel\n9\n\n\nThe Middleman\nPerson\n8\n\n\nSerenity\nVessel\n8\n\n\nNorthern Light\nVessel\n8\n\n\nHaacklee Harbor\nLocation\n8\n\n\nElise\nPerson\n7\n\n\nThe Lookout\nPerson\n7\n\n\nSailor Shifts Team\nOrganization\n7\n\n\nSamantha Blake\nPerson\n6\n\n\nGlitters Team\nOrganization\n4\n\n\nKnowles\nVessel\n4\n\n\nSmall Fry\nPerson\n3\n\n\nOsprey\nVessel\n3\n\n\nCity Officials\nGroup\n1\n\n\n\n\n\n\n\n\n\n\n\nCentrality Metrics and Direct & Indirect Influences\n\n\n\nBy calculating centrality metrics within Nadia’s two-hop ego network, we observe that the most influential nodes in her environment—by PageRank, betweenness, and degree—are Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia’s information flow and access to other parts of the network.\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n\n\n\n\n\n\nCode\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng &lt;- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 &lt;- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank &lt;- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df &lt;- as_data_frame(ego_1, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness &lt;- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Degree for the ego network\nV(ego_1)$degree &lt;- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n1c. With a focus on “Nadia Conti”, the visuals above could determine who has influence over this person.\n\n\n\n\nDegree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\nSeveral other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia’s network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that Nadia’s environment is both diverse and robust.\nDirect Connections\nThese direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti’s node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\nPeople: Elise, Liam Thorne, Davis, Rodriguez\nOrganization: V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\nVessel: Neptune, Marlin, Remora, Sentinel\nLocation: Haacklee Harbor\n\nInterpretation: The PageRank, Betweenness, and Degree centrality plots all consistently show Nadia Conti as a major hub, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\nNadia’s position suggests she is a key connector and influencer but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence—and be influenced—is amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia’s access to information, resources, and strategic decisions."
  },
  {
    "objectID": "Test_Folder/Rico_q3/Take Home Exercise 3.html",
    "href": "Test_Folder/Rico_q3/Take Home Exercise 3.html",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "In this part of the Take home Exercise, I will be impplementing the possible prototype that I will be using as part of our group’s SHINY project.\n\n\nThe Oceanus knowledge graph reveals complex interactions among vessels, individuals, organizations, and locations in a region suspected of illegal activities, particularly around Nemo Reef. With numerous monitoring, communication, and suspicious activity records, this dataset presents an opportunity to uncover hidden patterns of behavior, influence networks, and potential illicit operations. The goal is to leverage interactive visual analytics to support investigative journalism, policy enforcement, and regulatory audits, especially regarding unauthorized vessel activities and environmental violations.\n\n\n\n\n\n\npacman::p_load(tidyverse, jsonlite, \n               tidygraph, ggraph, SmartEDA, \n               ggrepel, scales, lubridate, dplyr, \n               visNetwork, viridis)\n\n\n\n\n\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")\n\n\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)\n\n\n\n\n\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n\n# To rename source and target fields\n\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source, \n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), \n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\n# To create mapping of fields\n\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n# Concert from_id to to_id\n\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to)) \n\n# Subset nodes to those only used by edges\n\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n# Rebuild from old index to old index\n\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n# Update edge indices to node\n\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\n\n\nThe code below is to help us to further clean the data first before we can start to answer question 3\n\n# Step 1: Define pseudonyms\npseudonym_keywords &lt;- c(\"Boss\", \"The Lookout\", \"The Intern\", \"Mrs. Money\", \n                        \"The Accountant\", \"The Middleman\", \"Small Fry\")\n\n# Step 2: Filter pseudonym nodes (from mc3_nodes_final)\npseudonym_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(\n    sub_type == \"Person\",\n    str_detect(name, regex(paste(pseudonym_keywords, collapse = \"|\"), ignore_case = TRUE))\n  )\n\n# Step 3: Get all edge rows where from/to match pseudonym node indices\npseudonym_node_indices &lt;- pseudonym_nodes$new_index\n\npseudonym_edges_final &lt;- mc3_edges_final %&gt;%\n  filter(from %in% pseudonym_node_indices | to %in% pseudonym_node_indices)\n\n# Step 4: Get only nodes that are involved in these edges\nused_node_indices &lt;- unique(c(pseudonym_edges_final$from, pseudonym_edges_final$to))\n\npseudonym_nodes_final &lt;- mc3_nodes_final %&gt;%\n  filter(new_index %in% used_node_indices) %&gt;%\n  mutate(label_type = ifelse(new_index %in% pseudonym_node_indices, \"Pseudonym\", \"Regular\"))\n\n# Step 5: Reindex nodes to match edge structure (0-based problem fix)\npseudonym_nodes_final &lt;- pseudonym_nodes_final %&gt;%\n  mutate(temp_index = row_number())\n\n# Mapping old new_index to new temp_index (for tbl_graph alignment)\nindex_map &lt;- pseudonym_nodes_final %&gt;%\n  select(old = new_index, new = temp_index)\n\n# Update edges to new 1-based index\npseudonym_edges_final &lt;- pseudonym_edges_final %&gt;%\n  left_join(index_map, by = c(\"from\" = \"old\")) %&gt;%\n  rename(from_new = new) %&gt;%\n  left_join(index_map, by = c(\"to\" = \"old\")) %&gt;%\n  rename(to_new = new) %&gt;%\n  filter(!is.na(from_new), !is.na(to_new)) %&gt;%\n  select(from = from_new, to = to_new, type)\n\n# Step 6: Build graph\npseudonym_graph &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n)\n\nBefore we start to answer the questions, let us first test out if the data cleaning is effective, which should be if not you wil not be able to see this!\n\nTest codeTest\n\n\n\nggraph(pseudonym_graph, layout = \"fr\") +\n  geom_edge_link(alpha = 0.3) +\n  geom_node_point(aes(color = label_type), size = 4) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 3) +\n  labs(\n    title = \"Pseudonym Communication Network\",\n    subtitle = \"Highlighting entities and their use of pseudonyms\",\n    color = \"Entity Type\"\n  ) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisations below shows the entities labelled based on their real names or pseudinyms which are labelled differently using color codes so as for easier visualisation.\n\nMethod 1Method 2\n\n\n\n# Count how many connections each pseudonym has\npseudonym_links &lt;- pseudonym_edges_final %&gt;%\n  left_join(pseudonym_nodes_final, by = c(\"from\" = \"temp_index\")) %&gt;%\n  rename(pseudonym = name) %&gt;%\n  filter(!is.na(pseudonym)) %&gt;%   # ✅ Only valid pseudonym nodes\n  group_by(pseudonym) %&gt;%\n  summarise(connection_count = n()) %&gt;%\n  arrange(desc(connection_count))\n\n\n# Plot it\nggplot(pseudonym_links, aes(x = reorder(pseudonym, connection_count), y = connection_count)) +\n  geom_col(fill = \"tomato\") +\n  coord_flip() +\n  labs(\n    title = \"Communication Frequency by Pseudonym\",\n    x = \"Pseudonym Name\",\n    y = \"Number of Connections\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n# Prepare node dataframe\nnodes_vis &lt;- pseudonym_nodes_final %&gt;%\n  transmute(\n    id = temp_index,\n    label = name,\n    group = ifelse(label_type == \"Pseudonym\", \"Pseudonym\", \"Regular\"),\n    title = paste(\"Name:\", name, \"&lt;br&gt;Type:\", label_type)\n  )\n\n# Prepare edge dataframe\nedges_vis &lt;- pseudonym_edges_final %&gt;%\n  transmute(\n    from = from,\n    to = to,\n    label = type,\n    arrows = \"to\"\n  )\n\n# Create visNetwork\nvisNetwork(nodes_vis, edges_vis, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visGroups(groupname = \"Regular\", color = \"steelblue\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\"),\n    list(label = \"Regular\", shape = \"dot\", color = \"steelblue\")\n  )) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visPhysics(stabilization = TRUE)\n\n\n\n\n\n\n\n\nAs we can see, there are 2 methods that we can use to visualise this case. The aim of this visualisation is to help clepper to visually identufy which nodes are pseudonuyms, and how are they connected to the real identity. Suspicious names or aliases will appear isolated\n\n\n\n\n\n\nWhat can we learn from the observations above?\n\n\n\n\nFrom this visualisation, we can easily determine which names are Pseudonyms. These names can be easily identified via the color codes\nWe can easily trace who talks to and/or through aliases\nThis visualisation makes it easier for Clepper to spot suspicious names\n\n\n\n\n\n\n\nCodeVisualisation output\n\n\n\n# Q3b: Extract edges involving those pseudonyms\n# Build pseudonym network using tidygraph\npseudonym_graph_tbl &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n) %&gt;%\n  mutate(degree_centrality = centrality_degree(mode = \"all\"))  # centrality values added to nodes\n\n# Turn into tibble for ggplot\ntop_central &lt;- pseudonym_graph_tbl %&gt;%\n  as_tibble() %&gt;%\n  filter(label_type == \"Pseudonym\") %&gt;%\n  arrange(desc(degree_centrality)) %&gt;%\n  slice_head(n = 10)\n\n# Plot\nggplot(top_central, aes(x = reorder(name, degree_centrality), y = degree_centrality)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Central Pseudonym Entities\",\n    x = \"Pseudonym Name\",\n    y = \"Degree Centrality\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisation shows a bar chart of degree centrality that shows the tiop 10 most connectd pseudonyms. The aim of this graph is to heko clepper to quantify influence by measuring the cetrakity of the pseudonyms for deeper investigation. It also helps Clepper t identify who are the key players who may be controlling the flow of information\n\n\n\n\n\n\nWhat can we learn from the above visualisation?\n\n\n\n\nThese visualisation helps Clepper to identify wich of the pseudonyms are most active\nWe can see that the nodes act as central hubs wihin the pseudonym network\nThis visualisation can help clepper to prioritize pseudionyms first as part of his investigations\n\n\n\n\n\n\n\nCodeVisualisation Output\n\n\n\nshared_pseudonyms &lt;- pseudonym_nodes_final %&gt;%\n  group_by(name) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\n# Create nodes: both entities and pseudonyms\nvis_nodes_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(id = id, \n            label = id, \n            group = \"Entity\",\n            title = paste(\"Entity ID:\", id)) %&gt;%\n  bind_rows(\n    shared_pseudonyms %&gt;%\n      select(id = name) %&gt;%\n      distinct() %&gt;%\n      mutate(label = id,\n             group = \"Pseudonym\",\n             title = paste(\"Pseudonym:\", id))\n  )\n\nvis_edges_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(from = id, to = name)\n\nvisNetwork(vis_nodes_3c, vis_edges_3c, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Entity\", color = \"steelblue\") %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Entity\", shape = \"dot\", color = \"steelblue\"),\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\")\n  )) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisation used for this part of the question is an interactive graph using the visNetwork entity which shows the edges and nodes. The blue nodes indicates the entities (may be people or vessels), red nodes which is the pseudonym names and edges which indicates which entity uses what pseudonym. The aim of this visualisation is to expose the reusing of an alias whereby the same pseudonym is tied and connected to multiple entities\n\n\n\n\n\n\nWhat can we learn from this visualisation?\n\n\n\n\nThis visualisation helps Clepper to easily identify which pseudonyms are reused by multiple entities\nThis breaks the assumed connection between identity and name revealing many one-to-one mapping\nThis therefore can help Clepper to detect deception strategies such as multiple people pretending to have one single alias, hence minimising the risks of impersonation."
  },
  {
    "objectID": "Test_Folder/Rico_q3/Take Home Exercise 3.html#motivation-of-this-project",
    "href": "Test_Folder/Rico_q3/Take Home Exercise 3.html#motivation-of-this-project",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "The Oceanus knowledge graph reveals complex interactions among vessels, individuals, organizations, and locations in a region suspected of illegal activities, particularly around Nemo Reef. With numerous monitoring, communication, and suspicious activity records, this dataset presents an opportunity to uncover hidden patterns of behavior, influence networks, and potential illicit operations. The goal is to leverage interactive visual analytics to support investigative journalism, policy enforcement, and regulatory audits, especially regarding unauthorized vessel activities and environmental violations."
  },
  {
    "objectID": "Test_Folder/Rico_q3/Take Home Exercise 3.html#data-preparation",
    "href": "Test_Folder/Rico_q3/Take Home Exercise 3.html#data-preparation",
    "title": "Take-Home Exercise 3",
    "section": "",
    "text": "pacman::p_load(tidyverse, jsonlite, \n               tidygraph, ggraph, SmartEDA, \n               ggrepel, scales, lubridate, dplyr, \n               visNetwork, viridis)\n\n\n\n\n\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")\n\n\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)\n\n\n\n\n\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n\n# To rename source and target fields\n\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source, \n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), \n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\n# To create mapping of fields\n\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n# Concert from_id to to_id\n\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to)) \n\n# Subset nodes to those only used by edges\n\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n# Rebuild from old index to old index\n\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n# Update edge indices to node\n\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\n\n\nThe code below is to help us to further clean the data first before we can start to answer question 3\n\n# Step 1: Define pseudonyms\npseudonym_keywords &lt;- c(\"Boss\", \"The Lookout\", \"The Intern\", \"Mrs. Money\", \n                        \"The Accountant\", \"The Middleman\", \"Small Fry\")\n\n# Step 2: Filter pseudonym nodes (from mc3_nodes_final)\npseudonym_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(\n    sub_type == \"Person\",\n    str_detect(name, regex(paste(pseudonym_keywords, collapse = \"|\"), ignore_case = TRUE))\n  )\n\n# Step 3: Get all edge rows where from/to match pseudonym node indices\npseudonym_node_indices &lt;- pseudonym_nodes$new_index\n\npseudonym_edges_final &lt;- mc3_edges_final %&gt;%\n  filter(from %in% pseudonym_node_indices | to %in% pseudonym_node_indices)\n\n# Step 4: Get only nodes that are involved in these edges\nused_node_indices &lt;- unique(c(pseudonym_edges_final$from, pseudonym_edges_final$to))\n\npseudonym_nodes_final &lt;- mc3_nodes_final %&gt;%\n  filter(new_index %in% used_node_indices) %&gt;%\n  mutate(label_type = ifelse(new_index %in% pseudonym_node_indices, \"Pseudonym\", \"Regular\"))\n\n# Step 5: Reindex nodes to match edge structure (0-based problem fix)\npseudonym_nodes_final &lt;- pseudonym_nodes_final %&gt;%\n  mutate(temp_index = row_number())\n\n# Mapping old new_index to new temp_index (for tbl_graph alignment)\nindex_map &lt;- pseudonym_nodes_final %&gt;%\n  select(old = new_index, new = temp_index)\n\n# Update edges to new 1-based index\npseudonym_edges_final &lt;- pseudonym_edges_final %&gt;%\n  left_join(index_map, by = c(\"from\" = \"old\")) %&gt;%\n  rename(from_new = new) %&gt;%\n  left_join(index_map, by = c(\"to\" = \"old\")) %&gt;%\n  rename(to_new = new) %&gt;%\n  filter(!is.na(from_new), !is.na(to_new)) %&gt;%\n  select(from = from_new, to = to_new, type)\n\n# Step 6: Build graph\npseudonym_graph &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n)\n\nBefore we start to answer the questions, let us first test out if the data cleaning is effective, which should be if not you wil not be able to see this!\n\nTest codeTest\n\n\n\nggraph(pseudonym_graph, layout = \"fr\") +\n  geom_edge_link(alpha = 0.3) +\n  geom_node_point(aes(color = label_type), size = 4) +\n  geom_node_text(aes(label = name), repel = TRUE, size = 3) +\n  labs(\n    title = \"Pseudonym Communication Network\",\n    subtitle = \"Highlighting entities and their use of pseudonyms\",\n    color = \"Entity Type\"\n  ) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisations below shows the entities labelled based on their real names or pseudinyms which are labelled differently using color codes so as for easier visualisation.\n\nMethod 1Method 2\n\n\n\n# Count how many connections each pseudonym has\npseudonym_links &lt;- pseudonym_edges_final %&gt;%\n  left_join(pseudonym_nodes_final, by = c(\"from\" = \"temp_index\")) %&gt;%\n  rename(pseudonym = name) %&gt;%\n  filter(!is.na(pseudonym)) %&gt;%   # ✅ Only valid pseudonym nodes\n  group_by(pseudonym) %&gt;%\n  summarise(connection_count = n()) %&gt;%\n  arrange(desc(connection_count))\n\n\n# Plot it\nggplot(pseudonym_links, aes(x = reorder(pseudonym, connection_count), y = connection_count)) +\n  geom_col(fill = \"tomato\") +\n  coord_flip() +\n  labs(\n    title = \"Communication Frequency by Pseudonym\",\n    x = \"Pseudonym Name\",\n    y = \"Number of Connections\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n# Prepare node dataframe\nnodes_vis &lt;- pseudonym_nodes_final %&gt;%\n  transmute(\n    id = temp_index,\n    label = name,\n    group = ifelse(label_type == \"Pseudonym\", \"Pseudonym\", \"Regular\"),\n    title = paste(\"Name:\", name, \"&lt;br&gt;Type:\", label_type)\n  )\n\n# Prepare edge dataframe\nedges_vis &lt;- pseudonym_edges_final %&gt;%\n  transmute(\n    from = from,\n    to = to,\n    label = type,\n    arrows = \"to\"\n  )\n\n# Create visNetwork\nvisNetwork(nodes_vis, edges_vis, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visGroups(groupname = \"Regular\", color = \"steelblue\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\"),\n    list(label = \"Regular\", shape = \"dot\", color = \"steelblue\")\n  )) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visPhysics(stabilization = TRUE)\n\n\n\n\n\n\n\n\nAs we can see, there are 2 methods that we can use to visualise this case. The aim of this visualisation is to help clepper to visually identufy which nodes are pseudonuyms, and how are they connected to the real identity. Suspicious names or aliases will appear isolated\n\n\n\n\n\n\nWhat can we learn from the observations above?\n\n\n\n\nFrom this visualisation, we can easily determine which names are Pseudonyms. These names can be easily identified via the color codes\nWe can easily trace who talks to and/or through aliases\nThis visualisation makes it easier for Clepper to spot suspicious names\n\n\n\n\n\n\n\nCodeVisualisation output\n\n\n\n# Q3b: Extract edges involving those pseudonyms\n# Build pseudonym network using tidygraph\npseudonym_graph_tbl &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n) %&gt;%\n  mutate(degree_centrality = centrality_degree(mode = \"all\"))  # centrality values added to nodes\n\n# Turn into tibble for ggplot\ntop_central &lt;- pseudonym_graph_tbl %&gt;%\n  as_tibble() %&gt;%\n  filter(label_type == \"Pseudonym\") %&gt;%\n  arrange(desc(degree_centrality)) %&gt;%\n  slice_head(n = 10)\n\n# Plot\nggplot(top_central, aes(x = reorder(name, degree_centrality), y = degree_centrality)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Central Pseudonym Entities\",\n    x = \"Pseudonym Name\",\n    y = \"Degree Centrality\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisation shows a bar chart of degree centrality that shows the tiop 10 most connectd pseudonyms. The aim of this graph is to heko clepper to quantify influence by measuring the cetrakity of the pseudonyms for deeper investigation. It also helps Clepper t identify who are the key players who may be controlling the flow of information\n\n\n\n\n\n\nWhat can we learn from the above visualisation?\n\n\n\n\nThese visualisation helps Clepper to identify wich of the pseudonyms are most active\nWe can see that the nodes act as central hubs wihin the pseudonym network\nThis visualisation can help clepper to prioritize pseudionyms first as part of his investigations\n\n\n\n\n\n\n\nCodeVisualisation Output\n\n\n\nshared_pseudonyms &lt;- pseudonym_nodes_final %&gt;%\n  group_by(name) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\n# Create nodes: both entities and pseudonyms\nvis_nodes_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(id = id, \n            label = id, \n            group = \"Entity\",\n            title = paste(\"Entity ID:\", id)) %&gt;%\n  bind_rows(\n    shared_pseudonyms %&gt;%\n      select(id = name) %&gt;%\n      distinct() %&gt;%\n      mutate(label = id,\n             group = \"Pseudonym\",\n             title = paste(\"Pseudonym:\", id))\n  )\n\nvis_edges_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(from = id, to = name)\n\nvisNetwork(vis_nodes_3c, vis_edges_3c, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Entity\", color = \"steelblue\") %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Entity\", shape = \"dot\", color = \"steelblue\"),\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\")\n  )) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisation used for this part of the question is an interactive graph using the visNetwork entity which shows the edges and nodes. The blue nodes indicates the entities (may be people or vessels), red nodes which is the pseudonym names and edges which indicates which entity uses what pseudonym. The aim of this visualisation is to expose the reusing of an alias whereby the same pseudonym is tied and connected to multiple entities\n\n\n\n\n\n\nWhat can we learn from this visualisation?\n\n\n\n\nThis visualisation helps Clepper to easily identify which pseudonyms are reused by multiple entities\nThis breaks the assumed connection between identity and name revealing many one-to-one mapping\nThis therefore can help Clepper to detect deception strategies such as multiple people pretending to have one single alias, hence minimising the risks of impersonation."
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "",
    "text": "This take home exercise is based on the VAST Challenge Mini Case 3\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jessen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation.\nYour task is to develop new and novel visualizations and visual analytics approaches to help Clepper get to the bottom of this story"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#initial-eda",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#initial-eda",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "3.1 Initial EDA",
    "text": "3.1 Initial EDA\n\n\nShow code\nExpCatViz(data=mc3_nodes,\n          col=\"pink\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#relationship-between-entities-and-events",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#relationship-between-entities-and-events",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.1 Relationship between entities and events",
    "text": "6.1 Relationship between entities and events\n\n\nShow code\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 2) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#entity-distribution",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#entity-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.2 Entity distribution",
    "text": "6.2 Entity distribution\n\n\nShow code\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#event-type-distribution",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#event-type-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.3 Event type distribution",
    "text": "6.3 Event type distribution\n\n\nShow code\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#list-of-communication-participants",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#list-of-communication-participants",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4 List of communication participants",
    "text": "6.4 List of communication participants\n\n\nShow code\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#visualization-of-communication-participants-network",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#visualization-of-communication-participants-network",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4.1 Visualization of communication participants network",
    "text": "6.4.1 Visualization of communication participants network\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-1a-and-1b",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-1a-and-1b",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 1a and 1b",
    "text": "VAST Challenge Task & Question 1a and 1b\nClepper found that messages frequently came in at around the same time each day.\n\nDevelop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\nHow do these patterns shift over the two weeks of observations?\n\nObjective\n\nIdentify when communications happen most often during each day.\nDetect shifts in these patterns over the 2-week period.\nLater: Focus on a specific entity (e.g., Nadia Conti) and explore who influences them.\n\n\nStep 1: Extract & Parse Communication Event Timestamps\nExtract the Communication Timestamps from mc3_nodes_final and filter for communication events.\n\n\nShow code\n# Filter for Communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n\n\nParse the Communication Timestamp into the format “dd/mm/yyy (ddd)” for ease of reference.\n\n\nShow code\n# Communication events with parsed date and time\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n\n\n\n\nStep 2: Visualize the Communication Volume for Analysis\n\n2.1 - Bar Plot of daily communication volume over the 2 weeks period:\n\n\nShow code\n# Step 1: Prepare daily message volume data\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count &lt;- mean(daily_message_volume$message_count)\ntotal_msg_count &lt;- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n2.2 - Interactive Table of daily communication volume variation(message count)\n\n\nShow code\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %&gt;% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\n2.3a - Heat Map of hourly message volume for each day over the 2 weeks period:\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count\n\n\nShow code\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender–receiver–timestamp structure\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender–receiver–timestamp\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(sender_id = id, sender_label = label), by = \"sender_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, hour) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;⏰ Hour: \", sprintf(\"%02d:00\", hour),\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np &lt;- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nWe will increase the resolution to half-hour time slots.\n\n\n2.4b - Heat Map of half-hourly message volume for each day over the 2 weeks period:\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count.\n\n\nShow code\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)  # ✅ fixed receiver_id\n\n# Step 2: Reconstruct sender–receiver–event linkage\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, time_bin, time_label) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;🕒 Time: \", time_label,\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np &lt;- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n2.4c - Density plot of Daily half-hourly message volume over the 2 weeks period:\nThe faceted density plot that shows the distribution of communication events by time of day, broken down for each day in the dataset. It helps to visually detect temporal communication patterns, intensity, and consistency over multiple days.\n\nOverview of the 2 week periodDay 1 - 01/10/2040Day 2 - 02/10/2040Day 3 - 03/10/2040Day 4 - 04/10/2040Day 5 - 05/10/2040Day 6 - 06/10/2040Day 7 - 07/10/2040Day 8 - 08/10/2040Day 9 - 09/10/2040Day 10 - 10/10/2040Day 11 - 11/10/2040Day 12 - 12/10/2040Day 13 - 13/10/2040Day 14 - 14/10/2040\n\n\n\n\nShow code\n# Step 1: Preprocess communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats &lt;- comm_events %&gt;%\n  group_by(date_label) %&gt;%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n📈 Insights This Visualization Offers\n\n\n\nStep 3: Plot Combined Hourly and Half-hourly Communication Volume\nBar Plot of combined hourly message volume over the 2 weeks period:\n\n\nShow code\n# Prepare data\ncomm_hourly &lt;- comm_events %&gt;%\n  count(hour) %&gt;%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nBar Plot of combined half-hourly message volume in the 2 weeks period.\n\n\nShow code\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute &lt; 30, 0, 30))\n  )\n\ncomm_halfhour &lt;- comm_events %&gt;%\n  count(time_bin) %&gt;%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1a. What are the identifiable daily temporal patterns in communications?\n\n\n\n\nThe daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)—a sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\nThe temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\nFor instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends—communication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n\n\n\n\n\n\n\n\n\n1b. How do these patterns shift over the two weeks of observations?\n\n\n\n\nOver the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of “surge” (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation—an analytical signal that warrants closer inspection of event logs or external triggers for those dates.\nAnother notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule—potentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures."
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-1c",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-1c",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 1c",
    "text": "VAST Challenge Task & Question 1c\nClepper found that messages frequently came in at around the same time each day.\n\nFocus on a specific entity and use this information to determine who has influence over them.\n\n\n3.1 - Data Preparation for “Nadia Conti” Influence Analysis\nWe first extracted the relevant communication edges from the dataset, pairing “sent” and “received” communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\nShow code\n# Extract sent and received communication event edges\nsent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges &lt;- sent_edges %&gt;%\n  inner_join(received_edges, by = \"event\") %&gt;%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges &lt;- sent_edges %&gt;%\n  select(from = source_entity, to = event)\nsingle_received_edges &lt;- received_edges %&gt;%\n  select(from = event, to = target_entity)\n\nall_edges &lt;- bind_rows(paired_edges, single_sent_edges, single_received_edges) %&gt;%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  pull(id) %&gt;% as.character()\n\nentity_edges &lt;- all_edges %&gt;%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  select(id, label, sub_type)\n\n\n\n\n3.2 - Build the Global Network and Compute Centrality\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node—PageRank, betweenness, and degree—quantifying the influence and connectivity of every entity in the overall network.\n\n\nShow code\nlibrary(igraph)\n\ng &lt;- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank &lt;- page_rank(g)$vector\nV(g)$betweenness &lt;- betweenness(g)\nV(g)$degree &lt;- degree(g)\n\n\n\n\n3.3 - Extract “Nadia Conti” Ego Network (2-hop Neighbourhood)\nFocusing on “Nadia Conti”, we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia’s immediate sphere of influence and the key players connected to her.\n\n\nShow code\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\nego_graph &lt;- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n\n\n\n\n3.4 - Visualize Nadia Conti’s Ego Network (Interactive)\nWe visualized Nadia’s ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti’s communication environment.\n\n\nShow code\nnodes_df &lt;- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_graph)$label, \"&lt;/b&gt;&lt;br&gt;\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"&lt;br&gt;\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"&lt;br&gt;\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df &lt;- as_data_frame(ego_graph, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %&gt;%\n  visNodes(scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %&gt;%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#global-and-ego-network-structure",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#global-and-ego-network-structure",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Global and Ego-Network Structure",
    "text": "Global and Ego-Network Structure\nThe overview network visualization reveals that Nadia Conti is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia’s influence neighborhood.\n\n3.5 - Centrality Tables for Nadia’s Ego Network\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\nPageRank (overall influence),\nBetweenness (information brokerage/intermediary role), and\nDegree (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\nShow code\n# PageRank table\npagerank_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %&gt;% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %&gt;% arrange(desc(betweenness))\n\n# Degree table\ndegree_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %&gt;% arrange(desc(degree))\n\n\n\n\nShow code\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n\n\n\nPageRank Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\npagerank\n\n\n\n\nMako\nVessel\n0.0687\n\n\nOceanus City Council\nOrganization\n0.0530\n\n\nReef Guardian\nVessel\n0.0454\n\n\nNadia Conti\nPerson\n0.0432\n\n\nRemora\nVessel\n0.0409\n\n\nV. Miesel Shipping\nOrganization\n0.0394\n\n\nNeptune\nVessel\n0.0358\n\n\nHimark Harbor\nLocation\n0.0358\n\n\nLiam Thorne\nPerson\n0.0275\n\n\nBoss\nPerson\n0.0272\n\n\nSentinel\nVessel\n0.0250\n\n\nPaackland Harbor\nLocation\n0.0244\n\n\nDavis\nPerson\n0.0239\n\n\nMarlin\nVessel\n0.0235\n\n\nEcoVigil\nVessel\n0.0233\n\n\nGreen Guardians\nOrganization\n0.0224\n\n\nMrs. Money\nPerson\n0.0192\n\n\nSailor Shifts Team\nOrganization\n0.0186\n\n\nSeawatch\nVessel\n0.0186\n\n\nElise\nPerson\n0.0182\n\n\nSerenity\nVessel\n0.0170\n\n\nHorizon\nVessel\n0.0152\n\n\nThe Middleman\nPerson\n0.0142\n\n\nNorthern Light\nVessel\n0.0135\n\n\nRodriguez\nPerson\n0.0122\n\n\nSamantha Blake\nPerson\n0.0114\n\n\nHaacklee Harbor\nLocation\n0.0111\n\n\nOsprey\nVessel\n0.0088\n\n\nCity Officials\nGroup\n0.0066\n\n\nThe Lookout\nPerson\n0.0062\n\n\nKnowles\nVessel\n0.0051\n\n\nSmall Fry\nPerson\n0.0035\n\n\nGlitters Team\nOrganization\n0.0035\n\n\n\n\n\n\n\nShow code\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n\n\n\nBetweenness Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\nbetweenness\n\n\n\n\nMako\nVessel\n368.50\n\n\nMrs. Money\nPerson\n167.18\n\n\nReef Guardian\nVessel\n139.69\n\n\nBoss\nPerson\n136.18\n\n\nV. Miesel Shipping\nOrganization\n118.70\n\n\nNadia Conti\nPerson\n117.87\n\n\nOceanus City Council\nOrganization\n116.11\n\n\nRemora\nVessel\n90.45\n\n\nNeptune\nVessel\n82.59\n\n\nThe Lookout\nPerson\n80.51\n\n\nHimark Harbor\nLocation\n52.61\n\n\nThe Middleman\nPerson\n50.78\n\n\nLiam Thorne\nPerson\n41.81\n\n\nHaacklee Harbor\nLocation\n41.30\n\n\nSentinel\nVessel\n34.54\n\n\nGreen Guardians\nOrganization\n27.51\n\n\nPaackland Harbor\nLocation\n27.08\n\n\nDavis\nPerson\n22.36\n\n\nEcoVigil\nVessel\n12.63\n\n\nRodriguez\nPerson\n11.75\n\n\nNorthern Light\nVessel\n9.76\n\n\nSailor Shifts Team\nOrganization\n7.34\n\n\nHorizon\nVessel\n6.72\n\n\nMarlin\nVessel\n6.23\n\n\nSeawatch\nVessel\n5.20\n\n\nElise\nPerson\n4.60\n\n\nSamantha Blake\nPerson\n4.49\n\n\nSerenity\nVessel\n0.81\n\n\nKnowles\nVessel\n0.50\n\n\nSmall Fry\nPerson\n0.00\n\n\nGlitters Team\nOrganization\n0.00\n\n\nOsprey\nVessel\n0.00\n\n\nCity Officials\nGroup\n0.00\n\n\n\n\n\n\n\nShow code\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n\n\n\nDegree Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\ndegree\n\n\n\n\nMako\nVessel\n37\n\n\nOceanus City Council\nOrganization\n28\n\n\nReef Guardian\nVessel\n27\n\n\nRemora\nVessel\n21\n\n\nV. Miesel Shipping\nOrganization\n19\n\n\nNeptune\nVessel\n19\n\n\nNadia Conti\nPerson\n17\n\n\nGreen Guardians\nOrganization\n17\n\n\nHimark Harbor\nLocation\n17\n\n\nDavis\nPerson\n16\n\n\nSentinel\nVessel\n16\n\n\nBoss\nPerson\n13\n\n\nEcoVigil\nVessel\n13\n\n\nPaackland Harbor\nLocation\n13\n\n\nMrs. Money\nPerson\n12\n\n\nHorizon\nVessel\n12\n\n\nLiam Thorne\nPerson\n11\n\n\nRodriguez\nPerson\n10\n\n\nMarlin\nVessel\n10\n\n\nSeawatch\nVessel\n9\n\n\nThe Middleman\nPerson\n8\n\n\nSerenity\nVessel\n8\n\n\nNorthern Light\nVessel\n8\n\n\nHaacklee Harbor\nLocation\n8\n\n\nElise\nPerson\n7\n\n\nThe Lookout\nPerson\n7\n\n\nSailor Shifts Team\nOrganization\n7\n\n\nSamantha Blake\nPerson\n6\n\n\nGlitters Team\nOrganization\n4\n\n\nKnowles\nVessel\n4\n\n\nSmall Fry\nPerson\n3\n\n\nOsprey\nVessel\n3\n\n\nCity Officials\nGroup\n1"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#centrality-metrics-and-direct-indirect-influences",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#centrality-metrics-and-direct-indirect-influences",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Centrality Metrics and Direct & Indirect Influences",
    "text": "Centrality Metrics and Direct & Indirect Influences\nBy calculating centrality metrics within Nadia’s two-hop ego network, we observe that the most influential nodes in her environment—by PageRank, betweenness, and degree—are Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia’s information flow and access to other parts of the network.\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n\n3.5.1 - PageRank for Nadia Conti\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng &lt;- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 &lt;- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank &lt;- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df &lt;- as_data_frame(ego_1, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n3.5.2 - Betweenness for Nadia Conti\n\n\nShow code\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness &lt;- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n3.5.3 - Degree for Nadia Conti\n\n\nShow code\n# 1. Compute Degree for the ego network\nV(ego_1)$degree &lt;- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n1c. With a focus on “Nadia Conti”, the visuals above could determine who has influence over this person.\n\n\n\n\nDegree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\nSeveral other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia’s network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that Nadia’s environment is both diverse and robust.\nDirect Connections\nThese direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti’s node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\nPeople: Elise, Liam Thorne, Davis, Rodriguez\nOrganization: V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\nVessel: Neptune, Marlin, Remora, Sentinel\nLocation: Haacklee Harbor\n\nInterpretation: The PageRank, Betweenness, and Degree centrality plots all consistently show Nadia Conti as a major hub, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\nNadia’s position suggests she is a key connector and influencer but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence—and be influenced—is amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia’s access to information, resources, and strategic decisions."
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#strategy-for-question-2",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#strategy-for-question-2",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Strategy for Question 2:",
    "text": "Strategy for Question 2:\n\n1. Filter for Communication Events Only\n\nUse edges that connect Entity → Event (Communication) and Event (Communication) → Entity.\nFocus only on Communication events and extract senders and receivers.\n\n\n\nShow code\n# Extract Communication Events from nodes\ncommunication_events &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, label)\n\n# Extract sent edges: Entity → Communication Event\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% communication_events$id)\n\n# Extract received edges: Communication Event → Entity\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% communication_events$id)\n\n# Join both to get Sender → Communication → Receiver\ncomm_links &lt;- comm_sent_edges %&gt;%\n  select(comm_id = to_id, sender = from_id) %&gt;%\n  inner_join(\n    comm_received_edges %&gt;% select(comm_id = from_id, receiver = to_id),\n    by = \"comm_id\"\n  ) %&gt;%\n  filter(sender != receiver)\n\n\n\n\n2. Construct a Bipartite Graph of Communications\n\nFrom edges:\n\nSender (Entity) → Communication Event\nCommunication Event → Receiver (Entity)\n\nJoin both directions to link:\nEntity A → Communication Event → Entity B → derive Entity A → Entity B communication links.\n\n\n\nShow code\n# Get people and vessel node IDs\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter comm links to include only person ↔ vessel or person ↔ person, etc.\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\n3. Build Communication Network\n\nNodes: People and Vessels only (from mc3_nodes_cleaned).\nEdges: Summarized links between these nodes based on co-involvement in the same communication event.\n\n\n\nShow code\n# Edge weight (number of communications)\nedge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Create node list for graph\nnodes_df &lt;- people_vessels %&gt;%\n  filter(id %in% c(edge_df$sender, edge_df$receiver))\n\n# Build graph object\ncomm_graph &lt;- tbl_graph(nodes = nodes_df, edges = edge_df, directed = FALSE)\n\n\n\n\n4. Apply Community Detection (e.g., Louvain or Walktrap)\n\nUse igraph or tidygraph to detect communities.\nAnnotate communities for possible labels (e.g., Green Guardians, Sailor Shift fans) using node metadata.\n\n\n\nShow code\ncomm_graph &lt;- comm_graph %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\n5. Visualize Network\n\n\nShow code\nshape_map &lt;- c(\"Person\" = \"circle\", \"Vessel\" = \"triangle\")\n\ncolor_map &lt;- c(\n  \"Person\" = \"#fc8d62\",\n  \"Organization\" = \"#6baed6\",\n  \"Vessel\" = \"#66c2a2\",\n  \"Location\" = \"#c6dbef\",\n  \"Nadia Conti\" = \"#ffd92f\"\n)\n\nggraph(comm_graph, layout = \"fr\") +\n  geom_edge_link(aes(width = weight), alpha = 0.2, color = \"gray50\") +\n  geom_node_point(aes(color = group, shape = group), size = 4) +\n  geom_node_text(aes(label = label), repel = TRUE, size = 2.5) +\n  scale_shape_manual(values = shape_map) +\n  scale_color_manual(values = color_map) +\n  theme_graph() +\n  labs(title = \"Communication Clusters Between People and Vessels\",\n       subtitle = \"Communities detected using Louvain algorithm\")\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Get only Person and Vessel nodes\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter communication links for person ↔ vessel/person only\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\nShow code\n# Count number of communications between each sender–receiver pair\ncomm_edge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Build node dataframe from involved IDs only\ncomm_node_df &lt;- people_vessels %&gt;%\n  filter(id %in% unique(c(comm_edge_df$sender, comm_edge_df$receiver))) %&gt;%\n  mutate(\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Vessel\" ~ \"triangle\"\n    ),\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",\n      group == \"Vessel\" ~ \"#66c2a2\",\n      label == \"Nadia Conti\" ~ \"#ffd92f\",\n      TRUE ~ \"#c6dbef\"\n    )\n  )\n\n# Format edges for visNetwork\ncomm_vis_edges &lt;- comm_edge_df %&gt;%\n  rename(from = sender, to = receiver) %&gt;%\n  mutate(width = weight)\n\n\n\n\nShow code\nlibrary(igraph)\n\n# Create igraph object\ngraph_ig &lt;- graph_from_data_frame(comm_vis_edges, directed = FALSE, vertices = comm_node_df)\n\n# Apply Louvain clustering\nlouvain_groups &lt;- cluster_louvain(graph_ig)\ncomm_node_df$group_comm &lt;- as.factor(membership(louvain_groups))\n\n\n\n\nShow code\nlibrary(visNetwork)\n\n# Title heading\ncat(\"### Interactive Network of Communication Between People and Vessels\")\n\n\n### Interactive Network of Communication Between People and Vessels\n\n\nShow code\n# Final interactive visNetwork with consistent styling\nvisNetwork(\n  nodes = comm_node_df,\n  edges = comm_vis_edges\n) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -80,\n      centralGravity = 0.01,\n      springLength = 50,\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n    ),\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\n\nShow code\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nShow code\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nShow code\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -50,   # Increase pull toward center\n      centralGravity = 0.005,        # Lower keeps outer nodes further\n      springLength = 100,            # Length between nodes\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages by sender/receiver\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and label\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Bar plot\nggplot(comm_summary, aes(x = reorder(label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggtext)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages sent and received\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and format\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Create colored labels for x-axis\ncomm_summary &lt;- comm_summary %&gt;%\n  mutate(\n    x_label = paste0(\n      \"&lt;span style='color:\",\n      case_when(\n        sub_type == \"Vessel\" ~ \"#66c2a2\",\n        sub_type == \"Person\" ~ \"#fc8d62\",\n        TRUE ~ \"gray\"\n      ),\n      \"'&gt;\", label, \"&lt;/span&gt;\"\n    )\n  )\n\n# Step 5: Bar Plot with colored axis text\nggplot(comm_summary, aes(x = reorder(x_label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_markdown(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotly)\nlibrary(DT)\n\n# Step 1: Compute message counts\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 2: Combine counts\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\")\n\n# Step 3: Reshape for plotly\ncomm_long &lt;- comm_summary %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Plotly bar chart (interactive)\nplot_ly(\n  comm_long,\n  x = ~label,\n  y = ~count,\n  color = ~direction,\n  colors = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\"),\n  type = 'bar',\n  text = ~paste0(\"Entity: \", label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Count: \", count),\n  hoverinfo = 'text',\n  name = ~direction\n) %&gt;%\n  layout(\n    title = \"Interactive Message Volume by Entity\",\n    barmode = 'group',\n    xaxis = list(title = \"Entity\", tickangle = -45),\n    yaxis = list(title = \"Message Count\")\n  )\n\n\n\n\n\n\n\n\nShow code\ndatatable(\n  comm_summary %&gt;% arrange(desc(sent + received)),\n  options = list(\n    pageLength = 10,\n    autoWidth = TRUE,\n    searchHighlight = TRUE\n  ),\n  colnames = c(\"ID\", \"Name\", \"Sent\", \"Received\", \"Type\")\n)"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#strategy-to-tackle-q2b",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#strategy-to-tackle-q2b",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Strategy to Tackle Q2b",
    "text": "Strategy to Tackle Q2b\n\nStep 1: Community Detection with Louvain\n\nUse igraph::cluster_louvain() on the communication network built in 2a (undirected).\nAssign a community ID to each node (nodes_vis$community).\n\n\n\nStep 2: Inspect and Interpret Communities\n\nSummarize the composition of each community by:\n\nNumber of persons/vessels\nTop labels in each group\nKnown keywords (e.g., “Green Guardians”, “Sailor Shift”, vessel names like “Aurora” or “Bluefin”)\n\n\n\n\nStep 3: Color-code the Network by Community\n\nAssign a distinct color to each detected community.\nRetain shape encoding (dot = Person, triangle = Vessel).\n\n\n\nStep 4: Interactive Visualization\n\nUse visNetwork to display the full communication network:\n\nColor nodes by community\nTooltip includes label, type, community\nLegend for each detected community\n\n\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Create igraph from person-vessel edges\ng_comm &lt;- graph_from_data_frame(edges_vis, directed = FALSE, vertices = nodes_vis)\n\n# Louvain detection\nlouvain_clusters &lt;- cluster_louvain(g_comm)\nnodes_vis$louvain_comm &lt;- as.factor(membership(louvain_clusters))\n\n# Walktrap detection\nwalktrap_clusters &lt;- cluster_walktrap(g_comm)\nnodes_vis$walktrap_comm &lt;- as.factor(membership(walktrap_clusters))\n\n# Create color palettes\nmax_comm &lt;- max(as.numeric(nodes_vis$louvain_comm), as.numeric(nodes_vis$walktrap_comm))\ncomm_colors &lt;- brewer.pal(n = min(max_comm, 8), name = \"Set2\")\n\n# Assign community color for each method\nnodes_louvain &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(louvain_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Louvain: \", louvain_comm)\n  )\n\nnodes_walktrap &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(walktrap_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Walktrap: \", walktrap_comm)\n  )\n\n\n\n\nShow code\n# Define consistent edge formatting\nedges_format &lt;- edges_vis %&gt;%\n  mutate(arrows = \"to\", width = width)\n\n# Louvain network\nlouvain_net &lt;- visNetwork(nodes_louvain, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Louvain Communities\"), useGroups = FALSE)\n\n# Walktrap network\nwalktrap_net &lt;- visNetwork(nodes_walktrap, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Walktrap Communities\"), useGroups = FALSE)\n\n\n📌 Louvain Community Network\n\n\nShow code\n# Generate cluster legend for Louvain\nlouvain_legend &lt;- unique(nodes_louvain$louvain_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_louvain$color[nodes_louvain$louvain_comm == comm_id])[1]\n    )\n  })\n\n# Render Louvain network\ncat(\"## Louvain Community Detection Network\")\n\n\n## Louvain Community Detection Network\n\n\nShow code\nvisNetwork(nodes_louvain, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = louvain_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )\n\n\n\n\n\n\n📌 Walktrap Community Network\n\n\nShow code\n# Generate cluster legend for Walktrap\nwalktrap_legend &lt;- unique(nodes_walktrap$walktrap_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_walktrap$color[nodes_walktrap$walktrap_comm == comm_id])[1]\n    )\n  })\n\n# Render Walktrap network\ncat(\"## Walktrap Community Detection Network\")\n\n\n## Walktrap Community Detection Network\n\n\nShow code\nvisNetwork(nodes_walktrap, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = walktrap_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )"
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-3a",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-3a",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 3a",
    "text": "VAST Challenge Task & Question 3a\n\nExpanding upon your prior visual analytics, determine who is using pseudonyms to communicate, and what these pseudonyms are.\n\nSome that Clepper has already identified include: “Boss”, and “The Lookout”, but there appear to be many more.\nTo complicate the matter, pseudonyms may be used by multiple people or vessels.\n\n\n\n1. Cleaning the dataset\nThe code below is to help us to further clean the data first before we can start to answer question 3\n\n\nShow code\n# Step 1: Define pseudonyms\npseudonym_keywords &lt;- c(\"Boss\", \"The Lookout\", \"The Intern\", \"Mrs. Money\", \n                        \"The Accountant\", \"The Middleman\", \"Small Fry\")\n\n# Step 2: Filter pseudonym nodes (from mc3_nodes_final)\npseudonym_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(\n    sub_type == \"Person\",\n    str_detect(name, regex(paste(pseudonym_keywords, collapse = \"|\"), ignore_case = TRUE))\n  )\n\n# Step 3: Get all edge rows where from/to match pseudonym node indices\npseudonym_node_indices &lt;- pseudonym_nodes$new_index\n\npseudonym_edges_final &lt;- mc3_edges_final %&gt;%\n  filter(from %in% pseudonym_node_indices | to %in% pseudonym_node_indices)\n\n# Step 4: Get only nodes that are involved in these edges\nused_node_indices &lt;- unique(c(pseudonym_edges_final$from, pseudonym_edges_final$to))\n\npseudonym_nodes_final &lt;- mc3_nodes_final %&gt;%\n  filter(new_index %in% used_node_indices) %&gt;%\n  mutate(label_type = ifelse(new_index %in% pseudonym_node_indices, \"Pseudonym\", \"Regular\"))\n\n# Step 5: Reindex nodes to match edge structure (0-based problem fix)\npseudonym_nodes_final &lt;- pseudonym_nodes_final %&gt;%\n  mutate(temp_index = row_number())\n\n# Mapping old new_index to new temp_index (for tbl_graph alignment)\nindex_map &lt;- pseudonym_nodes_final %&gt;%\n  select(old = new_index, new = temp_index)\n\n# Update edges to new 1-based index\npseudonym_edges_final &lt;- pseudonym_edges_final %&gt;%\n  left_join(index_map, by = c(\"from\" = \"old\")) %&gt;%\n  rename(from_new = new) %&gt;%\n  left_join(index_map, by = c(\"to\" = \"old\")) %&gt;%\n  rename(to_new = new) %&gt;%\n  filter(!is.na(from_new), !is.na(to_new)) %&gt;%\n  select(from = from_new, to = to_new, type)\n\n# Step 6: Build graph\npseudonym_graph &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n)\n\n\nBefore we start to answer the questions, let us first test out if the data cleaning is effective, which should be if not you wil not be able to see this!\n\nTest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisations below shows the entities labelled based on their real names or pseudinyms which are labelled differently using color codes so as for easier visualisation.\n\nMethod 1Method 2\n\n\n\n\nShow code\n# Count how many connections each pseudonym has\npseudonym_links &lt;- pseudonym_edges_final %&gt;%\n  left_join(pseudonym_nodes_final, by = c(\"from\" = \"temp_index\")) %&gt;%\n  rename(pseudonym = name) %&gt;%\n  filter(!is.na(pseudonym)) %&gt;%   # ✅ Only valid pseudonym nodes\n  group_by(pseudonym) %&gt;%\n  summarise(connection_count = n()) %&gt;%\n  arrange(desc(connection_count))\n\n\n# Plot it\nggplot(pseudonym_links, aes(x = reorder(pseudonym, connection_count), y = connection_count)) +\n  geom_col(fill = \"tomato\") +\n  coord_flip() +\n  labs(\n    title = \"Communication Frequency by Pseudonym\",\n    x = \"Pseudonym Name\",\n    y = \"Number of Connections\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Prepare node dataframe\nnodes_vis &lt;- pseudonym_nodes_final %&gt;%\n  transmute(\n    id = temp_index,\n    label = name,\n    group = ifelse(label_type == \"Pseudonym\", \"Pseudonym\", \"Regular\"),\n    title = paste(\"Name:\", name, \"&lt;br&gt;Type:\", label_type)\n  )\n\n# Prepare edge dataframe\nedges_vis &lt;- pseudonym_edges_final %&gt;%\n  transmute(\n    from = from,\n    to = to,\n    label = type,\n    arrows = \"to\"\n  )\n\n# Create visNetwork\nvisNetwork(nodes_vis, edges_vis, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visGroups(groupname = \"Regular\", color = \"steelblue\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\"),\n    list(label = \"Regular\", shape = \"dot\", color = \"steelblue\")\n  )) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visPhysics(stabilization = TRUE)\n\n\n\n\n\n\n\n\n\nAs we can see, there are 2 methods that we can use to visualise this case. The aim of this visualisation is to help clepper to visually identufy which nodes are pseudonuyms, and how are they connected to the real identity. Suspicious names or aliases will appear isolated\n\nFrom this visualisation, we can easily determine which names are Pseudonyms. These names can be easily identified via the color codes\nWe can easily trace who talks to and/or through aliases\nThis visualisation makes it easier for Clepper to spot suspicious names\n\n\n\n2. Question 3b\n\nDescribe how your visualizations make it easier for Clepper to identify common entities in the knowledge graph.\n\n\nCodeVisualisation output\n\n\n\n\nShow code\n# Q3b: Extract edges involving those pseudonyms\n# Build pseudonym network using tidygraph\npseudonym_graph_tbl &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n) %&gt;%\n  mutate(degree_centrality = centrality_degree(mode = \"all\"))  # centrality values added to nodes\n\n# Turn into tibble for ggplot\ntop_central &lt;- pseudonym_graph_tbl %&gt;%\n  as_tibble() %&gt;%\n  filter(label_type == \"Pseudonym\") %&gt;%\n  arrange(desc(degree_centrality)) %&gt;%\n  slice_head(n = 10)\n\n# Plot\nggplot(top_central, aes(x = reorder(name, degree_centrality), y = degree_centrality)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Central Pseudonym Entities\",\n    x = \"Pseudonym Name\",\n    y = \"Degree Centrality\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisation shows a bar chart of degree centrality that shows the tiop 10 most connectd pseudonyms. The aim of this graph is to heko clepper to quantify influence by measuring the cetrakity of the pseudonyms for deeper investigation. It also helps Clepper t identify who are the key players who may be controlling the flow of information\n\nThese visualisation helps Clepper to identify wich of the pseudonyms are most active\nWe can see that the nodes act as central hubs wihin the pseudonym network\nThis visualisation can help clepper to prioritize pseudionyms first as part of his investigations\n\n\n\n3. Question 3c\n\n\n\n\n\n\nThe visualisation used for this part of the question is an interactive graph using the visNetwork entity which shows the edges and nodes. The blue nodes indicates the entities (may be people or vessels), red nodes which is the pseudonym names and edges which indicates which entity uses what pseudonym. The aim of this visualisation is to expose the reusing of an alias whereby the same pseudonym is tied and connected to multiple entities\n\nThis visualisation helps Clepper to easily identify which pseudonyms are reused by multiple entities\nThis breaks the assumed connection between identity and name revealing many one-to-one mapping\nThis therefore can help Clepper to detect deception strategies such as multiple people pretending to have one single alias, hence minimising the risks of impersonation."
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-4a",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#vast-challenge-task-question-4a",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 4a",
    "text": "VAST Challenge Task & Question 4a\n\nClepper suspects that Nadia Conti, who was formerly entangled in an illegal fishing scheme, may have continued illicit activity within Oceanus.\n\nThrough visual analytics, provide evidence that Nadia is, or is not, doing something illegal.\n\n\n\n1. Extracting Nadia’s data\n\n\nShow code\nnodes &lt;- MC3$nodes\nedges &lt;- MC3$edges\n\n# Extract communication events\ncomms &lt;- nodes %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, content)\n\n# Link to sender & receiver\nsent_edges &lt;- edges %&gt;% filter(type == \"sent\") %&gt;%\n  select(source = source, comm_id = target)\n\nrecv_edges &lt;- edges %&gt;% filter(type == \"received\") %&gt;%\n  select(comm_id = source, target = target)\n\n# Merge\ncomms_data &lt;- comms %&gt;%\n  left_join(sent_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(sender = source) %&gt;%\n\n  left_join(recv_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(receiver = target)\n\n# Add sender/receiver names\nmc3_nodes_cleaned &lt;- nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE)\n\ncomms_data &lt;- comms_data %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver\" = \"id\"))\n\n# Count Nadia's messages\nnadia_counts &lt;- comms_data %&gt;%\n  summarise(\n    Sent = sum(sender_label == \"Nadia Conti\", na.rm = TRUE),\n    Received = sum(receiver_label == \"Nadia Conti\", na.rm = TRUE)\n  ) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Type\", values_to = \"Count\") %&gt;%\n  mutate(\n    Percent = Count / sum(Count),\n    Label = paste0(round(Percent * 100), \"%\\n(\", Count, \" msgs)\")\n  )\n\n\n\n\n2. Message count of Nadia\n\n\nShow code\nggplot(nadia_counts, aes(x = Count, y = reorder(Type, Count), fill = Type)) +\n  geom_col(color = \"white\") +\n  geom_text(aes(label = paste0(Count, \" msgs (\", round(Percent * 100), \"%)\")),\n            hjust = -0.1, size = 4) +\n  scale_fill_manual(values = c(\"Sent\" = \"deepskyblue3\", \"Received\" = \"cyan\")) +\n  labs(title = paste0(\"Nadia Conti's Messages (Total: \", sum(nadia_counts$Count), \")\"),\n       x = \"Message Count\", y = NULL) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(face = \"bold\")) +\n  xlim(0, max(nadia_counts$Count) * 1.2)\n\n\n\n\n\n\n\n\n\n\n\n3. Message frequency of Nadia\n\n\nShow code\n# Make sure nadia_data is created\nnadia_data &lt;- comms_data %&gt;%\n  filter(sender_label == \"Nadia Conti\" | receiver_label == \"Nadia Conti\") %&gt;%\n  left_join(nodes %&gt;% select(id, timestamp), by = c(\"id\" = \"id\")) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(date = as.Date(timestamp), hour = hour(timestamp))\n\n# Create daily_freq\ndaily_freq &lt;- nadia_data %&gt;%\n  group_by(date) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n# Create hourly_freq\nhourly_freq &lt;- nadia_data %&gt;%\n  group_by(date, hour) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n\n\n3.1 Daily\n\n\nShow code\nggplot(daily_freq, aes(x = date, y = count)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = count), vjust = -0.5, size = 3) +\n  labs(\n    title = \"Nadia Conti's Daily Message Frequency\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n3.2 Hourly\n\n\nShow code\nlibrary(plotly)\n\nplot_ly(\n  data = hourly_freq,\n  x = ~hour,\n  y = ~count,\n  color = ~as.factor(date),\n  type = 'bar',\n  text = ~paste(\"Date:\", date, \"&lt;br&gt;Hour:\", hour, \"&lt;br&gt;Messages:\", count),\n  hoverinfo = 'text'\n) %&gt;%\n  layout(\n    barmode = 'dodge',  # use 'stack' if you prefer stacked bars\n    title = \"Nadia Conti's Hourly Message Frequency\",\n    xaxis = list(title = \"Hour of Day\"),\n    yaxis = list(title = \"Message Count\"),\n    legend = list(title = list(text = \"Date\"))\n  )\n\n\n\n\n\n\n\n\n\n4. Nadia’s relationship pattern\n\n\nShow code\nlibrary(ggplot2)\n\n# Count relationships by type\nrelationship_counts &lt;- mc3_edges_cleaned %&gt;%\n  filter(type != \"sent\", type != \"received\") %&gt;%  # Focus on relationships, not communication\n  count(type, sort = TRUE)\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(visNetwork)\n\n# Summarise Nadia's communication edges\nnadia_edges &lt;- nadia_data %&gt;%\n  count(sender_label, receiver_label) %&gt;%\n  filter(!is.na(sender_label), !is.na(receiver_label)) %&gt;%\n  rename(from = sender_label, to = receiver_label, value = n)\n\n# Get sender + receiver entity info\n# Get type info for sender and receiver\nentity_info &lt;- bind_rows(\n  nadia_data %&gt;%\n    left_join(mc3_nodes_cleaned %&gt;% select(id, name = label, type = sub_type),\n              by = c(\"sender\" = \"id\")) %&gt;%\n    select(name, type),\n  nadia_data %&gt;%\n    left_join(mc3_nodes_cleaned %&gt;% select(id, name = label, type = sub_type),\n              by = c(\"receiver\" = \"id\")) %&gt;%\n    select(name, type)\n) %&gt;%\n  distinct()\n\n# Build node table\nnadia_nodes &lt;- tibble(name = unique(c(nadia_edges$from, nadia_edges$to))) %&gt;%\n  left_join(entity_info, by = \"name\") %&gt;%\n  mutate(\n    group = ifelse(name == \"Nadia Conti\", \"Nadia Conti\", type),\n    id = name,\n    label = name,\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",       \n      group == \"Organization\" ~ \"#6baed6\",\n      group == \"Vessel\" ~ \"#66c2a2\",      \n      group == \"Location\" ~ \"#c6dbef\",    \n      group == \"Nadia Conti\" ~ \"#ffd92f\", \n      TRUE ~ \"#d9d9d9\"\n    ),\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Organization\" ~ \"square\",\n      group == \"Vessel\" ~ \"triangle\",\n      group == \"Location\" ~ \"diamond\",\n      group == \"Nadia Conti\" ~ \"star\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Render network\nvisNetwork(nodes = nadia_nodes, edges = nadia_edges) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(gravitationalConstant = -25, centralGravity = 0.01, springLength = 50, springConstant = 0.02),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Organization\", shape = \"square\", color = \"#6baed6\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\"),\n      list(label = \"Location\", shape = \"diamond\", color = \"#c6dbef\"),\n      list(label = \"Nadia Conti\", shape = \"star\", color = \"#ffd92f\")\n    ),\n    width = 0.2,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\n\n5. Nadia’s most frequent commuter\n\n\nShow code\n# Get communication events linked to Nadia\nnadia_comm_ids &lt;- edges %&gt;%\n  filter(type == \"sent\" | type == \"received\") %&gt;%\n  filter(source == mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"] |\n         target == mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]) %&gt;%\n  mutate(comm_id = ifelse(type == \"sent\", target, source)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Get edges related to these communications\nnadia_related_edges &lt;- edges %&gt;%\n  filter(source %in% nadia_comm_ids | target %in% nadia_comm_ids)\n\n# Get people connected (excluding comm events + Nadia herself)\nnadia_id &lt;- mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]\n\nnadia_contacts_ids &lt;- nadia_related_edges %&gt;%\n  mutate(person_id = ifelse(source %in% nadia_comm_ids, target, source)) %&gt;%\n  filter(!person_id %in% nadia_comm_ids, person_id != nadia_id) %&gt;%\n  count(person_id, sort = TRUE)\n\n# Join with node labels\ntop_contacts_named &lt;- nadia_contacts_ids %&gt;%\n  left_join(nodes %&gt;% filter(sub_type == \"Person\") %&gt;% select(id, name = label),\n            by = c(\"person_id\" = \"id\")) %&gt;%\n  filter(!is.na(name))\n\n\n\n\nShow code\ntop_contacts_named %&gt;%\n  slice_max(n, n = 3) %&gt;%\n  ggplot(aes(x = reorder(name, n), y = n)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 3 Contacts Communicating with Nadia Conti\",\n    x = \"Contact Person\",\n    y = \"Number of Messages\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(DT)\n\nnadia_id &lt;- mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]\n\n# Nadia's communication event IDs\nnadia_comm_ids &lt;- edges %&gt;%\n  filter(type == \"sent\" | type == \"received\") %&gt;%\n  filter(source == nadia_id | target == nadia_id) %&gt;%\n  mutate(comm_id = ifelse(type == \"sent\", target, source)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Top contact comm IDs\ntop_contact_comm_ids &lt;- edges %&gt;%\n  filter(\n    (source %in% nadia_comm_ids & target %in% top_contacts_named$person_id) |\n    (target %in% nadia_comm_ids & source %in% top_contacts_named$person_id)\n  ) %&gt;%\n  mutate(comm_id = ifelse(source %in% nadia_comm_ids, source, target)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Get comm event details\nnadia_messages &lt;- nodes %&gt;%\n  filter(id %in% top_contact_comm_ids) %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, timestamp, content) %&gt;%\n  left_join(edges %&gt;% filter(type == \"sent\") %&gt;% select(id = target, sender = source),\n            by = \"id\") %&gt;%\n  left_join(edges %&gt;% filter(type == \"received\") %&gt;% select(id = source, receiver = target),\n            by = \"id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_name = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_name = label), by = c(\"receiver\" = \"id\")) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    sender_receiver = paste(sender_name, \"→\", receiver_name)\n  ) %&gt;%\n  arrange(timestamp) %&gt;%\n  select(timestamp, sender_receiver, content)\n\n# Display\nDT::datatable(\n  nadia_messages,\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE,\n    initComplete = htmlwidgets::JS(\n      \"function(settings, json) {\",\n      \"$(this.api().table().header()).css({'background-color': '#f8f9fa', 'color': '#333'});\",\n      \"}\"\n    )\n  ),\n  rownames = FALSE,\n  class = 'stripe hover compact',\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:16px; color:#444;',\n    'Messages'\n  )\n)\n\n\n\n\n\n\n\n\n6. Temporal + suspicious event alignment\n\n6.1 Showing Nadia’s unusually active days\n\n\nShow code\n# Compute mean + SD of daily messages\ndaily_summary &lt;- daily_freq %&gt;%\n  summarise(mean_count = mean(count), sd_count = sd(count))\n\n# Flag days with unusually high message counts\nspike_days &lt;- daily_freq %&gt;%\n  filter(count &gt; daily_summary$mean_count + 2 * daily_summary$sd_count)\n\n# Show spike days\nprint(spike_days)\n\n\n# A tibble: 1 × 2\n  date       count\n  &lt;date&gt;     &lt;int&gt;\n1 2040-10-08     9\n\n\n\n\n6.2 Suspicious dates\n\n\nShow code\nsuspicious_dates &lt;- as.Date(c(\"2040-10-05\", \"2040-10-08\", \"2040-10-11\")) # example reef closure, approvals, etc.\n\n\n\n\nShow code\nspike_days %&gt;%\n  mutate(suspicious = ifelse(date %in% suspicious_dates, \"YES\", \"NO\"))\n\n\n# A tibble: 1 × 3\n  date       count suspicious\n  &lt;date&gt;     &lt;int&gt; &lt;chr&gt;     \n1 2040-10-08     9 YES       \n\n\n\n\nShow code\nlibrary(plotly)\nlibrary(dplyr)\n\n# Suppose suspicious dates (replace with real ones)\nsuspicious_dates &lt;- as.Date(c(\"2040-10-05\", \"2040-10-08\", \"2040-10-11\"))\n\n# Compute threshold\ndaily_summary &lt;- daily_freq %&gt;%\n  summarise(mean_count = mean(count), sd_count = sd(count))\n\nthreshold &lt;- daily_summary$mean_count + 2 * daily_summary$sd_count\n\n# Add status column\ndaily_freq_plot &lt;- daily_freq %&gt;%\n  mutate(\n    status = case_when(\n      date %in% suspicious_dates ~ \"Suspicious Date\",\n      count &gt; threshold ~ \"Spike\",\n      TRUE ~ \"Normal\"\n    )\n  )\n\n# Assign colors\nstatus_colors &lt;- c(\n  \"Normal\" = \"steelblue\",\n  \"Spike\" = \"red\",\n  \"Suspicious Date\" = \"orange\"\n)\n\n# Build Plotly bar chart\nplot_ly(\n  data = daily_freq_plot,\n  x = ~date,\n  y = ~count,\n  type = 'bar',\n  color = ~status,\n  colors = status_colors,\n  text = ~paste(\"Date:\", date, \"&lt;br&gt;Messages:\", count, \"&lt;br&gt;Status:\", status),\n  hoverinfo = 'text'\n) %&gt;%\n  layout(\n    title = \"Nadia Conti's Daily Communication\",\n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"Message Count\"),\n    barmode = 'group',\n    legend = list(title = list(text = \"Status\"))\n  ) %&gt;%\n  add_lines(\n    x = ~date,\n    y = rep(threshold, nrow(daily_freq_plot)),\n    line = list(dash = 'dash', color = 'red'),\n    name = 'Spike Threshold',\n    inherit = FALSE\n  )\n\n\n\n\n\n\n\n\n\n7. Drilling down on spike + flagged date\n\n7.1 Extract Nadia’s message from Oct 8\n\n\nShow code\n# Build fresh nadia_data with content included at the start\nnadia_data &lt;- comms %&gt;%\n  left_join(sent_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(sender = source) %&gt;%\n  left_join(recv_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(receiver = target) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver\" = \"id\")) %&gt;%\n  left_join(nodes %&gt;% select(id, timestamp), by = \"id\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    hour = hour(timestamp)\n  ) %&gt;%\n  filter(sender_label == \"Nadia Conti\" | receiver_label == \"Nadia Conti\") %&gt;%\n  filter(!is.na(timestamp))\n\n\n\n\nShow code\noct8_msgs &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  select(timestamp, sender_label, receiver_label, content) %&gt;%\n  arrange(timestamp)\n\nDT::datatable(\n  oct8_msgs,\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE,\n    columnDefs = list(\n      list(\n        targets = 3,  # adjust if content is not 3rd col\n        render = JS(\n          \"function(data, type, row, meta) {\",\n          \"return type === 'display' && data.length &gt; 50 ?\",\n          \"'&lt;span title=\\\"' + data + '\\\"&gt;' + data.substr(0, 50) + '...&lt;/span&gt;' : data;\",\n          \"}\"\n        )\n      )\n    )\n  ),\n  rownames = FALSE,\n  class = 'stripe hover compact',\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:14px; color:#444;',\n    '📌 Nadia Conti Messages on Oct 8, 2040'\n  )\n)\n\n\n\n\n\n\n\n\n7.2 Keywords of Oct 8\nShowing messages on Oct 8 mentioning suspicious terms of:\n\npermit\napproval\nreef\ncargo\nshipment\nillegal\n\n\n\nShow code\n# Define suspicious keywords\nkeywords &lt;- c(\"permit\", \"approval\", \"reef\", \"cargo\", \"shipment\", \"dock\", \"illegal\")\n\n# Filter messages on Oct 8 with suspicious terms\noct8_flagged_msgs &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  filter(!is.na(content)) %&gt;%\n  filter(grepl(paste(keywords, collapse = \"|\"), content, ignore.case = TRUE)) %&gt;%\n  select(timestamp, sender_label, receiver_label, content) %&gt;%\n  arrange(timestamp)\n\n# Display in interactive table\nDT::datatable(\n  oct8_flagged_msgs,\n  options = list(pageLength = 5, autoWidth = TRUE),\n  rownames = FALSE,\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:16px; color:#444;',\n    '📌 Oct 8 Messages with Suspicious Keywords'\n  )\n)\n\n\n\n\n\n\n\n\n7.3 Network of Oct 8 communication\n\n\nShow code\nlibrary(visNetwork)\n\n# Summarize comms on Oct 8\noct8_edges &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  count(sender_label, receiver_label) %&gt;%\n  filter(!is.na(sender_label), !is.na(receiver_label)) %&gt;%\n  rename(from = sender_label, to = receiver_label, value = n)\n\n# Build node list\noct8_nodes &lt;- tibble(name = unique(c(oct8_edges$from, oct8_edges$to))) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(label, sub_type), by = c(\"name\" = \"label\")) %&gt;%\n  mutate(\n    group = ifelse(name == \"Nadia Conti\", \"Nadia Conti\", sub_type),\n    id = name,\n    label = name\n  )\n\n# Render network\nvisNetwork(oct8_nodes, oct8_edges) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 456) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLegend()\n\n\n\n\n\n\nNadia is heavily involved in:\n\nDiscussion of Nemo Reef, permits, foundation work\nCoordinating payments, doubling fees, Harbor Master cooperation\nAdjusting schedules to avoid council suspicion\n\nHighly suspicious tone: manipulation, concealment, operational coordination beyond scope.\n\n\n\n8. Linking Oct 8 comms to permits, approvals, or vessel activity\n\n\nShow code\nsuspicious_events_alt &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type %in% c(\"VesselMovement\", \"Monitoring\", \"HarborReport\", \"Fishing\", \"Enforcement\")) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(timestamp &gt;= as.POSIXct(\"2040-10-08\"))\n\nDT::datatable(\n  suspicious_events_alt %&gt;%\n    select(type, label, sub_type, id, timestamp, monitoring_type, findings),\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE\n  ),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(plotly)\n\n# 1️⃣ Prepare entity-related vessel/harbor events\nentity_events &lt;- suspicious_events_alt %&gt;%\n  filter(str_detect(findings, regex(\"Neptune|Miesel|Mako\", ignore_case = TRUE))) %&gt;%\n  mutate(entity = case_when(\n    str_detect(findings, regex(\"Neptune\", ignore_case = TRUE)) ~ \"Neptune\",\n    str_detect(findings, regex(\"Miesel\", ignore_case = TRUE)) ~ \"Miesel\",\n    str_detect(findings, regex(\"Mako\", ignore_case = TRUE)) ~ \"Mako\",\n    TRUE ~ \"Other\"\n  ))\n\n# 2️⃣ Build interactive plot\nplot_ly() %&gt;%\n  # Nadia comms\n  add_markers(\n    data = nadia_data,\n    x = ~timestamp,\n    y = ~\"Nadia Message\",\n    marker = list(color = \"red\", size = 10),\n    text = ~paste0(\"Nadia Message&lt;br&gt;\", timestamp),\n    hoverinfo = \"text\",\n    name = \"Nadia Message\"\n  ) %&gt;%\n  # Neptune events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Neptune\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#1f77b4\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Neptune Event\"\n  ) %&gt;%\n  # Miesel events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Miesel\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#17becf\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Miesel Event\"\n  ) %&gt;%\n  # Mako events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Mako\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#7f7f7f\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Mako Event\"\n  ) %&gt;%\n  layout(\n    title = \"Nadia Comms + Vessel/Harbor Events\",\n    xaxis = list(title = \"Time\"),\n    yaxis = list(title = \"\"),\n    legend = list(orientation = \"h\", x = 0.1, y = -0.3)\n  )\n\n\n\n\n\n\nThe interactive timeline highlights that Nadia Conti’s communications were closely followed by vessel/harbor events involving Neptune, V. Miesel Shipping, and Mako. Notably:\n•   On **Oct 8**, Nadia’s messages spiked, coinciding with planned operations at Nemo Reef.\n\n•   Shortly afterward, vessel activities linked to **Neptune, Miesel, and Mako** were logged.\n\n•   This temporal proximity strongly suggests coordination between Nadia and these entities.\nThere is no evidence of formal approvals or permits linked to these activities, pointing to potential covert operations."
  },
  {
    "objectID": "Test_Folder/adrian_test_q4/testing_q4.html#question-4b",
    "href": "Test_Folder/adrian_test_q4/testing_q4.html#question-4b",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Question 4B",
    "text": "Question 4B\n\nSummarize Nadia’s actions visually. Are Clepper’s suspicions justified?"
  },
  {
    "objectID": "project_proposal/project_proposal.html",
    "href": "project_proposal/project_proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "In this take-home exercise, you are required to select one of the module of your proposed Shiny application and complete the following tasks:\n\nTo evaluate and determine the necessary R packages needed for your Shiny application are supported in R CRAN,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determine above.\n\n\n\n\n\nThis prototype module is part of a larger visual analytics application for Mini-Challenge 3 (VAST Challenge 2025). It supports investigative journalist Clepper Jessen in uncovering hidden relationships and pseudonymous communication patterns within the radio transcript dataset of Oceanus.\nThe goal of this prototype is to storyboard and test a modular component that will eventually be integrated into the full Shiny application. The focus is on community detection and interactive pseudonym analysis, providing users with the ability to dynamically explore clusters of entities based on radio communication activity.\nThis document outlines the prototyping process, from data wrangling and method selection, to interactive interface design using Shiny components. The storyboard describes how different visual and interactive elements will work together to support investigative insights.\n\n\n\nThe source data is a knowledge graph in JSON format (MC3_graph.json) provided in the VAST Challenge 2025 Mini-Challenge 3. It consists of two primary components:\n\nNodes: Representing entities such as persons, vessels, places, and roles, each with metadata such as labels and types.\nEdges: Representing communications between nodes with attributes such as sender, receiver, channel, date-time, and message weight.\n\n\n\nThe following R packages were used for data wrangling:\n\n\nCode\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(jsonlite)\nlibrary(dplyr)\n\n\nThe steps to prepare the data are as follows:\nStep 1: Load and Parse the JSON File\n# Load the knowledge graph json_graph &lt;- jsonlite::read_json(\"data/MC3_graph.json\")\nStep 2: Extract and Structure Nodes and Edges\n# Convert to tibble format nodes_tbl &lt;- as_tibble(json_graph$nodes) edges_tbl &lt;- as_tibble(json_graph$links)  # Rename and structure columns for compatibility nodes_tbl &lt;- nodes_tbl %&gt;% rename(id = id, label = name, type = entity_type) edges_tbl &lt;- edges_tbl %&gt;% rename(from = source, to = target)\nStep 3: Convert to a Tidygraph Object\ngraph_data &lt;- tbl_graph(nodes = nodes_tbl, edges = edges_tbl, directed = TRUE)\nStep 4: Clean and Enrich the Graph\n# Filter out edges with low weights or irrelevant connections (e.g., self-loops) graph_data &lt;- graph_data %&gt;%    activate(edges) %&gt;%    filter(!is.na(from), !is.na(to)) %&gt;%    filter(weight &gt; 1) %&gt;%    activate(nodes) %&gt;%    mutate(degree = centrality_degree())\nStep 5: Verify Graph Summary\nsummary(graph_data)\nThese steps ensure that the data is converted into a tidy, filterable, and graph-compatible structure for community detection and interactive visualisation.\nThe core data transformation principles applied include:\n\nParsed JSON using tidygraph and igraph to build a directed graph structure from node-link format.\nMapped entity metadata to classify nodes into roles such as Person, Vessel, and Place.\nFiltered and simplified the graph, including removal of self-loops and edges with insignificant weights to retain only meaningful relationships.\nEnriched nodes with centrality metrics, particularly degree centrality, which is used for sizing and filtering nodes during visualisation.\n\n\n\n\n\nThis module employs a dual-pronged analytical strategy that combines community detection algorithms with exploratory network visualization. These techniques allow the investigator to detect tightly linked communication subgroups, potentially exposing pseudonym clusters or coordinated behavior among vessels and individuals.\n\n\nWe adopted two widely recognized algorithms for graph community detection:\n\nLouvain Community Detection: An unsupervised modularity-based approach that optimizes the partitioning of the graph into clusters. It is computationally efficient and ideal for detecting broad clusters in large-scale networks.\nWalktrap Community Detection: Uses short random walks to find densely connected subgraphs. It is suitable for identifying smaller, more cohesive communities and capturing subtle relational dynamics.\n\nBoth algorithms produce numeric cluster IDs for each node, which are then used for node coloring and group-based filtering in the visual layer.\n\n\n\nVisualisation is a central element in this prototype, serving both as an exploratory and explanatory tool. Two main techniques were employed:\n\nStatic Graphs using ggraph: These are helpful during the analytical phase for layout calibration, edge density verification, and debugging of network transformations.\nInteractive Graphs using visNetwork: These are deployed in the Shiny UI to support user-driven exploration. visNetwork provides pan, zoom, hover, and click functionality, which enhances pattern recognition and contextual analysis.\n\nColor schemes were intentionally chosen to reflect community membership (via cluster ID), and node sizing was mapped to degree centrality to emphasize influence or activity within the graph.\nAdditional enhancements include:\n\nHover tooltips to display entity type and communication degree\nLegend to distinguish nodes by category (Person, Vessel, Place)\nReactive filtering to isolate specific patterns of interest\nStatic Graphs: Using ggraph for initial exploration.\nInteractive Network: Leveraging visNetwork for drilldown, tooltips, and filtering.\n\n\n\n\n\nThis section emphasizes key prototyping principles outlined in the exercise brief:\n\nEvaluation of R Packages from CRAN: The prototype uses CRAN-supported packages such as shiny, visNetwork, tidygraph, ggraph, igraph, jsonlite, dplyr, and DT, all verified as stable and production-ready. This ensures compatibility and reduces technical risk when scaling the full Shiny application.\nValidation of Functional Code: All prototype components will be individually tested using RStudio. The pre-processing logic and community detection methods seek to ensure that it return correct outputs, and the visual network plot reacts dynamically to filtered inputs. Each Shiny UI input will be tied to a reactive server-side operation, tested both in isolation and in the Shiny runtime environment.\nDefinition of Inputs and Outputs: Inputs include dropdowns for algorithm selection, checkboxes for entity filtering, and sliders for edge weight thresholds. Outputs include an interactive visNetwork graph, node information text display, and (optionally) an exportable snapshot. This alignment ensures clarity for both developers and users.\nShiny UI Component Selection: Interface components are chosen to balance functionality and user experience:\n\nselectInput() offers a clear choice between Louvain and Walktrap algorithms.\ncheckboxGroupInput() allows entity-specific filtering for targeted analysis.\nsliderInput() provides intuitive numeric filtering for graph density.\nvisNetworkOutput() renders an interactive and scalable network layout.\nverbatimTextOutput() reveals node metadata for contextual interpretation.\n\n\nThese choices follow principles showcased in leading prototypes (e.g., Decoding Chaos and Tanzania Tourism), focusing on minimal cognitive load, fast responsiveness, and user-guided discovery.\nTo ensure clarity and usability, this module is designed using a storyboard-driven approach, inspired by best practices observed in exemplary prototype pages such as those from Decoding Chaos and Tanzania Tourism Analysis.\n\n\nDrawing inspiration from these references:\n\nUse incremental prototyping: starting with static exploration, then layering interactivity.\nImplement modular design: develop this as one self-contained component for integration into the larger app.\nInclude user-centered workflows: filters and actions modeled after investigative tasks (e.g., discovering who communicates frequently, identifying aliases).\n\n\n\n\n\nDefine User Goals: Support Clepper in uncovering clustered interactions and pseudonym aliases.\nStoryboard Sketching: Initial wireframes were drafted to conceptualize component layout — influenced by those in the Decoding Chaos storyboard page.\nComponent-Task Mapping: Every UI widget was explicitly mapped to a backend logic, ensuring traceability and transparency.\n\n\n\n\nTo inform the visual language and layout of the Shiny application, our team designed a prototype landing page comprising several interlinked interface sections. These visuals illustrate the envisioned user interface and serve as references for component development.\n\n\nThis mock-up establishes the visual identity and thematic branding for the dashboard. It reflects both the investigative tone of the VAST Challenge and our team’s creative approach. It includes a left navigation menu that guides users to each of the core question modules (Q1 to Q4), providing a consistent sidebar layout throughout the app.\n\n\n\n\n\nThis section visualizes message frequency over time to detect periodicity or anomalies. It includes:\n\nA dynamic bar chart summarizing total and average daily volume.\nInteractive dropdown and hover tooltips for contextual exploration.\n\nThis template serves as a reference for time-series visualizations to be integrated in future timeline-driven modules of the application.\n\n\n\n\nThis visual emphasizes network centrality and ego relationships. It includes:\n\nShapes and colors to differentiate entity types (e.g., vessel, organization, person).\nA drop-down filter to focus on individual entities.\n\nThis model informed the modular network layout used in our prototype for community and pseudonym analysis.\n\n\n\n\nThis low-fidelity layout demonstrates the foundational module structure:\n\nLeft panel: Parameter controls\nRight panel: Interactive graph and metadata display\n\nIt serves as the core layout pattern for the Shiny UI development, supporting Louvain/Walktrap switching, entity filters, and network interactivity.\n\n\n\n\n\nThe storyboard sketch and mock-ups reinforce a consistent modular layout adopted across the Shiny application. Each view uses a sidebar-main panel split, empowering users to choose algorithm types and entity filters on the left and observe dynamic network results on the right.\n\nSidebar: Control panel for selecting algorithm type, filtering entity type, and edge weight.\nMain Panel: Interactive network with dynamic tooltips, zoom/pan, and metadata inspection.\nTabbed Interface (optional): To toggle between community detection algorithms or show temporal comparisons.\nExport & Snapshot Option: Allow user to capture the view for reporting.\n\n\n\nBelow is a simplified Shiny layout using fluidPage() to map this structure:\n\n\nCode\n#|code-fold: False\n\nui &lt;- fluidPage(\n  titlePanel(\"Community Detection & Pseudonym Explorer\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"algo\", \"Community Detection Algorithm\", choices = c(\"Louvain\", \"Walktrap\")),\n      checkboxGroupInput(\"type\", \"Entity Types\", choices = c(\"Person\", \"Vessel\", \"Place\")),\n      sliderInput(\"weight\", \"Minimum Edge Weight\", min = 1, max = 10, value = 2)\n    ),\n    mainPanel(\n      visNetworkOutput(\"net\", height = \"600px\"),\n      verbatimTextOutput(\"info\")\n    )\n  )\n)\n\n\nThis structure ensures responsiveness, clarity, and user engagement. The design accommodates future expansion while maintaining a low learning curve. Screenshots from earlier dashboard questions, such as the bar chart in Q1A&B and the entity-focused network of Q1C, served as design blueprints to guide the final implementation.\n\n\n\n\nIn addition to interactive graph exploration, this Shiny application supports tabulated results presented using the DT package. This enhances user control and discoverability when inspecting detailed data outputs such as entity centrality, community membership, or alias metadata.\n\n\n\nUsing DT::datatable(), users can:\n\n🔍 Search and filter across any column\n🔼🔽 Sort by degree, cluster ID, type, or other attributes\n🎯 Focus on specific entities or pseudonyms from the wider graph output\n\n\n\n\n\nCode\nmainPanel(\n  DTOutput(\"result_table\")\n)\n\n\n\n\n\n\n\nCode\noutput$result_table &lt;- renderDT({\n  datatable(df_results,\n            options = list(\n              pageLength = 10,\n              autoWidth = TRUE,\n              searchHighlight = TRUE\n            ),\n            rownames = FALSE,\n            filter = \"top\",\n            class = 'stripe hover compact')\n})\n\n\nThis supports investigation workflows such as:\n\nListing top communicators by degree centrality\nExploring all known aliases and pseudonyms\nDisplaying communication volume by entity pairs\n\nBy embedding this alongside the network graph, the application delivers both relational context and tabulated drilldown capabilities, bridging visual insight with attribute-level data access.\n\n\n\n\n\n\n\nUI Component\nPurpose\n\n\n\n\nselectInput(\"algo\")\nChoose detection algorithm (Louvain/Walktrap)\n\n\ncheckboxGroupInput(\"type\")\nFilter node types (person, vessel, place)\n\n\nsliderInput(\"weight\")\nFilter connections below weight threshold\n\n\nvisNetworkOutput(\"net\")\nDisplay interactive graph\n\n\nverbatimTextOutput(\"info\")\nNode metadata panel\n\n\n\nDesign Learnings from References\n\nTanzania Tourism emphasized clarity in visual transitions and guided storytelling.\nDecoding Chaos used a modular dashboard and strong use of aspatial/geospatial splits — we aim to mirror this by making this module fully pluggable.\nConfirmatory Analysis example showed the benefit of toggling between analytical models — we aim to adopt this in Louvain vs. Walktrap switch.\n\n\n\n\n\n\nTo make the Shiny application more engaging and insightful, we expand beyond core filters and outputs to include a wider array of interactive features.\n\n\n\n\n\n\n\n\n\nInput Control\nDescription\n\n\nselectInput(\"algo\")\nCommunity detection method selector (Louvain or Walktrap)\n\n\ncheckboxGroupInput(\"type\")\nEntity type filter (Person, Vessel, Place)\n\n\nsliderInput(\"weight\")\nMinimum edge weight threshold to reduce noise\n\n\nselectInput(\"focus_entity\")\nFocus on a particular entity (e.g., Nadia Conti) to show ego network\n\n\ncheckboxInput(\"highlight_alias\")\nToggle to highlight entities suspected of pseudonym usage\n\n\ndateRangeInput(\"comm_range\")\nSelect time window to filter communication edges\n\n\nselectInput(\"cluster_id\")\nFilter or highlight a specific cluster based on detection algorithm\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput Component\nDescription\n\n\nvisNetworkOutput(\"net\")\nInteractive network showing colored clusters and filtered edges\n\n\nverbatimTextOutput(\"info\")\nMetadata of selected node (e.g., name, type, degree)\n\n\nplotOutput(\"timeline_plot\")\nCommunication volume over time (to be integrated)\n\n\nDTOutput(\"result_table\")\nTabular view of nodes or edges with filtering and sorting features\n\n\ndownloadButton(\"export_plot\")\nExport current network view as image or snapshot\n\n\ntextOutput(\"cluster_summary\")\nSummary statistics for selected community cluster\n\n\n\n\n\n\n\nDrill-down via double-click: Expand a node to show direct neighbors\nBrushing and linking: Select nodes from network to highlight rows in table\nDynamic color mapping: Toggle between cluster ID, entity type, or degree centrality as node color basis\nTopic integration: Add top-communicated keywords per cluster in hover tooltip or side display\nAlias grouping: Visually link nodes suspected to share the same pseudonym\n\nThese enhancements not only add usability and depth, but also align tightly with the investigative workflow Clepper is likely to pursue — identifying leads, tracking influence, and exposing deceptive practices over time.\n\n\n\n\nCommunity detection algorithm\nEntity type filter\nWeight threshold\n\n\n\n\n\nNetwork plot (interactive, color-coded clusters)\nNode metadata when clicked\nExportable graph snapshot (optional)\n\n\n\n\n\n\n\nCode\n# Community Detection\ngraph_louvain &lt;- graph_data %&gt;% \n  mutate(community = group_louvain())\n\n# Interactive Plot\noutput$net &lt;- renderVisNetwork({\n  filtered &lt;- graph_louvain %&gt;% activate(edges) %&gt;% filter(weight &gt;= input$weight)\n  visNetwork(filtered)\n})\n\n\n\n\n\nThis Take-home 3 prototype marks a successful first implementation of a modular Shiny component tailored for investigative visual analytics. It showcases the power of combining community detection algorithms, interactive network diagrams, and dynamic filtering interfaces to surface hidden communication patterns and pseudonym dynamics in a complex dataset.\nKey strengths of this prototype include:\n\nA tested and extensible data pipeline for converting JSON-based knowledge graphs into tidygraph objects\nWell-integrated community detection logic (Louvain and Walktrap)\nA modular and visually consistent user interface grounded in investigative needs\nEffective alignment between network visualisation and tabular insight via linked interactivity\n\nThis prototype also reflects lessons learned from top-performing prior projects (e.g., Decoding Chaos, Tanzania Tourism) in terms of storyboarding, modular UI planning, and interaction design.\n\n\nTo scale this prototype into a full-featured module within the final application, the following development goals are recommended:\n\nIntegrate Timeline Filtering: Allow communication edges to be filtered by date range using dateRangeInput().\nImplement Pseudonym Disambiguation: Build logic to identify and visually cluster suspected pseudonym aliases across multiple entities.\nTopic Enrichment: Associate dominant message themes with detected communities using keyword extraction or topic modeling.\nBrushing & Linking: Enable node selections in the network to highlight related records in the tabular view, enhancing discoverability.\nGeospatial Integration: Add optional map-based view to connect network dynamics to spatial context (if vessel coordinates or harbor data is available).\nScenario Testing: Validate with real investigative use cases by simulating Clepper Jessen’s workflow end-to-end.\n\nWith these enhancements, the application can evolve into a powerful and intuitive investigative platform — revealing who is connected, how they communicate, and which identities may be intentionally obscured."
  },
  {
    "objectID": "project_proposal/project_proposal.html#the-task",
    "href": "project_proposal/project_proposal.html#the-task",
    "title": "Project Proposal",
    "section": "",
    "text": "In this take-home exercise, you are required to select one of the module of your proposed Shiny application and complete the following tasks:\n\nTo evaluate and determine the necessary R packages needed for your Shiny application are supported in R CRAN,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determine above."
  },
  {
    "objectID": "project_proposal/project_proposal.html#introduction",
    "href": "project_proposal/project_proposal.html#introduction",
    "title": "Project Proposal",
    "section": "",
    "text": "This prototype module is part of a larger visual analytics application for Mini-Challenge 3 (VAST Challenge 2025). It supports investigative journalist Clepper Jessen in uncovering hidden relationships and pseudonymous communication patterns within the radio transcript dataset of Oceanus.\nThe goal of this prototype is to storyboard and test a modular component that will eventually be integrated into the full Shiny application. The focus is on community detection and interactive pseudonym analysis, providing users with the ability to dynamically explore clusters of entities based on radio communication activity.\nThis document outlines the prototyping process, from data wrangling and method selection, to interactive interface design using Shiny components. The storyboard describes how different visual and interactive elements will work together to support investigative insights."
  },
  {
    "objectID": "project_proposal/project_proposal.html#data-preparation",
    "href": "project_proposal/project_proposal.html#data-preparation",
    "title": "Project Proposal",
    "section": "",
    "text": "The source data is a knowledge graph in JSON format (MC3_graph.json) provided in the VAST Challenge 2025 Mini-Challenge 3. It consists of two primary components:\n\nNodes: Representing entities such as persons, vessels, places, and roles, each with metadata such as labels and types.\nEdges: Representing communications between nodes with attributes such as sender, receiver, channel, date-time, and message weight.\n\n\n\nThe following R packages were used for data wrangling:\n\n\nCode\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(jsonlite)\nlibrary(dplyr)\n\n\nThe steps to prepare the data are as follows:\nStep 1: Load and Parse the JSON File\n# Load the knowledge graph json_graph &lt;- jsonlite::read_json(\"data/MC3_graph.json\")\nStep 2: Extract and Structure Nodes and Edges\n# Convert to tibble format nodes_tbl &lt;- as_tibble(json_graph$nodes) edges_tbl &lt;- as_tibble(json_graph$links)  # Rename and structure columns for compatibility nodes_tbl &lt;- nodes_tbl %&gt;% rename(id = id, label = name, type = entity_type) edges_tbl &lt;- edges_tbl %&gt;% rename(from = source, to = target)\nStep 3: Convert to a Tidygraph Object\ngraph_data &lt;- tbl_graph(nodes = nodes_tbl, edges = edges_tbl, directed = TRUE)\nStep 4: Clean and Enrich the Graph\n# Filter out edges with low weights or irrelevant connections (e.g., self-loops) graph_data &lt;- graph_data %&gt;%    activate(edges) %&gt;%    filter(!is.na(from), !is.na(to)) %&gt;%    filter(weight &gt; 1) %&gt;%    activate(nodes) %&gt;%    mutate(degree = centrality_degree())\nStep 5: Verify Graph Summary\nsummary(graph_data)\nThese steps ensure that the data is converted into a tidy, filterable, and graph-compatible structure for community detection and interactive visualisation.\nThe core data transformation principles applied include:\n\nParsed JSON using tidygraph and igraph to build a directed graph structure from node-link format.\nMapped entity metadata to classify nodes into roles such as Person, Vessel, and Place.\nFiltered and simplified the graph, including removal of self-loops and edges with insignificant weights to retain only meaningful relationships.\nEnriched nodes with centrality metrics, particularly degree centrality, which is used for sizing and filtering nodes during visualisation."
  },
  {
    "objectID": "project_proposal/project_proposal.html#analytical-and-visualisation-techniques",
    "href": "project_proposal/project_proposal.html#analytical-and-visualisation-techniques",
    "title": "Project Proposal",
    "section": "",
    "text": "This module employs a dual-pronged analytical strategy that combines community detection algorithms with exploratory network visualization. These techniques allow the investigator to detect tightly linked communication subgroups, potentially exposing pseudonym clusters or coordinated behavior among vessels and individuals.\n\n\nWe adopted two widely recognized algorithms for graph community detection:\n\nLouvain Community Detection: An unsupervised modularity-based approach that optimizes the partitioning of the graph into clusters. It is computationally efficient and ideal for detecting broad clusters in large-scale networks.\nWalktrap Community Detection: Uses short random walks to find densely connected subgraphs. It is suitable for identifying smaller, more cohesive communities and capturing subtle relational dynamics.\n\nBoth algorithms produce numeric cluster IDs for each node, which are then used for node coloring and group-based filtering in the visual layer.\n\n\n\nVisualisation is a central element in this prototype, serving both as an exploratory and explanatory tool. Two main techniques were employed:\n\nStatic Graphs using ggraph: These are helpful during the analytical phase for layout calibration, edge density verification, and debugging of network transformations.\nInteractive Graphs using visNetwork: These are deployed in the Shiny UI to support user-driven exploration. visNetwork provides pan, zoom, hover, and click functionality, which enhances pattern recognition and contextual analysis.\n\nColor schemes were intentionally chosen to reflect community membership (via cluster ID), and node sizing was mapped to degree centrality to emphasize influence or activity within the graph.\nAdditional enhancements include:\n\nHover tooltips to display entity type and communication degree\nLegend to distinguish nodes by category (Person, Vessel, Place)\nReactive filtering to isolate specific patterns of interest\nStatic Graphs: Using ggraph for initial exploration.\nInteractive Network: Leveraging visNetwork for drilldown, tooltips, and filtering."
  },
  {
    "objectID": "project_proposal/project_proposal.html#ui-design-prototyping-storyboarding",
    "href": "project_proposal/project_proposal.html#ui-design-prototyping-storyboarding",
    "title": "Project Proposal",
    "section": "",
    "text": "This section emphasizes key prototyping principles outlined in the exercise brief:\n\nEvaluation of R Packages from CRAN: The prototype uses CRAN-supported packages such as shiny, visNetwork, tidygraph, ggraph, igraph, jsonlite, dplyr, and DT, all verified as stable and production-ready. This ensures compatibility and reduces technical risk when scaling the full Shiny application.\nValidation of Functional Code: All prototype components will be individually tested using RStudio. The pre-processing logic and community detection methods seek to ensure that it return correct outputs, and the visual network plot reacts dynamically to filtered inputs. Each Shiny UI input will be tied to a reactive server-side operation, tested both in isolation and in the Shiny runtime environment.\nDefinition of Inputs and Outputs: Inputs include dropdowns for algorithm selection, checkboxes for entity filtering, and sliders for edge weight thresholds. Outputs include an interactive visNetwork graph, node information text display, and (optionally) an exportable snapshot. This alignment ensures clarity for both developers and users.\nShiny UI Component Selection: Interface components are chosen to balance functionality and user experience:\n\nselectInput() offers a clear choice between Louvain and Walktrap algorithms.\ncheckboxGroupInput() allows entity-specific filtering for targeted analysis.\nsliderInput() provides intuitive numeric filtering for graph density.\nvisNetworkOutput() renders an interactive and scalable network layout.\nverbatimTextOutput() reveals node metadata for contextual interpretation.\n\n\nThese choices follow principles showcased in leading prototypes (e.g., Decoding Chaos and Tanzania Tourism), focusing on minimal cognitive load, fast responsiveness, and user-guided discovery.\nTo ensure clarity and usability, this module is designed using a storyboard-driven approach, inspired by best practices observed in exemplary prototype pages such as those from Decoding Chaos and Tanzania Tourism Analysis.\n\n\nDrawing inspiration from these references:\n\nUse incremental prototyping: starting with static exploration, then layering interactivity.\nImplement modular design: develop this as one self-contained component for integration into the larger app.\nInclude user-centered workflows: filters and actions modeled after investigative tasks (e.g., discovering who communicates frequently, identifying aliases).\n\n\n\n\n\nDefine User Goals: Support Clepper in uncovering clustered interactions and pseudonym aliases.\nStoryboard Sketching: Initial wireframes were drafted to conceptualize component layout — influenced by those in the Decoding Chaos storyboard page.\nComponent-Task Mapping: Every UI widget was explicitly mapped to a backend logic, ensuring traceability and transparency.\n\n\n\n\nTo inform the visual language and layout of the Shiny application, our team designed a prototype landing page comprising several interlinked interface sections. These visuals illustrate the envisioned user interface and serve as references for component development.\n\n\nThis mock-up establishes the visual identity and thematic branding for the dashboard. It reflects both the investigative tone of the VAST Challenge and our team’s creative approach. It includes a left navigation menu that guides users to each of the core question modules (Q1 to Q4), providing a consistent sidebar layout throughout the app.\n\n\n\n\n\nThis section visualizes message frequency over time to detect periodicity or anomalies. It includes:\n\nA dynamic bar chart summarizing total and average daily volume.\nInteractive dropdown and hover tooltips for contextual exploration.\n\nThis template serves as a reference for time-series visualizations to be integrated in future timeline-driven modules of the application.\n\n\n\n\nThis visual emphasizes network centrality and ego relationships. It includes:\n\nShapes and colors to differentiate entity types (e.g., vessel, organization, person).\nA drop-down filter to focus on individual entities.\n\nThis model informed the modular network layout used in our prototype for community and pseudonym analysis.\n\n\n\n\nThis low-fidelity layout demonstrates the foundational module structure:\n\nLeft panel: Parameter controls\nRight panel: Interactive graph and metadata display\n\nIt serves as the core layout pattern for the Shiny UI development, supporting Louvain/Walktrap switching, entity filters, and network interactivity.\n\n\n\n\n\nThe storyboard sketch and mock-ups reinforce a consistent modular layout adopted across the Shiny application. Each view uses a sidebar-main panel split, empowering users to choose algorithm types and entity filters on the left and observe dynamic network results on the right.\n\nSidebar: Control panel for selecting algorithm type, filtering entity type, and edge weight.\nMain Panel: Interactive network with dynamic tooltips, zoom/pan, and metadata inspection.\nTabbed Interface (optional): To toggle between community detection algorithms or show temporal comparisons.\nExport & Snapshot Option: Allow user to capture the view for reporting.\n\n\n\nBelow is a simplified Shiny layout using fluidPage() to map this structure:\n\n\nCode\n#|code-fold: False\n\nui &lt;- fluidPage(\n  titlePanel(\"Community Detection & Pseudonym Explorer\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"algo\", \"Community Detection Algorithm\", choices = c(\"Louvain\", \"Walktrap\")),\n      checkboxGroupInput(\"type\", \"Entity Types\", choices = c(\"Person\", \"Vessel\", \"Place\")),\n      sliderInput(\"weight\", \"Minimum Edge Weight\", min = 1, max = 10, value = 2)\n    ),\n    mainPanel(\n      visNetworkOutput(\"net\", height = \"600px\"),\n      verbatimTextOutput(\"info\")\n    )\n  )\n)\n\n\nThis structure ensures responsiveness, clarity, and user engagement. The design accommodates future expansion while maintaining a low learning curve. Screenshots from earlier dashboard questions, such as the bar chart in Q1A&B and the entity-focused network of Q1C, served as design blueprints to guide the final implementation.\n\n\n\n\nIn addition to interactive graph exploration, this Shiny application supports tabulated results presented using the DT package. This enhances user control and discoverability when inspecting detailed data outputs such as entity centrality, community membership, or alias metadata.\n\n\n\nUsing DT::datatable(), users can:\n\n🔍 Search and filter across any column\n🔼🔽 Sort by degree, cluster ID, type, or other attributes\n🎯 Focus on specific entities or pseudonyms from the wider graph output\n\n\n\n\n\nCode\nmainPanel(\n  DTOutput(\"result_table\")\n)\n\n\n\n\n\n\n\nCode\noutput$result_table &lt;- renderDT({\n  datatable(df_results,\n            options = list(\n              pageLength = 10,\n              autoWidth = TRUE,\n              searchHighlight = TRUE\n            ),\n            rownames = FALSE,\n            filter = \"top\",\n            class = 'stripe hover compact')\n})\n\n\nThis supports investigation workflows such as:\n\nListing top communicators by degree centrality\nExploring all known aliases and pseudonyms\nDisplaying communication volume by entity pairs\n\nBy embedding this alongside the network graph, the application delivers both relational context and tabulated drilldown capabilities, bridging visual insight with attribute-level data access.\n\n\n\n\n\n\n\nUI Component\nPurpose\n\n\n\n\nselectInput(\"algo\")\nChoose detection algorithm (Louvain/Walktrap)\n\n\ncheckboxGroupInput(\"type\")\nFilter node types (person, vessel, place)\n\n\nsliderInput(\"weight\")\nFilter connections below weight threshold\n\n\nvisNetworkOutput(\"net\")\nDisplay interactive graph\n\n\nverbatimTextOutput(\"info\")\nNode metadata panel\n\n\n\nDesign Learnings from References\n\nTanzania Tourism emphasized clarity in visual transitions and guided storytelling.\nDecoding Chaos used a modular dashboard and strong use of aspatial/geospatial splits — we aim to mirror this by making this module fully pluggable.\nConfirmatory Analysis example showed the benefit of toggling between analytical models — we aim to adopt this in Louvain vs. Walktrap switch."
  },
  {
    "objectID": "project_proposal/project_proposal.html#parameters-and-outputs",
    "href": "project_proposal/project_proposal.html#parameters-and-outputs",
    "title": "Project Proposal",
    "section": "",
    "text": "To make the Shiny application more engaging and insightful, we expand beyond core filters and outputs to include a wider array of interactive features.\n\n\n\n\n\n\n\n\n\nInput Control\nDescription\n\n\nselectInput(\"algo\")\nCommunity detection method selector (Louvain or Walktrap)\n\n\ncheckboxGroupInput(\"type\")\nEntity type filter (Person, Vessel, Place)\n\n\nsliderInput(\"weight\")\nMinimum edge weight threshold to reduce noise\n\n\nselectInput(\"focus_entity\")\nFocus on a particular entity (e.g., Nadia Conti) to show ego network\n\n\ncheckboxInput(\"highlight_alias\")\nToggle to highlight entities suspected of pseudonym usage\n\n\ndateRangeInput(\"comm_range\")\nSelect time window to filter communication edges\n\n\nselectInput(\"cluster_id\")\nFilter or highlight a specific cluster based on detection algorithm\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput Component\nDescription\n\n\nvisNetworkOutput(\"net\")\nInteractive network showing colored clusters and filtered edges\n\n\nverbatimTextOutput(\"info\")\nMetadata of selected node (e.g., name, type, degree)\n\n\nplotOutput(\"timeline_plot\")\nCommunication volume over time (to be integrated)\n\n\nDTOutput(\"result_table\")\nTabular view of nodes or edges with filtering and sorting features\n\n\ndownloadButton(\"export_plot\")\nExport current network view as image or snapshot\n\n\ntextOutput(\"cluster_summary\")\nSummary statistics for selected community cluster\n\n\n\n\n\n\n\nDrill-down via double-click: Expand a node to show direct neighbors\nBrushing and linking: Select nodes from network to highlight rows in table\nDynamic color mapping: Toggle between cluster ID, entity type, or degree centrality as node color basis\nTopic integration: Add top-communicated keywords per cluster in hover tooltip or side display\nAlias grouping: Visually link nodes suspected to share the same pseudonym\n\nThese enhancements not only add usability and depth, but also align tightly with the investigative workflow Clepper is likely to pursue — identifying leads, tracking influence, and exposing deceptive practices over time.\n\n\n\n\nCommunity detection algorithm\nEntity type filter\nWeight threshold\n\n\n\n\n\nNetwork plot (interactive, color-coded clusters)\nNode metadata when clicked\nExportable graph snapshot (optional)"
  },
  {
    "objectID": "project_proposal/project_proposal.html#prototype-code-snippets",
    "href": "project_proposal/project_proposal.html#prototype-code-snippets",
    "title": "Project Proposal",
    "section": "",
    "text": "Code\n# Community Detection\ngraph_louvain &lt;- graph_data %&gt;% \n  mutate(community = group_louvain())\n\n# Interactive Plot\noutput$net &lt;- renderVisNetwork({\n  filtered &lt;- graph_louvain %&gt;% activate(edges) %&gt;% filter(weight &gt;= input$weight)\n  visNetwork(filtered)\n})"
  },
  {
    "objectID": "project_proposal/project_proposal.html#reflections-and-next-steps",
    "href": "project_proposal/project_proposal.html#reflections-and-next-steps",
    "title": "Project Proposal",
    "section": "",
    "text": "This Take-home 3 prototype marks a successful first implementation of a modular Shiny component tailored for investigative visual analytics. It showcases the power of combining community detection algorithms, interactive network diagrams, and dynamic filtering interfaces to surface hidden communication patterns and pseudonym dynamics in a complex dataset.\nKey strengths of this prototype include:\n\nA tested and extensible data pipeline for converting JSON-based knowledge graphs into tidygraph objects\nWell-integrated community detection logic (Louvain and Walktrap)\nA modular and visually consistent user interface grounded in investigative needs\nEffective alignment between network visualisation and tabular insight via linked interactivity\n\nThis prototype also reflects lessons learned from top-performing prior projects (e.g., Decoding Chaos, Tanzania Tourism) in terms of storyboarding, modular UI planning, and interaction design.\n\n\nTo scale this prototype into a full-featured module within the final application, the following development goals are recommended:\n\nIntegrate Timeline Filtering: Allow communication edges to be filtered by date range using dateRangeInput().\nImplement Pseudonym Disambiguation: Build logic to identify and visually cluster suspected pseudonym aliases across multiple entities.\nTopic Enrichment: Associate dominant message themes with detected communities using keyword extraction or topic modeling.\nBrushing & Linking: Enable node selections in the network to highlight related records in the tabular view, enhancing discoverability.\nGeospatial Integration: Add optional map-based view to connect network dynamics to spatial context (if vessel coordinates or harbor data is available).\nScenario Testing: Validate with real investigative use cases by simulating Clepper Jessen’s workflow end-to-end.\n\nWith these enhancements, the application can evolve into a powerful and intuitive investigative platform — revealing who is connected, how they communicate, and which identities may be intentionally obscured."
  },
  {
    "objectID": "Mtg_Minutes/Meeting02.html",
    "href": "Mtg_Minutes/Meeting02.html",
    "title": "Minutes 2",
    "section": "",
    "text": "Meeting Minutes 2"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html",
    "href": "main_project_qmd/main_project_qmd/main_DC.html",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "",
    "text": "This take home exercise is based on the VAST Challenge Mini Case 3\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jessen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation.\nYour task is to develop new and novel visualizations and visual analytics approaches to help Clepper get to the bottom of this story"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#initial-eda",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#initial-eda",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "3.1 Initial EDA",
    "text": "3.1 Initial EDA\n\n\nShow code\nExpCatViz(data=mc3_nodes,\n          col=\"pink\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#relationship-between-entities-and-events",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#relationship-between-entities-and-events",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.1 Relationship between entities and events",
    "text": "6.1 Relationship between entities and events\n\n\nShow code\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 2) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#entity-distribution",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#entity-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.2 Entity distribution",
    "text": "6.2 Entity distribution\n\n\nShow code\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#event-type-distribution",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#event-type-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.3 Event type distribution",
    "text": "6.3 Event type distribution\n\n\nShow code\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#list-of-communication-participants",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#list-of-communication-participants",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4 List of communication participants",
    "text": "6.4 List of communication participants\n\n\nShow code\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#visualization-of-communication-participants-network",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#visualization-of-communication-participants-network",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4.1 Visualization of communication participants network",
    "text": "6.4.1 Visualization of communication participants network\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-1a-and-1b",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-1a-and-1b",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 1a and 1b",
    "text": "VAST Challenge Task & Question 1a and 1b\nClepper found that messages frequently came in at around the same time each day.\n\nDevelop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\nHow do these patterns shift over the two weeks of observations?\n\nObjective\n\nIdentify when communications happen most often during each day.\nDetect shifts in these patterns over the 2-week period.\nLater: Focus on a specific entity (e.g., Nadia Conti) and explore who influences them.\n\n\nStep 1: Extract & Parse Communication Event Timestamps\nExtract the Communication Timestamps from mc3_nodes_final and filter for communication events.\n\n\nShow code\n# Filter for Communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n\n\nParse the Communication Timestamp into the format “dd/mm/yyy (ddd)” for ease of reference.\n\n\nShow code\n# Communication events with parsed date and time\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n\n\n\n\nStep 2: Visualize the Communication Volume for Analysis\n\n2.1 - Bar Plot of daily communication volume over the 2 weeks period:\n\n\nShow code\n# Step 1: Prepare daily message volume data\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count &lt;- mean(daily_message_volume$message_count)\ntotal_msg_count &lt;- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n2.2 - Interactive Table of daily communication volume variation(message count)\n\n\nShow code\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %&gt;% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\n2.3a - Heat Map of hourly message volume for each day over the 2 weeks period:\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count\n\n\nShow code\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender–receiver–timestamp structure\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender–receiver–timestamp\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(sender_id = id, sender_label = label), by = \"sender_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, hour) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;⏰ Hour: \", sprintf(\"%02d:00\", hour),\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np &lt;- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nWe will increase the resolution to half-hour time slots.\n\n\n2.4b - Heat Map of half-hourly message volume for each day over the 2 weeks period:\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count.\n\n\nShow code\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)  # ✅ fixed receiver_id\n\n# Step 2: Reconstruct sender–receiver–event linkage\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, time_bin, time_label) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;🕒 Time: \", time_label,\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np &lt;- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n2.4c - Density plot of Daily half-hourly message volume over the 2 weeks period:\nThe faceted density plot that shows the distribution of communication events by time of day, broken down for each day in the dataset. It helps to visually detect temporal communication patterns, intensity, and consistency over multiple days.\n\nOverview of the 2 week periodDay 1 - 01/10/2040Day 2 - 02/10/2040Day 3 - 03/10/2040Day 4 - 04/10/2040Day 5 - 05/10/2040Day 6 - 06/10/2040Day 7 - 07/10/2040Day 8 - 08/10/2040Day 9 - 09/10/2040Day 10 - 10/10/2040Day 11 - 11/10/2040Day 12 - 12/10/2040Day 13 - 13/10/2040Day 14 - 14/10/2040\n\n\n\n\nShow code\n# Step 1: Preprocess communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats &lt;- comm_events %&gt;%\n  group_by(date_label) %&gt;%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n📈 Insights This Visualization Offers\n\n\n\nStep 3: Plot Combined Hourly and Half-hourly Communication Volume\nBar Plot of combined hourly message volume over the 2 weeks period:\n\n\nShow code\n# Prepare data\ncomm_hourly &lt;- comm_events %&gt;%\n  count(hour) %&gt;%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nBar Plot of combined half-hourly message volume in the 2 weeks period.\n\n\nShow code\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute &lt; 30, 0, 30))\n  )\n\ncomm_halfhour &lt;- comm_events %&gt;%\n  count(time_bin) %&gt;%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1a. What are the identifiable daily temporal patterns in communications?\n\n\n\n\nThe daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)—a sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\nThe temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\nFor instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends—communication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n\n\n\n\n\n\n\n\n\n1b. How do these patterns shift over the two weeks of observations?\n\n\n\n\nOver the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of “surge” (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation—an analytical signal that warrants closer inspection of event logs or external triggers for those dates.\nAnother notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule—potentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-1c",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-1c",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 1c",
    "text": "VAST Challenge Task & Question 1c\nClepper found that messages frequently came in at around the same time each day.\n\nFocus on a specific entity and use this information to determine who has influence over them.\n\n\n3.1 - Data Preparation for “Nadia Conti” Influence Analysis\nWe first extracted the relevant communication edges from the dataset, pairing “sent” and “received” communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\nShow code\n# Extract sent and received communication event edges\nsent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges &lt;- sent_edges %&gt;%\n  inner_join(received_edges, by = \"event\") %&gt;%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges &lt;- sent_edges %&gt;%\n  select(from = source_entity, to = event)\nsingle_received_edges &lt;- received_edges %&gt;%\n  select(from = event, to = target_entity)\n\nall_edges &lt;- bind_rows(paired_edges, single_sent_edges, single_received_edges) %&gt;%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  pull(id) %&gt;% as.character()\n\nentity_edges &lt;- all_edges %&gt;%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  select(id, label, sub_type)\n\n\n\n\n3.2 - Build the Global Network and Compute Centrality\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node—PageRank, betweenness, and degree—quantifying the influence and connectivity of every entity in the overall network.\n\n\nShow code\nlibrary(igraph)\n\ng &lt;- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank &lt;- page_rank(g)$vector\nV(g)$betweenness &lt;- betweenness(g)\nV(g)$degree &lt;- degree(g)\n\n\n\n\n3.3 - Extract “Nadia Conti” Ego Network (2-hop Neighbourhood)\nFocusing on “Nadia Conti”, we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia’s immediate sphere of influence and the key players connected to her.\n\n\nShow code\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\nego_graph &lt;- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n\n\n\n\n3.4 - Visualize Nadia Conti’s Ego Network (Interactive)\nWe visualized Nadia’s ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti’s communication environment.\n\n\nShow code\nnodes_df &lt;- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_graph)$label, \"&lt;/b&gt;&lt;br&gt;\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"&lt;br&gt;\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"&lt;br&gt;\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df &lt;- as_data_frame(ego_graph, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %&gt;%\n  visNodes(scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %&gt;%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#global-and-ego-network-structure",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#global-and-ego-network-structure",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Global and Ego-Network Structure",
    "text": "Global and Ego-Network Structure\nThe overview network visualization reveals that Nadia Conti is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia’s influence neighborhood.\n\n3.5 - Centrality Tables for Nadia’s Ego Network\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\nPageRank (overall influence),\nBetweenness (information brokerage/intermediary role), and\nDegree (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\nShow code\n# PageRank table\npagerank_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %&gt;% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %&gt;% arrange(desc(betweenness))\n\n# Degree table\ndegree_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %&gt;% arrange(desc(degree))\n\n\n\n\nShow code\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n\n\n\nPageRank Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\npagerank\n\n\n\n\nMako\nVessel\n0.0687\n\n\nOceanus City Council\nOrganization\n0.0530\n\n\nReef Guardian\nVessel\n0.0454\n\n\nNadia Conti\nPerson\n0.0432\n\n\nRemora\nVessel\n0.0409\n\n\nV. Miesel Shipping\nOrganization\n0.0394\n\n\nNeptune\nVessel\n0.0358\n\n\nHimark Harbor\nLocation\n0.0358\n\n\nLiam Thorne\nPerson\n0.0275\n\n\nBoss\nPerson\n0.0272\n\n\nSentinel\nVessel\n0.0250\n\n\nPaackland Harbor\nLocation\n0.0244\n\n\nDavis\nPerson\n0.0239\n\n\nMarlin\nVessel\n0.0235\n\n\nEcoVigil\nVessel\n0.0233\n\n\nGreen Guardians\nOrganization\n0.0224\n\n\nMrs. Money\nPerson\n0.0192\n\n\nSailor Shifts Team\nOrganization\n0.0186\n\n\nSeawatch\nVessel\n0.0186\n\n\nElise\nPerson\n0.0182\n\n\nSerenity\nVessel\n0.0170\n\n\nHorizon\nVessel\n0.0152\n\n\nThe Middleman\nPerson\n0.0142\n\n\nNorthern Light\nVessel\n0.0135\n\n\nRodriguez\nPerson\n0.0122\n\n\nSamantha Blake\nPerson\n0.0114\n\n\nHaacklee Harbor\nLocation\n0.0111\n\n\nOsprey\nVessel\n0.0088\n\n\nCity Officials\nGroup\n0.0066\n\n\nThe Lookout\nPerson\n0.0062\n\n\nKnowles\nVessel\n0.0051\n\n\nSmall Fry\nPerson\n0.0035\n\n\nGlitters Team\nOrganization\n0.0035\n\n\n\n\n\n\n\nShow code\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n\n\n\nBetweenness Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\nbetweenness\n\n\n\n\nMako\nVessel\n368.50\n\n\nMrs. Money\nPerson\n167.18\n\n\nReef Guardian\nVessel\n139.69\n\n\nBoss\nPerson\n136.18\n\n\nV. Miesel Shipping\nOrganization\n118.70\n\n\nNadia Conti\nPerson\n117.87\n\n\nOceanus City Council\nOrganization\n116.11\n\n\nRemora\nVessel\n90.45\n\n\nNeptune\nVessel\n82.59\n\n\nThe Lookout\nPerson\n80.51\n\n\nHimark Harbor\nLocation\n52.61\n\n\nThe Middleman\nPerson\n50.78\n\n\nLiam Thorne\nPerson\n41.81\n\n\nHaacklee Harbor\nLocation\n41.30\n\n\nSentinel\nVessel\n34.54\n\n\nGreen Guardians\nOrganization\n27.51\n\n\nPaackland Harbor\nLocation\n27.08\n\n\nDavis\nPerson\n22.36\n\n\nEcoVigil\nVessel\n12.63\n\n\nRodriguez\nPerson\n11.75\n\n\nNorthern Light\nVessel\n9.76\n\n\nSailor Shifts Team\nOrganization\n7.34\n\n\nHorizon\nVessel\n6.72\n\n\nMarlin\nVessel\n6.23\n\n\nSeawatch\nVessel\n5.20\n\n\nElise\nPerson\n4.60\n\n\nSamantha Blake\nPerson\n4.49\n\n\nSerenity\nVessel\n0.81\n\n\nKnowles\nVessel\n0.50\n\n\nSmall Fry\nPerson\n0.00\n\n\nGlitters Team\nOrganization\n0.00\n\n\nOsprey\nVessel\n0.00\n\n\nCity Officials\nGroup\n0.00\n\n\n\n\n\n\n\nShow code\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n\n\n\nDegree Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\ndegree\n\n\n\n\nMako\nVessel\n37\n\n\nOceanus City Council\nOrganization\n28\n\n\nReef Guardian\nVessel\n27\n\n\nRemora\nVessel\n21\n\n\nV. Miesel Shipping\nOrganization\n19\n\n\nNeptune\nVessel\n19\n\n\nNadia Conti\nPerson\n17\n\n\nGreen Guardians\nOrganization\n17\n\n\nHimark Harbor\nLocation\n17\n\n\nDavis\nPerson\n16\n\n\nSentinel\nVessel\n16\n\n\nBoss\nPerson\n13\n\n\nEcoVigil\nVessel\n13\n\n\nPaackland Harbor\nLocation\n13\n\n\nMrs. Money\nPerson\n12\n\n\nHorizon\nVessel\n12\n\n\nLiam Thorne\nPerson\n11\n\n\nRodriguez\nPerson\n10\n\n\nMarlin\nVessel\n10\n\n\nSeawatch\nVessel\n9\n\n\nThe Middleman\nPerson\n8\n\n\nSerenity\nVessel\n8\n\n\nNorthern Light\nVessel\n8\n\n\nHaacklee Harbor\nLocation\n8\n\n\nElise\nPerson\n7\n\n\nThe Lookout\nPerson\n7\n\n\nSailor Shifts Team\nOrganization\n7\n\n\nSamantha Blake\nPerson\n6\n\n\nGlitters Team\nOrganization\n4\n\n\nKnowles\nVessel\n4\n\n\nSmall Fry\nPerson\n3\n\n\nOsprey\nVessel\n3\n\n\nCity Officials\nGroup\n1"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#centrality-metrics-and-direct-indirect-influences",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#centrality-metrics-and-direct-indirect-influences",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Centrality Metrics and Direct & Indirect Influences",
    "text": "Centrality Metrics and Direct & Indirect Influences\nBy calculating centrality metrics within Nadia’s two-hop ego network, we observe that the most influential nodes in her environment—by PageRank, betweenness, and degree—are Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia’s information flow and access to other parts of the network.\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n\n3.5.1 - PageRank for Nadia Conti\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng &lt;- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 &lt;- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank &lt;- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df &lt;- as_data_frame(ego_1, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n3.5.2 - Betweenness for Nadia Conti\n\n\nShow code\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness &lt;- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n3.5.3 - Degree for Nadia Conti\n\n\nShow code\n# 1. Compute Degree for the ego network\nV(ego_1)$degree &lt;- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n1c. With a focus on “Nadia Conti”, the visuals above could determine who has influence over this person.\n\n\n\n\nDegree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\nSeveral other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia’s network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that Nadia’s environment is both diverse and robust.\nDirect Connections\nThese direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti’s node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\nPeople: Elise, Liam Thorne, Davis, Rodriguez\nOrganization: V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\nVessel: Neptune, Marlin, Remora, Sentinel\nLocation: Haacklee Harbor\n\nInterpretation: The PageRank, Betweenness, and Degree centrality plots all consistently show Nadia Conti as a major hub, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\nNadia’s position suggests she is a key connector and influencer but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence—and be influenced—is amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia’s access to information, resources, and strategic decisions."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#strategy-for-question-2",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#strategy-for-question-2",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Strategy for Question 2:",
    "text": "Strategy for Question 2:\n\n1. Filter for Communication Events Only\n\nUse edges that connect Entity → Event (Communication) and Event (Communication) → Entity.\nFocus only on Communication events and extract senders and receivers.\n\n\n\nShow code\n# Extract Communication Events from nodes\ncommunication_events &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, label)\n\n# Extract sent edges: Entity → Communication Event\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% communication_events$id)\n\n# Extract received edges: Communication Event → Entity\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% communication_events$id)\n\n# Join both to get Sender → Communication → Receiver\ncomm_links &lt;- comm_sent_edges %&gt;%\n  select(comm_id = to_id, sender = from_id) %&gt;%\n  inner_join(\n    comm_received_edges %&gt;% select(comm_id = from_id, receiver = to_id),\n    by = \"comm_id\"\n  ) %&gt;%\n  filter(sender != receiver)\n\n\n\n\n2. Construct a Bipartite Graph of Communications\n\nFrom edges:\n\nSender (Entity) → Communication Event\nCommunication Event → Receiver (Entity)\n\nJoin both directions to link:\nEntity A → Communication Event → Entity B → derive Entity A → Entity B communication links.\n\n\n\nShow code\n# Get people and vessel node IDs\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter comm links to include only person ↔ vessel or person ↔ person, etc.\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\n3. Build Communication Network\n\nNodes: People and Vessels only (from mc3_nodes_cleaned).\nEdges: Summarized links between these nodes based on co-involvement in the same communication event.\n\n\n\nShow code\n# Edge weight (number of communications)\nedge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Create node list for graph\nnodes_df &lt;- people_vessels %&gt;%\n  filter(id %in% c(edge_df$sender, edge_df$receiver))\n\n# Build graph object\ncomm_graph &lt;- tbl_graph(nodes = nodes_df, edges = edge_df, directed = FALSE)\n\n\n\n\n4. Apply Community Detection (e.g., Louvain or Walktrap)\n\nUse igraph or tidygraph to detect communities.\nAnnotate communities for possible labels (e.g., Green Guardians, Sailor Shift fans) using node metadata.\n\n\n\nShow code\ncomm_graph &lt;- comm_graph %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\n5. Visualize Network\n\n\nShow code\nshape_map &lt;- c(\"Person\" = \"circle\", \"Vessel\" = \"triangle\")\n\ncolor_map &lt;- c(\n  \"Person\" = \"#fc8d62\",\n  \"Organization\" = \"#6baed6\",\n  \"Vessel\" = \"#66c2a2\",\n  \"Location\" = \"#c6dbef\",\n  \"Nadia Conti\" = \"#ffd92f\"\n)\n\nggraph(comm_graph, layout = \"fr\") +\n  geom_edge_link(aes(width = weight), alpha = 0.2, color = \"gray50\") +\n  geom_node_point(aes(color = group, shape = group), size = 4) +\n  geom_node_text(aes(label = label), repel = TRUE, size = 2.5) +\n  scale_shape_manual(values = shape_map) +\n  scale_color_manual(values = color_map) +\n  theme_graph() +\n  labs(title = \"Communication Clusters Between People and Vessels\",\n       subtitle = \"Communities detected using Louvain algorithm\")\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Get only Person and Vessel nodes\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter communication links for person ↔ vessel/person only\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\nShow code\n# Count number of communications between each sender–receiver pair\ncomm_edge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Build node dataframe from involved IDs only\ncomm_node_df &lt;- people_vessels %&gt;%\n  filter(id %in% unique(c(comm_edge_df$sender, comm_edge_df$receiver))) %&gt;%\n  mutate(\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Vessel\" ~ \"triangle\"\n    ),\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",\n      group == \"Vessel\" ~ \"#66c2a2\",\n      label == \"Nadia Conti\" ~ \"#ffd92f\",\n      TRUE ~ \"#c6dbef\"\n    )\n  )\n\n# Format edges for visNetwork\ncomm_vis_edges &lt;- comm_edge_df %&gt;%\n  rename(from = sender, to = receiver) %&gt;%\n  mutate(width = weight)\n\n\n\n\nShow code\nlibrary(igraph)\n\n# Create igraph object\ngraph_ig &lt;- graph_from_data_frame(comm_vis_edges, directed = FALSE, vertices = comm_node_df)\n\n# Apply Louvain clustering\nlouvain_groups &lt;- cluster_louvain(graph_ig)\ncomm_node_df$group_comm &lt;- as.factor(membership(louvain_groups))\n\n\n\n\nShow code\nlibrary(visNetwork)\n\n# Title heading\ncat(\"### Interactive Network of Communication Between People and Vessels\")\n\n\n### Interactive Network of Communication Between People and Vessels\n\n\nShow code\n# Final interactive visNetwork with consistent styling\nvisNetwork(\n  nodes = comm_node_df,\n  edges = comm_vis_edges\n) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -80,\n      centralGravity = 0.01,\n      springLength = 50,\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n    ),\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\n\nShow code\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nShow code\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nShow code\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -50,   # Increase pull toward center\n      centralGravity = 0.005,        # Lower keeps outer nodes further\n      springLength = 100,            # Length between nodes\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages by sender/receiver\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and label\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Bar plot\nggplot(comm_summary, aes(x = reorder(label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggtext)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages sent and received\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and format\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Create colored labels for x-axis\ncomm_summary &lt;- comm_summary %&gt;%\n  mutate(\n    x_label = paste0(\n      \"&lt;span style='color:\",\n      case_when(\n        sub_type == \"Vessel\" ~ \"#66c2a2\",\n        sub_type == \"Person\" ~ \"#fc8d62\",\n        TRUE ~ \"gray\"\n      ),\n      \"'&gt;\", label, \"&lt;/span&gt;\"\n    )\n  )\n\n# Step 5: Bar Plot with colored axis text\nggplot(comm_summary, aes(x = reorder(x_label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_markdown(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotly)\nlibrary(DT)\n\n# Step 1: Compute message counts\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 2: Combine counts\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\")\n\n# Step 3: Reshape for plotly\ncomm_long &lt;- comm_summary %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Plotly bar chart (interactive)\nplot_ly(\n  comm_long,\n  x = ~label,\n  y = ~count,\n  color = ~direction,\n  colors = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\"),\n  type = 'bar',\n  text = ~paste0(\"Entity: \", label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Count: \", count),\n  hoverinfo = 'text',\n  name = ~direction\n) %&gt;%\n  layout(\n    title = \"Interactive Message Volume by Entity\",\n    barmode = 'group',\n    xaxis = list(title = \"Entity\", tickangle = -45),\n    yaxis = list(title = \"Message Count\")\n  )\n\n\n\n\n\n\n\n\nShow code\ndatatable(\n  comm_summary %&gt;% arrange(desc(sent + received)),\n  options = list(\n    pageLength = 10,\n    autoWidth = TRUE,\n    searchHighlight = TRUE\n  ),\n  colnames = c(\"ID\", \"Name\", \"Sent\", \"Received\", \"Type\")\n)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#strategy-to-tackle-q2b",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#strategy-to-tackle-q2b",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Strategy to Tackle Q2b",
    "text": "Strategy to Tackle Q2b\n\nStep 1: Community Detection with Louvain\n\nUse igraph::cluster_louvain() on the communication network built in 2a (undirected).\nAssign a community ID to each node (nodes_vis$community).\n\n\n\nStep 2: Inspect and Interpret Communities\n\nSummarize the composition of each community by:\n\nNumber of persons/vessels\nTop labels in each group\nKnown keywords (e.g., “Green Guardians”, “Sailor Shift”, vessel names like “Aurora” or “Bluefin”)\n\n\n\n\nStep 3: Color-code the Network by Community\n\nAssign a distinct color to each detected community.\nRetain shape encoding (dot = Person, triangle = Vessel).\n\n\n\nStep 4: Interactive Visualization\n\nUse visNetwork to display the full communication network:\n\nColor nodes by community\nTooltip includes label, type, community\nLegend for each detected community\n\n\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Create igraph from person-vessel edges\ng_comm &lt;- graph_from_data_frame(edges_vis, directed = FALSE, vertices = nodes_vis)\n\n# Louvain detection\nlouvain_clusters &lt;- cluster_louvain(g_comm)\nnodes_vis$louvain_comm &lt;- as.factor(membership(louvain_clusters))\n\n# Walktrap detection\nwalktrap_clusters &lt;- cluster_walktrap(g_comm)\nnodes_vis$walktrap_comm &lt;- as.factor(membership(walktrap_clusters))\n\n# Create color palettes\nmax_comm &lt;- max(as.numeric(nodes_vis$louvain_comm), as.numeric(nodes_vis$walktrap_comm))\ncomm_colors &lt;- brewer.pal(n = min(max_comm, 8), name = \"Set2\")\n\n# Assign community color for each method\nnodes_louvain &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(louvain_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Louvain: \", louvain_comm)\n  )\n\nnodes_walktrap &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(walktrap_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Walktrap: \", walktrap_comm)\n  )\n\n\n\n\nShow code\n# Define consistent edge formatting\nedges_format &lt;- edges_vis %&gt;%\n  mutate(arrows = \"to\", width = width)\n\n# Louvain network\nlouvain_net &lt;- visNetwork(nodes_louvain, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Louvain Communities\"), useGroups = FALSE)\n\n# Walktrap network\nwalktrap_net &lt;- visNetwork(nodes_walktrap, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Walktrap Communities\"), useGroups = FALSE)\n\n\n📌 Louvain Community Network\n\n\nShow code\n# Generate cluster legend for Louvain\nlouvain_legend &lt;- unique(nodes_louvain$louvain_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_louvain$color[nodes_louvain$louvain_comm == comm_id])[1]\n    )\n  })\n\n# Render Louvain network\ncat(\"## Louvain Community Detection Network\")\n\n\n## Louvain Community Detection Network\n\n\nShow code\nvisNetwork(nodes_louvain, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = louvain_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )\n\n\n\n\n\n\n📌 Walktrap Community Network\n\n\nShow code\n# Generate cluster legend for Walktrap\nwalktrap_legend &lt;- unique(nodes_walktrap$walktrap_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_walktrap$color[nodes_walktrap$walktrap_comm == comm_id])[1]\n    )\n  })\n\n# Render Walktrap network\ncat(\"## Walktrap Community Detection Network\")\n\n\n## Walktrap Community Detection Network\n\n\nShow code\nvisNetwork(nodes_walktrap, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = walktrap_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-3a",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-3a",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 3a",
    "text": "VAST Challenge Task & Question 3a\n\nExpanding upon your prior visual analytics, determine who is using pseudonyms to communicate, and what these pseudonyms are.\n\nSome that Clepper has already identified include: “Boss”, and “The Lookout”, but there appear to be many more.\nTo complicate the matter, pseudonyms may be used by multiple people or vessels.\n\n\n\n1. Cleaning the dataset\nThe code below is to help us to further clean the data first before we can start to answer question 3\n\n\nShow code\n# Step 1: Define pseudonyms\npseudonym_keywords &lt;- c(\"Boss\", \"The Lookout\", \"The Intern\", \"Mrs. Money\", \n                        \"The Accountant\", \"The Middleman\", \"Small Fry\")\n\n# Step 2: Filter pseudonym nodes (from mc3_nodes_final)\npseudonym_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(\n    sub_type == \"Person\",\n    str_detect(name, regex(paste(pseudonym_keywords, collapse = \"|\"), ignore_case = TRUE))\n  )\n\n# Step 3: Get all edge rows where from/to match pseudonym node indices\npseudonym_node_indices &lt;- pseudonym_nodes$new_index\n\npseudonym_edges_final &lt;- mc3_edges_final %&gt;%\n  filter(from %in% pseudonym_node_indices | to %in% pseudonym_node_indices)\n\n# Step 4: Get only nodes that are involved in these edges\nused_node_indices &lt;- unique(c(pseudonym_edges_final$from, pseudonym_edges_final$to))\n\npseudonym_nodes_final &lt;- mc3_nodes_final %&gt;%\n  filter(new_index %in% used_node_indices) %&gt;%\n  mutate(label_type = ifelse(new_index %in% pseudonym_node_indices, \"Pseudonym\", \"Regular\"))\n\n# Step 5: Reindex nodes to match edge structure (0-based problem fix)\npseudonym_nodes_final &lt;- pseudonym_nodes_final %&gt;%\n  mutate(temp_index = row_number())\n\n# Mapping old new_index to new temp_index (for tbl_graph alignment)\nindex_map &lt;- pseudonym_nodes_final %&gt;%\n  select(old = new_index, new = temp_index)\n\n# Update edges to new 1-based index\npseudonym_edges_final &lt;- pseudonym_edges_final %&gt;%\n  left_join(index_map, by = c(\"from\" = \"old\")) %&gt;%\n  rename(from_new = new) %&gt;%\n  left_join(index_map, by = c(\"to\" = \"old\")) %&gt;%\n  rename(to_new = new) %&gt;%\n  filter(!is.na(from_new), !is.na(to_new)) %&gt;%\n  select(from = from_new, to = to_new, type)\n\n# Step 6: Build graph\npseudonym_graph &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n)\n\n\nBefore we start to answer the questions, let us first test out if the data cleaning is effective, which should be if not you wil not be able to see this!\n\nTest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisations below shows the entities labelled based on their real names or pseudinyms which are labelled differently using color codes so as for easier visualisation.\n\nMethod 1Method 2\n\n\n\n\nShow code\n# Count how many connections each pseudonym has\npseudonym_links &lt;- pseudonym_edges_final %&gt;%\n  left_join(pseudonym_nodes_final, by = c(\"from\" = \"temp_index\")) %&gt;%\n  rename(pseudonym = name) %&gt;%\n  filter(!is.na(pseudonym)) %&gt;%   # ✅ Only valid pseudonym nodes\n  group_by(pseudonym) %&gt;%\n  summarise(connection_count = n()) %&gt;%\n  arrange(desc(connection_count))\n\n\n# Plot it\nggplot(pseudonym_links, aes(x = reorder(pseudonym, connection_count), y = connection_count)) +\n  geom_col(fill = \"tomato\") +\n  coord_flip() +\n  labs(\n    title = \"Communication Frequency by Pseudonym\",\n    x = \"Pseudonym Name\",\n    y = \"Number of Connections\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Prepare node dataframe\nnodes_vis &lt;- pseudonym_nodes_final %&gt;%\n  transmute(\n    id = temp_index,\n    label = name,\n    group = ifelse(label_type == \"Pseudonym\", \"Pseudonym\", \"Regular\"),\n    title = paste(\"Name:\", name, \"&lt;br&gt;Type:\", label_type)\n  )\n\n# Prepare edge dataframe\nedges_vis &lt;- pseudonym_edges_final %&gt;%\n  transmute(\n    from = from,\n    to = to,\n    label = type,\n    arrows = \"to\"\n  )\n\n# Create visNetwork\nvisNetwork(nodes_vis, edges_vis, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visGroups(groupname = \"Regular\", color = \"steelblue\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\"),\n    list(label = \"Regular\", shape = \"dot\", color = \"steelblue\")\n  )) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visPhysics(stabilization = TRUE)\n\n\n\n\n\n\n\n\n\nAs we can see, there are 2 methods that we can use to visualise this case. The aim of this visualisation is to help clepper to visually identufy which nodes are pseudonuyms, and how are they connected to the real identity. Suspicious names or aliases will appear isolated\n\nFrom this visualisation, we can easily determine which names are Pseudonyms. These names can be easily identified via the color codes\nWe can easily trace who talks to and/or through aliases\nThis visualisation makes it easier for Clepper to spot suspicious names\n\n\n\n2. Question 3b\n\nDescribe how your visualizations make it easier for Clepper to identify common entities in the knowledge graph.\n\n\nCodeVisualisation output\n\n\n\n\nShow code\n# Q3b: Extract edges involving those pseudonyms\n# Build pseudonym network using tidygraph\npseudonym_graph_tbl &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n) %&gt;%\n  mutate(degree_centrality = centrality_degree(mode = \"all\"))  # centrality values added to nodes\n\n# Turn into tibble for ggplot\ntop_central &lt;- pseudonym_graph_tbl %&gt;%\n  as_tibble() %&gt;%\n  filter(label_type == \"Pseudonym\") %&gt;%\n  arrange(desc(degree_centrality)) %&gt;%\n  slice_head(n = 10)\n\n# Plot\nggplot(top_central, aes(x = reorder(name, degree_centrality), y = degree_centrality)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Central Pseudonym Entities\",\n    x = \"Pseudonym Name\",\n    y = \"Degree Centrality\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Q3b: Extract edges involving those pseudonyms\n# Build pseudonym network using tidygraph\npseudonym_graph_tbl &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n) %&gt;%\n  mutate(degree_centrality = centrality_degree(mode = \"all\"))  # centrality values added to nodes\n\n# Turn into tibble for ggplot\ntop_central &lt;- pseudonym_graph_tbl %&gt;%\n  as_tibble() %&gt;%\n  filter(label_type == \"Pseudonym\") %&gt;%\n  arrange(desc(degree_centrality)) %&gt;%\n  slice_head(n = 10)\n\n# Plot\nggplot(top_central, aes(x = reorder(name, degree_centrality), y = degree_centrality)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Central Pseudonym Entities\",\n    x = \"Pseudonym Name\",\n    y = \"Degree Centrality\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisation shows a bar chart of degree centrality that shows the top 10 most connectd pseudonyms. The aim of this graph is to heko clepper to quantify influence by measuring the cetrality of the pseudonyms for deeper investigation. It also helps Clepper t identify who are the key players who may be controlling the flow of information\n\nThese visualisation helps Clepper to identify wich of the pseudonyms are most active\nWe can see that the nodes act as central hubs wihin the pseudonym network\nThis visualisation can help clepper to prioritize pseudionyms first as part of his investigations\n\n\n\n3. Question 3c\nCode\n\n\nShow code\nshared_pseudonyms &lt;- pseudonym_nodes_final %&gt;%\n  group_by(name) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\n# Create nodes: both entities and pseudonyms\nvis_nodes_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(id = id, \n            label = id, \n            group = \"Entity\",\n            title = paste(\"Entity ID:\", id)) %&gt;%\n  bind_rows(\n    shared_pseudonyms %&gt;%\n      select(id = name) %&gt;%\n      distinct() %&gt;%\n      mutate(label = id,\n             group = \"Pseudonym\",\n             title = paste(\"Pseudonym:\", id))\n  )\n\nvis_edges_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(from = id, to = name)\n\nvisNetwork(vis_nodes_3c, vis_edges_3c, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Entity\", color = \"steelblue\") %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Entity\", shape = \"dot\", color = \"steelblue\"),\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\")\n  )) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisualisation Output\n\n\nShow code\nshared_pseudonyms &lt;- pseudonym_nodes_final %&gt;%\n  group_by(name) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\n# Create nodes: both entities and pseudonyms\nvis_nodes_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(id = id, \n            label = id, \n            group = \"Entity\",\n            title = paste(\"Entity ID:\", id)) %&gt;%\n  bind_rows(\n    shared_pseudonyms %&gt;%\n      select(id = name) %&gt;%\n      distinct() %&gt;%\n      mutate(label = id,\n             group = \"Pseudonym\",\n             title = paste(\"Pseudonym:\", id))\n  )\n\nvis_edges_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(from = id, to = name)\n\nvisNetwork(vis_nodes_3c, vis_edges_3c, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Entity\", color = \"steelblue\") %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Entity\", shape = \"dot\", color = \"steelblue\"),\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\")\n  )) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nThe visualisation used for this part of the question is an interactive graph using the visNetwork entity which shows the edges and nodes. The blue nodes indicates the entities (may be people or vessels), red nodes which is the pseudonym names and edges which indicates which entity uses what pseudonym. The aim of this visualisation is to expose the reusing of an alias whereby the same pseudonym is tied and connected to multiple entities\n\nThis visualisation helps Clepper to easily identify which pseudonyms are reused by multiple entities\nThis breaks the assumed connection between identity and name revealing many one-to-one mapping\nThis therefore can help Clepper to detect deception strategies such as multiple people pretending to have one single alias, hence minimising the risks of impersonation."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-4a",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#vast-challenge-task-question-4a",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 4a",
    "text": "VAST Challenge Task & Question 4a\n\nClepper suspects that Nadia Conti, who was formerly entangled in an illegal fishing scheme, may have continued illicit activity within Oceanus.\n\nThrough visual analytics, provide evidence that Nadia is, or is not, doing something illegal.\n\n\n\n1. Extracting Nadia’s data\n\n\nShow code\nnodes &lt;- MC3$nodes\nedges &lt;- MC3$edges\n\n# Extract communication events\ncomms &lt;- nodes %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, content)\n\n# Link to sender & receiver\nsent_edges &lt;- edges %&gt;% filter(type == \"sent\") %&gt;%\n  select(source = source, comm_id = target)\n\nrecv_edges &lt;- edges %&gt;% filter(type == \"received\") %&gt;%\n  select(comm_id = source, target = target)\n\n# Merge\ncomms_data &lt;- comms %&gt;%\n  left_join(sent_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(sender = source) %&gt;%\n\n  left_join(recv_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(receiver = target)\n\n# Add sender/receiver names\nmc3_nodes_cleaned &lt;- nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE)\n\ncomms_data &lt;- comms_data %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver\" = \"id\"))\n\n# Count Nadia's messages\nnadia_counts &lt;- comms_data %&gt;%\n  summarise(\n    Sent = sum(sender_label == \"Nadia Conti\", na.rm = TRUE),\n    Received = sum(receiver_label == \"Nadia Conti\", na.rm = TRUE)\n  ) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Type\", values_to = \"Count\") %&gt;%\n  mutate(\n    Percent = Count / sum(Count),\n    Label = paste0(round(Percent * 100), \"%\\n(\", Count, \" msgs)\")\n  )\n\n\n\n\n2. Message count of Nadia\n\n\nShow code\nggplot(nadia_counts, aes(x = Count, y = reorder(Type, Count), fill = Type)) +\n  geom_col(color = \"white\") +\n  geom_text(aes(label = paste0(Count, \" msgs (\", round(Percent * 100), \"%)\")),\n            hjust = -0.1, size = 4) +\n  scale_fill_manual(values = c(\"Sent\" = \"deepskyblue3\", \"Received\" = \"cyan\")) +\n  labs(title = paste0(\"Nadia Conti's Messages (Total: \", sum(nadia_counts$Count), \")\"),\n       x = \"Message Count\", y = NULL) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(face = \"bold\")) +\n  xlim(0, max(nadia_counts$Count) * 1.2)\n\n\n\n\n\n\n\n\n\n\n\n3. Message frequency of Nadia\n\n\nShow code\n# Make sure nadia_data is created\nnadia_data &lt;- comms_data %&gt;%\n  filter(sender_label == \"Nadia Conti\" | receiver_label == \"Nadia Conti\") %&gt;%\n  left_join(nodes %&gt;% select(id, timestamp), by = c(\"id\" = \"id\")) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(date = as.Date(timestamp), hour = hour(timestamp))\n\n# Create daily_freq\ndaily_freq &lt;- nadia_data %&gt;%\n  group_by(date) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n# Create hourly_freq\nhourly_freq &lt;- nadia_data %&gt;%\n  group_by(date, hour) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n\n\n3.1 Daily\n\n\nShow code\nggplot(daily_freq, aes(x = date, y = count)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = count), vjust = -0.5, size = 3) +\n  labs(\n    title = \"Nadia Conti's Daily Message Frequency\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n3.2 Hourly\n\n\nShow code\nlibrary(plotly)\n\nplot_ly(\n  data = hourly_freq,\n  x = ~hour,\n  y = ~count,\n  color = ~as.factor(date),\n  type = 'bar',\n  text = ~paste(\"Date:\", date, \"&lt;br&gt;Hour:\", hour, \"&lt;br&gt;Messages:\", count),\n  hoverinfo = 'text'\n) %&gt;%\n  layout(\n    barmode = 'dodge',  # use 'stack' if you prefer stacked bars\n    title = \"Nadia Conti's Hourly Message Frequency\",\n    xaxis = list(title = \"Hour of Day\"),\n    yaxis = list(title = \"Message Count\"),\n    legend = list(title = list(text = \"Date\"))\n  )\n\n\n\n\n\n\n\n\n\n4. Nadia’s relationship pattern\n\n\nShow code\nlibrary(ggplot2)\n\n# Count relationships by type\nrelationship_counts &lt;- mc3_edges_cleaned %&gt;%\n  filter(type != \"sent\", type != \"received\") %&gt;%  # Focus on relationships, not communication\n  count(type, sort = TRUE)\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(visNetwork)\n\n# Summarise Nadia's communication edges\nnadia_edges &lt;- nadia_data %&gt;%\n  count(sender_label, receiver_label) %&gt;%\n  filter(!is.na(sender_label), !is.na(receiver_label)) %&gt;%\n  rename(from = sender_label, to = receiver_label, value = n)\n\n# Get sender + receiver entity info\n# Get type info for sender and receiver\nentity_info &lt;- bind_rows(\n  nadia_data %&gt;%\n    left_join(mc3_nodes_cleaned %&gt;% select(id, name = label, type = sub_type),\n              by = c(\"sender\" = \"id\")) %&gt;%\n    select(name, type),\n  nadia_data %&gt;%\n    left_join(mc3_nodes_cleaned %&gt;% select(id, name = label, type = sub_type),\n              by = c(\"receiver\" = \"id\")) %&gt;%\n    select(name, type)\n) %&gt;%\n  distinct()\n\n# Build node table\nnadia_nodes &lt;- tibble(name = unique(c(nadia_edges$from, nadia_edges$to))) %&gt;%\n  left_join(entity_info, by = \"name\") %&gt;%\n  mutate(\n    group = ifelse(name == \"Nadia Conti\", \"Nadia Conti\", type),\n    id = name,\n    label = name,\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",       \n      group == \"Organization\" ~ \"#6baed6\",\n      group == \"Vessel\" ~ \"#66c2a2\",      \n      group == \"Location\" ~ \"#c6dbef\",    \n      group == \"Nadia Conti\" ~ \"#ffd92f\", \n      TRUE ~ \"#d9d9d9\"\n    ),\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Organization\" ~ \"square\",\n      group == \"Vessel\" ~ \"triangle\",\n      group == \"Location\" ~ \"diamond\",\n      group == \"Nadia Conti\" ~ \"star\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Render network\nvisNetwork(nodes = nadia_nodes, edges = nadia_edges) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(gravitationalConstant = -25, centralGravity = 0.01, springLength = 50, springConstant = 0.02),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Organization\", shape = \"square\", color = \"#6baed6\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\"),\n      list(label = \"Location\", shape = \"diamond\", color = \"#c6dbef\"),\n      list(label = \"Nadia Conti\", shape = \"star\", color = \"#ffd92f\")\n    ),\n    width = 0.2,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\n\n5. Nadia’s most frequent commuter\n\n\nShow code\n# Get communication events linked to Nadia\nnadia_comm_ids &lt;- edges %&gt;%\n  filter(type == \"sent\" | type == \"received\") %&gt;%\n  filter(source == mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"] |\n         target == mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]) %&gt;%\n  mutate(comm_id = ifelse(type == \"sent\", target, source)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Get edges related to these communications\nnadia_related_edges &lt;- edges %&gt;%\n  filter(source %in% nadia_comm_ids | target %in% nadia_comm_ids)\n\n# Get people connected (excluding comm events + Nadia herself)\nnadia_id &lt;- mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]\n\nnadia_contacts_ids &lt;- nadia_related_edges %&gt;%\n  mutate(person_id = ifelse(source %in% nadia_comm_ids, target, source)) %&gt;%\n  filter(!person_id %in% nadia_comm_ids, person_id != nadia_id) %&gt;%\n  count(person_id, sort = TRUE)\n\n# Join with node labels\ntop_contacts_named &lt;- nadia_contacts_ids %&gt;%\n  left_join(nodes %&gt;% filter(sub_type == \"Person\") %&gt;% select(id, name = label),\n            by = c(\"person_id\" = \"id\")) %&gt;%\n  filter(!is.na(name))\n\n\n\n\nShow code\ntop_contacts_named %&gt;%\n  slice_max(n, n = 3) %&gt;%\n  ggplot(aes(x = reorder(name, n), y = n)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 3 Contacts Communicating with Nadia Conti\",\n    x = \"Contact Person\",\n    y = \"Number of Messages\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(DT)\n\nnadia_id &lt;- mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]\n\n# Nadia's communication event IDs\nnadia_comm_ids &lt;- edges %&gt;%\n  filter(type == \"sent\" | type == \"received\") %&gt;%\n  filter(source == nadia_id | target == nadia_id) %&gt;%\n  mutate(comm_id = ifelse(type == \"sent\", target, source)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Top contact comm IDs\ntop_contact_comm_ids &lt;- edges %&gt;%\n  filter(\n    (source %in% nadia_comm_ids & target %in% top_contacts_named$person_id) |\n    (target %in% nadia_comm_ids & source %in% top_contacts_named$person_id)\n  ) %&gt;%\n  mutate(comm_id = ifelse(source %in% nadia_comm_ids, source, target)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Get comm event details\nnadia_messages &lt;- nodes %&gt;%\n  filter(id %in% top_contact_comm_ids) %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, timestamp, content) %&gt;%\n  left_join(edges %&gt;% filter(type == \"sent\") %&gt;% select(id = target, sender = source),\n            by = \"id\") %&gt;%\n  left_join(edges %&gt;% filter(type == \"received\") %&gt;% select(id = source, receiver = target),\n            by = \"id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_name = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_name = label), by = c(\"receiver\" = \"id\")) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    sender_receiver = paste(sender_name, \"→\", receiver_name)\n  ) %&gt;%\n  arrange(timestamp) %&gt;%\n  select(timestamp, sender_receiver, content)\n\n# Display\nDT::datatable(\n  nadia_messages,\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE,\n    initComplete = htmlwidgets::JS(\n      \"function(settings, json) {\",\n      \"$(this.api().table().header()).css({'background-color': '#f8f9fa', 'color': '#333'});\",\n      \"}\"\n    )\n  ),\n  rownames = FALSE,\n  class = 'stripe hover compact',\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:16px; color:#444;',\n    'Messages'\n  )\n)\n\n\n\n\n\n\n\n\n6. Temporal + suspicious event alignment\n\n6.1 Showing Nadia’s unusually active days\n\n\nShow code\n# Compute mean + SD of daily messages\ndaily_summary &lt;- daily_freq %&gt;%\n  summarise(mean_count = mean(count), sd_count = sd(count))\n\n# Flag days with unusually high message counts\nspike_days &lt;- daily_freq %&gt;%\n  filter(count &gt; daily_summary$mean_count + 2 * daily_summary$sd_count)\n\n# Show spike days\nprint(spike_days)\n\n\n# A tibble: 1 × 2\n  date       count\n  &lt;date&gt;     &lt;int&gt;\n1 2040-10-08     9\n\n\n\n\n6.2 Suspicious dates\n\n\nShow code\nsuspicious_dates &lt;- as.Date(c(\"2040-10-05\", \"2040-10-08\", \"2040-10-11\")) # example reef closure, approvals, etc.\n\n\n\n\nShow code\nspike_days %&gt;%\n  mutate(suspicious = ifelse(date %in% suspicious_dates, \"YES\", \"NO\"))\n\n\n# A tibble: 1 × 3\n  date       count suspicious\n  &lt;date&gt;     &lt;int&gt; &lt;chr&gt;     \n1 2040-10-08     9 YES       \n\n\n\n\nShow code\nlibrary(plotly)\nlibrary(dplyr)\n\n# Suppose suspicious dates (replace with real ones)\nsuspicious_dates &lt;- as.Date(c(\"2040-10-05\", \"2040-10-08\", \"2040-10-11\"))\n\n# Compute threshold\ndaily_summary &lt;- daily_freq %&gt;%\n  summarise(mean_count = mean(count), sd_count = sd(count))\n\nthreshold &lt;- daily_summary$mean_count + 2 * daily_summary$sd_count\n\n# Add status column\ndaily_freq_plot &lt;- daily_freq %&gt;%\n  mutate(\n    status = case_when(\n      date %in% suspicious_dates ~ \"Suspicious Date\",\n      count &gt; threshold ~ \"Spike\",\n      TRUE ~ \"Normal\"\n    )\n  )\n\n# Assign colors\nstatus_colors &lt;- c(\n  \"Normal\" = \"steelblue\",\n  \"Spike\" = \"red\",\n  \"Suspicious Date\" = \"orange\"\n)\n\n# Build Plotly bar chart\nplot_ly(\n  data = daily_freq_plot,\n  x = ~date,\n  y = ~count,\n  type = 'bar',\n  color = ~status,\n  colors = status_colors,\n  text = ~paste(\"Date:\", date, \"&lt;br&gt;Messages:\", count, \"&lt;br&gt;Status:\", status),\n  hoverinfo = 'text'\n) %&gt;%\n  layout(\n    title = \"Nadia Conti's Daily Communication\",\n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"Message Count\"),\n    barmode = 'group',\n    legend = list(title = list(text = \"Status\"))\n  ) %&gt;%\n  add_lines(\n    x = ~date,\n    y = rep(threshold, nrow(daily_freq_plot)),\n    line = list(dash = 'dash', color = 'red'),\n    name = 'Spike Threshold',\n    inherit = FALSE\n  )\n\n\n\n\n\n\n\n\n\n7. Drilling down on spike + flagged date\n\n7.1 Extract Nadia’s message from Oct 8\n\n\nShow code\n# Build fresh nadia_data with content included at the start\nnadia_data &lt;- comms %&gt;%\n  left_join(sent_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(sender = source) %&gt;%\n  left_join(recv_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(receiver = target) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver\" = \"id\")) %&gt;%\n  left_join(nodes %&gt;% select(id, timestamp), by = \"id\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    hour = hour(timestamp)\n  ) %&gt;%\n  filter(sender_label == \"Nadia Conti\" | receiver_label == \"Nadia Conti\") %&gt;%\n  filter(!is.na(timestamp))\n\n\n\n\nShow code\noct8_msgs &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  select(timestamp, sender_label, receiver_label, content) %&gt;%\n  arrange(timestamp)\n\nDT::datatable(\n  oct8_msgs,\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE,\n    columnDefs = list(\n      list(\n        targets = 3,  # adjust if content is not 3rd col\n        render = JS(\n          \"function(data, type, row, meta) {\",\n          \"return type === 'display' && data.length &gt; 50 ?\",\n          \"'&lt;span title=\\\"' + data + '\\\"&gt;' + data.substr(0, 50) + '...&lt;/span&gt;' : data;\",\n          \"}\"\n        )\n      )\n    )\n  ),\n  rownames = FALSE,\n  class = 'stripe hover compact',\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:14px; color:#444;',\n    '📌 Nadia Conti Messages on Oct 8, 2040'\n  )\n)\n\n\n\n\n\n\n\n\n7.2 Keywords of Oct 8\nShowing messages on Oct 8 mentioning suspicious terms of:\n\npermit\napproval\nreef\ncargo\nshipment\nillegal\n\n\n\nShow code\n# Define suspicious keywords\nkeywords &lt;- c(\"permit\", \"approval\", \"reef\", \"cargo\", \"shipment\", \"dock\", \"illegal\")\n\n# Filter messages on Oct 8 with suspicious terms\noct8_flagged_msgs &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  filter(!is.na(content)) %&gt;%\n  filter(grepl(paste(keywords, collapse = \"|\"), content, ignore.case = TRUE)) %&gt;%\n  select(timestamp, sender_label, receiver_label, content) %&gt;%\n  arrange(timestamp)\n\n# Display in interactive table\nDT::datatable(\n  oct8_flagged_msgs,\n  options = list(pageLength = 5, autoWidth = TRUE),\n  rownames = FALSE,\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:16px; color:#444;',\n    '📌 Oct 8 Messages with Suspicious Keywords'\n  )\n)\n\n\n\n\n\n\n\n\n7.3 Network of Oct 8 communication\n\n\nShow code\nlibrary(visNetwork)\n\n# Summarize comms on Oct 8\noct8_edges &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  count(sender_label, receiver_label) %&gt;%\n  filter(!is.na(sender_label), !is.na(receiver_label)) %&gt;%\n  rename(from = sender_label, to = receiver_label, value = n)\n\n# Build node list\noct8_nodes &lt;- tibble(name = unique(c(oct8_edges$from, oct8_edges$to))) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(label, sub_type), by = c(\"name\" = \"label\")) %&gt;%\n  mutate(\n    group = ifelse(name == \"Nadia Conti\", \"Nadia Conti\", sub_type),\n    id = name,\n    label = name\n  )\n\n# Render network\nvisNetwork(oct8_nodes, oct8_edges) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 456) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLegend()\n\n\n\n\n\n\nNadia is heavily involved in:\n\nDiscussion of Nemo Reef, permits, foundation work\nCoordinating payments, doubling fees, Harbor Master cooperation\nAdjusting schedules to avoid council suspicion\n\nHighly suspicious tone: manipulation, concealment, operational coordination beyond scope.\n\n\n\n8. Linking Oct 8 comms to permits, approvals, or vessel activity\n\n\nShow code\nsuspicious_events_alt &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type %in% c(\"VesselMovement\", \"Monitoring\", \"HarborReport\", \"Fishing\", \"Enforcement\")) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(timestamp &gt;= as.POSIXct(\"2040-10-08\"))\n\nDT::datatable(\n  suspicious_events_alt %&gt;%\n    select(type, label, sub_type, id, timestamp, monitoring_type, findings),\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE\n  ),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(plotly)\n\n# 1️⃣ Prepare entity-related vessel/harbor events\nentity_events &lt;- suspicious_events_alt %&gt;%\n  filter(str_detect(findings, regex(\"Neptune|Miesel|Mako\", ignore_case = TRUE))) %&gt;%\n  mutate(entity = case_when(\n    str_detect(findings, regex(\"Neptune\", ignore_case = TRUE)) ~ \"Neptune\",\n    str_detect(findings, regex(\"Miesel\", ignore_case = TRUE)) ~ \"Miesel\",\n    str_detect(findings, regex(\"Mako\", ignore_case = TRUE)) ~ \"Mako\",\n    TRUE ~ \"Other\"\n  ))\n\n# 2️⃣ Build interactive plot\nplot_ly() %&gt;%\n  # Nadia comms\n  add_markers(\n    data = nadia_data,\n    x = ~timestamp,\n    y = ~\"Nadia Message\",\n    marker = list(color = \"red\", size = 10),\n    text = ~paste0(\"Nadia Message&lt;br&gt;\", timestamp),\n    hoverinfo = \"text\",\n    name = \"Nadia Message\"\n  ) %&gt;%\n  # Neptune events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Neptune\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#1f77b4\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Neptune Event\"\n  ) %&gt;%\n  # Miesel events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Miesel\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#17becf\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Miesel Event\"\n  ) %&gt;%\n  # Mako events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Mako\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#7f7f7f\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Mako Event\"\n  ) %&gt;%\n  layout(\n    title = \"Nadia Comms + Vessel/Harbor Events\",\n    xaxis = list(title = \"Time\"),\n    yaxis = list(title = \"\"),\n    legend = list(orientation = \"h\", x = 0.1, y = -0.3)\n  )\n\n\n\n\n\n\nThe interactive timeline highlights that Nadia Conti’s communications were closely followed by vessel/harbor events involving Neptune, V. Miesel Shipping, and Mako. Notably:\n•   On **Oct 8**, Nadia’s messages spiked, coinciding with planned operations at Nemo Reef.\n\n•   Shortly afterward, vessel activities linked to **Neptune, Miesel, and Mako** were logged.\n\n•   This temporal proximity strongly suggests coordination between Nadia and these entities.\nThere is no evidence of formal approvals or permits linked to these activities, pointing to potential covert operations."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC.html#question-4b---are-cleppers-suspicions-justified",
    "href": "main_project_qmd/main_project_qmd/main_DC.html#question-4b---are-cleppers-suspicions-justified",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Question 4B - Are Clepper’s suspicions justified?",
    "text": "Question 4B - Are Clepper’s suspicions justified?\n\n1. Findings\n1.1 Communication Activity\n\nNadia exchanged a total of 26 messages, of which 31% were sent and 69% received.\nAn unusually high volume of messages was recorded on 2040-10-08 (9 messages), exceeding the normal daily message count and crossing the defined spike threshold.\nMessaging patterns were concentrated between 08:00 and 12:00, suggesting focused coordination during operational hours.\n\n1.2 Relationship Network\n\nNetwork visualizations indicate Nadia as a central figure in communications with key individuals (Davis, Liam Thorne, Elise) and entities (Neptune, Marlin, V. Miesel Shipping).\nThe strongest links were observed between Nadia and Davis, Neptune, and Liam Thorne, with frequent exchanges regarding sensitive operational matters.\n\n1.3 Content of Communication\n\nThematic analysis identified frequent mentions of permits, approvals, reef, foundation work, shipment, and cargo.\nSeveral messages contained concerning elements, including discussions of doubling fees for cooperation, adjustments to patrol schedules, and concealing operations from the council.\n\n1.4 Temporal and Event Alignment\n\nTimeline analysis shows that Nadia’s communication spikes closely preceded vessel activities involving Neptune, V. Miesel Shipping, and Mako.\nThis temporal alignment strongly suggests a coordinated effort linked to unauthorized operations at Nemo Reef.\n\n\n\nConclusion\nThe evidence supports Clepper’s suspicions. Nadia’s communication patterns, network centrality, message content, and the alignment with vessel activity point to her active involvement in potentially covert and unauthorized operations. There is no indication of formal approvals associated with these activities, raising further concerns about compliance and legality."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html",
    "href": "main_project_qmd/main_project_qmd/main.html",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "",
    "text": "This take home exercise is based on the VAST Challenge Mini Case 3\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jessen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation.\nYour task is to develop new and novel visualizations and visual analytics approaches to help Clepper get to the bottom of this story"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#initial-eda",
    "href": "main_project_qmd/main_project_qmd/main.html#initial-eda",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "3.1 Initial EDA",
    "text": "3.1 Initial EDA\n\n\nShow code\nExpCatViz(data=mc3_nodes,\n          col=\"pink\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#relationship-between-entities-and-events",
    "href": "main_project_qmd/main_project_qmd/main.html#relationship-between-entities-and-events",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.1 Relationship between entities and events",
    "text": "6.1 Relationship between entities and events\n\n\nShow code\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 2) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#entity-distribution",
    "href": "main_project_qmd/main_project_qmd/main.html#entity-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.2 Entity distribution",
    "text": "6.2 Entity distribution\n\n\nShow code\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#event-type-distribution",
    "href": "main_project_qmd/main_project_qmd/main.html#event-type-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.3 Event type distribution",
    "text": "6.3 Event type distribution\n\n\nShow code\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#list-of-communication-participants",
    "href": "main_project_qmd/main_project_qmd/main.html#list-of-communication-participants",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4 List of communication participants",
    "text": "6.4 List of communication participants\n\n\nShow code\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#visualization-of-communication-participants-network",
    "href": "main_project_qmd/main_project_qmd/main.html#visualization-of-communication-participants-network",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4.1 Visualization of communication participants network",
    "text": "6.4.1 Visualization of communication participants network\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-1a-and-1b",
    "href": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-1a-and-1b",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 1a and 1b",
    "text": "VAST Challenge Task & Question 1a and 1b\nClepper found that messages frequently came in at around the same time each day.\n\nDevelop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\nHow do these patterns shift over the two weeks of observations?\n\nObjective\n\nIdentify when communications happen most often during each day.\nDetect shifts in these patterns over the 2-week period.\nLater: Focus on a specific entity (e.g., Nadia Conti) and explore who influences them.\n\n\nStep 1: Extract & Parse Communication Event Timestamps\nExtract the Communication Timestamps from mc3_nodes_final and filter for communication events.\n\n\nShow code\n# Filter for Communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n\n\nParse the Communication Timestamp into the format “dd/mm/yyy (ddd)” for ease of reference.\n\n\nShow code\n# Communication events with parsed date and time\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n\n\n\n\nStep 2: Visualize the Communication Volume for Analysis\n\n2.1 - Bar Plot of daily communication volume over the 2 weeks period:\n\n\nShow code\n# Step 1: Prepare daily message volume data\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count &lt;- mean(daily_message_volume$message_count)\ntotal_msg_count &lt;- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n2.2 - Interactive Table of daily communication volume variation(message count)\n\n\nShow code\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %&gt;% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\n2.3a - Heat Map of hourly message volume for each day over the 2 weeks period:\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count\n\n\nShow code\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender–receiver–timestamp structure\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender–receiver–timestamp\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(sender_id = id, sender_label = label), by = \"sender_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, hour) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;⏰ Hour: \", sprintf(\"%02d:00\", hour),\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np &lt;- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nWe will increase the resolution to half-hour time slots.\n\n\n2.4b - Heat Map of half-hourly message volume for each day over the 2 weeks period:\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count.\n\n\nShow code\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)  # ✅ fixed receiver_id\n\n# Step 2: Reconstruct sender–receiver–event linkage\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, time_bin, time_label) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;🕒 Time: \", time_label,\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np &lt;- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n2.4c - Density plot of Daily half-hourly message volume over the 2 weeks period:\nThe faceted density plot that shows the distribution of communication events by time of day, broken down for each day in the dataset. It helps to visually detect temporal communication patterns, intensity, and consistency over multiple days.\n\nOverview of the 2 week periodDay 1 - 01/10/2040Day 2 - 02/10/2040Day 3 - 03/10/2040Day 4 - 04/10/2040Day 5 - 05/10/2040Day 6 - 06/10/2040Day 7 - 07/10/2040Day 8 - 08/10/2040Day 9 - 09/10/2040Day 10 - 10/10/2040Day 11 - 11/10/2040Day 12 - 12/10/2040Day 13 - 13/10/2040Day 14 - 14/10/2040\n\n\n\n\nShow code\n# Step 1: Preprocess communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats &lt;- comm_events %&gt;%\n  group_by(date_label) %&gt;%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n📈 Insights This Visualization Offers\n\n\n\nStep 3: Plot Combined Hourly and Half-hourly Communication Volume\nBar Plot of combined hourly message volume over the 2 weeks period:\n\n\nShow code\n# Prepare data\ncomm_hourly &lt;- comm_events %&gt;%\n  count(hour) %&gt;%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nBar Plot of combined half-hourly message volume in the 2 weeks period.\n\n\nShow code\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute &lt; 30, 0, 30))\n  )\n\ncomm_halfhour &lt;- comm_events %&gt;%\n  count(time_bin) %&gt;%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1a. What are the identifiable daily temporal patterns in communications?\n\n\n\n\nThe daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)—a sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\nThe temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\nFor instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends—communication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n\n\n\n\n\n\n\n\n\n1b. How do these patterns shift over the two weeks of observations?\n\n\n\n\nOver the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of “surge” (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation—an analytical signal that warrants closer inspection of event logs or external triggers for those dates.\nAnother notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule—potentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-1c",
    "href": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-1c",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 1c",
    "text": "VAST Challenge Task & Question 1c\nClepper found that messages frequently came in at around the same time each day.\n\nFocus on a specific entity and use this information to determine who has influence over them.\n\n\n3.1 - Data Preparation for “Nadia Conti” Influence Analysis\nWe first extracted the relevant communication edges from the dataset, pairing “sent” and “received” communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\nShow code\n# Extract sent and received communication event edges\nsent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges &lt;- sent_edges %&gt;%\n  inner_join(received_edges, by = \"event\") %&gt;%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges &lt;- sent_edges %&gt;%\n  select(from = source_entity, to = event)\nsingle_received_edges &lt;- received_edges %&gt;%\n  select(from = event, to = target_entity)\n\nall_edges &lt;- bind_rows(paired_edges, single_sent_edges, single_received_edges) %&gt;%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  pull(id) %&gt;% as.character()\n\nentity_edges &lt;- all_edges %&gt;%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  select(id, label, sub_type)\n\n\n\n\n3.2 - Build the Global Network and Compute Centrality\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node—PageRank, betweenness, and degree—quantifying the influence and connectivity of every entity in the overall network.\n\n\nShow code\nlibrary(igraph)\n\ng &lt;- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank &lt;- page_rank(g)$vector\nV(g)$betweenness &lt;- betweenness(g)\nV(g)$degree &lt;- degree(g)\n\n\n\n\n3.3 - Extract “Nadia Conti” Ego Network (2-hop Neighbourhood)\nFocusing on “Nadia Conti”, we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia’s immediate sphere of influence and the key players connected to her.\n\n\nShow code\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\nego_graph &lt;- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n\n\n\n\n3.4 - Visualize Nadia Conti’s Ego Network (Interactive)\nWe visualized Nadia’s ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti’s communication environment.\n\n\nShow code\nnodes_df &lt;- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_graph)$label, \"&lt;/b&gt;&lt;br&gt;\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"&lt;br&gt;\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"&lt;br&gt;\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df &lt;- as_data_frame(ego_graph, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %&gt;%\n  visNodes(scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %&gt;%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#global-and-ego-network-structure",
    "href": "main_project_qmd/main_project_qmd/main.html#global-and-ego-network-structure",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Global and Ego-Network Structure",
    "text": "Global and Ego-Network Structure\nThe overview network visualization reveals that Nadia Conti is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia’s influence neighborhood.\n\n3.5 - Centrality Tables for Nadia’s Ego Network\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\nPageRank (overall influence),\nBetweenness (information brokerage/intermediary role), and\nDegree (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\nShow code\n# PageRank table\npagerank_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %&gt;% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %&gt;% arrange(desc(betweenness))\n\n# Degree table\ndegree_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %&gt;% arrange(desc(degree))\n\n\n\n\nShow code\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n\n\n\nPageRank Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\npagerank\n\n\n\n\nMako\nVessel\n0.0687\n\n\nOceanus City Council\nOrganization\n0.0530\n\n\nReef Guardian\nVessel\n0.0454\n\n\nNadia Conti\nPerson\n0.0432\n\n\nRemora\nVessel\n0.0409\n\n\nV. Miesel Shipping\nOrganization\n0.0394\n\n\nNeptune\nVessel\n0.0358\n\n\nHimark Harbor\nLocation\n0.0358\n\n\nLiam Thorne\nPerson\n0.0275\n\n\nBoss\nPerson\n0.0272\n\n\nSentinel\nVessel\n0.0250\n\n\nPaackland Harbor\nLocation\n0.0244\n\n\nDavis\nPerson\n0.0239\n\n\nMarlin\nVessel\n0.0235\n\n\nEcoVigil\nVessel\n0.0233\n\n\nGreen Guardians\nOrganization\n0.0224\n\n\nMrs. Money\nPerson\n0.0192\n\n\nSailor Shifts Team\nOrganization\n0.0186\n\n\nSeawatch\nVessel\n0.0186\n\n\nElise\nPerson\n0.0182\n\n\nSerenity\nVessel\n0.0170\n\n\nHorizon\nVessel\n0.0152\n\n\nThe Middleman\nPerson\n0.0142\n\n\nNorthern Light\nVessel\n0.0135\n\n\nRodriguez\nPerson\n0.0122\n\n\nSamantha Blake\nPerson\n0.0114\n\n\nHaacklee Harbor\nLocation\n0.0111\n\n\nOsprey\nVessel\n0.0088\n\n\nCity Officials\nGroup\n0.0066\n\n\nThe Lookout\nPerson\n0.0062\n\n\nKnowles\nVessel\n0.0051\n\n\nSmall Fry\nPerson\n0.0035\n\n\nGlitters Team\nOrganization\n0.0035\n\n\n\n\n\n\n\nShow code\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n\n\n\nBetweenness Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\nbetweenness\n\n\n\n\nMako\nVessel\n368.50\n\n\nMrs. Money\nPerson\n167.18\n\n\nReef Guardian\nVessel\n139.69\n\n\nBoss\nPerson\n136.18\n\n\nV. Miesel Shipping\nOrganization\n118.70\n\n\nNadia Conti\nPerson\n117.87\n\n\nOceanus City Council\nOrganization\n116.11\n\n\nRemora\nVessel\n90.45\n\n\nNeptune\nVessel\n82.59\n\n\nThe Lookout\nPerson\n80.51\n\n\nHimark Harbor\nLocation\n52.61\n\n\nThe Middleman\nPerson\n50.78\n\n\nLiam Thorne\nPerson\n41.81\n\n\nHaacklee Harbor\nLocation\n41.30\n\n\nSentinel\nVessel\n34.54\n\n\nGreen Guardians\nOrganization\n27.51\n\n\nPaackland Harbor\nLocation\n27.08\n\n\nDavis\nPerson\n22.36\n\n\nEcoVigil\nVessel\n12.63\n\n\nRodriguez\nPerson\n11.75\n\n\nNorthern Light\nVessel\n9.76\n\n\nSailor Shifts Team\nOrganization\n7.34\n\n\nHorizon\nVessel\n6.72\n\n\nMarlin\nVessel\n6.23\n\n\nSeawatch\nVessel\n5.20\n\n\nElise\nPerson\n4.60\n\n\nSamantha Blake\nPerson\n4.49\n\n\nSerenity\nVessel\n0.81\n\n\nKnowles\nVessel\n0.50\n\n\nSmall Fry\nPerson\n0.00\n\n\nGlitters Team\nOrganization\n0.00\n\n\nOsprey\nVessel\n0.00\n\n\nCity Officials\nGroup\n0.00\n\n\n\n\n\n\n\nShow code\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n\n\n\nDegree Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\ndegree\n\n\n\n\nMako\nVessel\n37\n\n\nOceanus City Council\nOrganization\n28\n\n\nReef Guardian\nVessel\n27\n\n\nRemora\nVessel\n21\n\n\nV. Miesel Shipping\nOrganization\n19\n\n\nNeptune\nVessel\n19\n\n\nNadia Conti\nPerson\n17\n\n\nGreen Guardians\nOrganization\n17\n\n\nHimark Harbor\nLocation\n17\n\n\nDavis\nPerson\n16\n\n\nSentinel\nVessel\n16\n\n\nBoss\nPerson\n13\n\n\nEcoVigil\nVessel\n13\n\n\nPaackland Harbor\nLocation\n13\n\n\nMrs. Money\nPerson\n12\n\n\nHorizon\nVessel\n12\n\n\nLiam Thorne\nPerson\n11\n\n\nRodriguez\nPerson\n10\n\n\nMarlin\nVessel\n10\n\n\nSeawatch\nVessel\n9\n\n\nThe Middleman\nPerson\n8\n\n\nSerenity\nVessel\n8\n\n\nNorthern Light\nVessel\n8\n\n\nHaacklee Harbor\nLocation\n8\n\n\nElise\nPerson\n7\n\n\nThe Lookout\nPerson\n7\n\n\nSailor Shifts Team\nOrganization\n7\n\n\nSamantha Blake\nPerson\n6\n\n\nGlitters Team\nOrganization\n4\n\n\nKnowles\nVessel\n4\n\n\nSmall Fry\nPerson\n3\n\n\nOsprey\nVessel\n3\n\n\nCity Officials\nGroup\n1"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#centrality-metrics-and-direct-indirect-influences",
    "href": "main_project_qmd/main_project_qmd/main.html#centrality-metrics-and-direct-indirect-influences",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Centrality Metrics and Direct & Indirect Influences",
    "text": "Centrality Metrics and Direct & Indirect Influences\nBy calculating centrality metrics within Nadia’s two-hop ego network, we observe that the most influential nodes in her environment—by PageRank, betweenness, and degree—are Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia’s information flow and access to other parts of the network.\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n\n3.5.1 - PageRank for Nadia Conti\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng &lt;- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 &lt;- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank &lt;- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df &lt;- as_data_frame(ego_1, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n3.5.2 - Betweenness for Nadia Conti\n\n\nShow code\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness &lt;- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n3.5.3 - Degree for Nadia Conti\n\n\nShow code\n# 1. Compute Degree for the ego network\nV(ego_1)$degree &lt;- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n1c. With a focus on “Nadia Conti”, the visuals above could determine who has influence over this person.\n\n\n\n\nDegree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\nSeveral other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia’s network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that Nadia’s environment is both diverse and robust.\nDirect Connections\nThese direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti’s node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\nPeople: Elise, Liam Thorne, Davis, Rodriguez\nOrganization: V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\nVessel: Neptune, Marlin, Remora, Sentinel\nLocation: Haacklee Harbor\n\nInterpretation: The PageRank, Betweenness, and Degree centrality plots all consistently show Nadia Conti as a major hub, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\nNadia’s position suggests she is a key connector and influencer but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence—and be influenced—is amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia’s access to information, resources, and strategic decisions."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#strategy-for-question-2",
    "href": "main_project_qmd/main_project_qmd/main.html#strategy-for-question-2",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Strategy for Question 2:",
    "text": "Strategy for Question 2:\n\n1. Filter for Communication Events Only\n\nUse edges that connect Entity → Event (Communication) and Event (Communication) → Entity.\nFocus only on Communication events and extract senders and receivers.\n\n\n\nShow code\n# Extract Communication Events from nodes\ncommunication_events &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, label)\n\n# Extract sent edges: Entity → Communication Event\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% communication_events$id)\n\n# Extract received edges: Communication Event → Entity\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% communication_events$id)\n\n# Join both to get Sender → Communication → Receiver\ncomm_links &lt;- comm_sent_edges %&gt;%\n  select(comm_id = to_id, sender = from_id) %&gt;%\n  inner_join(\n    comm_received_edges %&gt;% select(comm_id = from_id, receiver = to_id),\n    by = \"comm_id\"\n  ) %&gt;%\n  filter(sender != receiver)\n\n\n\n\n2. Construct a Bipartite Graph of Communications\n\nFrom edges:\n\nSender (Entity) → Communication Event\nCommunication Event → Receiver (Entity)\n\nJoin both directions to link:\nEntity A → Communication Event → Entity B → derive Entity A → Entity B communication links.\n\n\n\nShow code\n# Get people and vessel node IDs\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter comm links to include only person ↔ vessel or person ↔ person, etc.\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\n3. Build Communication Network\n\nNodes: People and Vessels only (from mc3_nodes_cleaned).\nEdges: Summarized links between these nodes based on co-involvement in the same communication event.\n\n\n\nShow code\n# Edge weight (number of communications)\nedge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Create node list for graph\nnodes_df &lt;- people_vessels %&gt;%\n  filter(id %in% c(edge_df$sender, edge_df$receiver))\n\n# Build graph object\ncomm_graph &lt;- tbl_graph(nodes = nodes_df, edges = edge_df, directed = FALSE)\n\n\n\n\n4. Apply Community Detection (e.g., Louvain or Walktrap)\n\nUse igraph or tidygraph to detect communities.\nAnnotate communities for possible labels (e.g., Green Guardians, Sailor Shift fans) using node metadata.\n\n\n\nShow code\ncomm_graph &lt;- comm_graph %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\n5. Visualize Network\n\n\nShow code\nshape_map &lt;- c(\"Person\" = \"circle\", \"Vessel\" = \"triangle\")\n\ncolor_map &lt;- c(\n  \"Person\" = \"#fc8d62\",\n  \"Organization\" = \"#6baed6\",\n  \"Vessel\" = \"#66c2a2\",\n  \"Location\" = \"#c6dbef\",\n  \"Nadia Conti\" = \"#ffd92f\"\n)\n\nggraph(comm_graph, layout = \"fr\") +\n  geom_edge_link(aes(width = weight), alpha = 0.2, color = \"gray50\") +\n  geom_node_point(aes(color = group, shape = group), size = 4) +\n  geom_node_text(aes(label = label), repel = TRUE, size = 2.5) +\n  scale_shape_manual(values = shape_map) +\n  scale_color_manual(values = color_map) +\n  theme_graph() +\n  labs(title = \"Communication Clusters Between People and Vessels\",\n       subtitle = \"Communities detected using Louvain algorithm\")\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Get only Person and Vessel nodes\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter communication links for person ↔ vessel/person only\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\nShow code\n# Count number of communications between each sender–receiver pair\ncomm_edge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Build node dataframe from involved IDs only\ncomm_node_df &lt;- people_vessels %&gt;%\n  filter(id %in% unique(c(comm_edge_df$sender, comm_edge_df$receiver))) %&gt;%\n  mutate(\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Vessel\" ~ \"triangle\"\n    ),\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",\n      group == \"Vessel\" ~ \"#66c2a2\",\n      label == \"Nadia Conti\" ~ \"#ffd92f\",\n      TRUE ~ \"#c6dbef\"\n    )\n  )\n\n# Format edges for visNetwork\ncomm_vis_edges &lt;- comm_edge_df %&gt;%\n  rename(from = sender, to = receiver) %&gt;%\n  mutate(width = weight)\n\n\n\n\nShow code\nlibrary(igraph)\n\n# Create igraph object\ngraph_ig &lt;- graph_from_data_frame(comm_vis_edges, directed = FALSE, vertices = comm_node_df)\n\n# Apply Louvain clustering\nlouvain_groups &lt;- cluster_louvain(graph_ig)\ncomm_node_df$group_comm &lt;- as.factor(membership(louvain_groups))\n\n\n\n\nShow code\nlibrary(visNetwork)\n\n# Title heading\ncat(\"### Interactive Network of Communication Between People and Vessels\")\n\n\n### Interactive Network of Communication Between People and Vessels\n\n\nShow code\n# Final interactive visNetwork with consistent styling\nvisNetwork(\n  nodes = comm_node_df,\n  edges = comm_vis_edges\n) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -80,\n      centralGravity = 0.01,\n      springLength = 50,\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n    ),\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\n\nShow code\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nShow code\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nShow code\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -50,   # Increase pull toward center\n      centralGravity = 0.005,        # Lower keeps outer nodes further\n      springLength = 100,            # Length between nodes\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages by sender/receiver\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and label\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Bar plot\nggplot(comm_summary, aes(x = reorder(label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggtext)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages sent and received\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and format\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Create colored labels for x-axis\ncomm_summary &lt;- comm_summary %&gt;%\n  mutate(\n    x_label = paste0(\n      \"&lt;span style='color:\",\n      case_when(\n        sub_type == \"Vessel\" ~ \"#66c2a2\",\n        sub_type == \"Person\" ~ \"#fc8d62\",\n        TRUE ~ \"gray\"\n      ),\n      \"'&gt;\", label, \"&lt;/span&gt;\"\n    )\n  )\n\n# Step 5: Bar Plot with colored axis text\nggplot(comm_summary, aes(x = reorder(x_label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_markdown(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotly)\nlibrary(DT)\n\n# Step 1: Compute message counts\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 2: Combine counts\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\")\n\n# Step 3: Reshape for plotly\ncomm_long &lt;- comm_summary %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Plotly bar chart (interactive)\nplot_ly(\n  comm_long,\n  x = ~label,\n  y = ~count,\n  color = ~direction,\n  colors = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\"),\n  type = 'bar',\n  text = ~paste0(\"Entity: \", label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Count: \", count),\n  hoverinfo = 'text',\n  name = ~direction\n) %&gt;%\n  layout(\n    title = \"Interactive Message Volume by Entity\",\n    barmode = 'group',\n    xaxis = list(title = \"Entity\", tickangle = -45),\n    yaxis = list(title = \"Message Count\")\n  )\n\n\n\n\n\n\n\n\nShow code\ndatatable(\n  comm_summary %&gt;% arrange(desc(sent + received)),\n  options = list(\n    pageLength = 10,\n    autoWidth = TRUE,\n    searchHighlight = TRUE\n  ),\n  colnames = c(\"ID\", \"Name\", \"Sent\", \"Received\", \"Type\")\n)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#strategy-to-tackle-q2b",
    "href": "main_project_qmd/main_project_qmd/main.html#strategy-to-tackle-q2b",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Strategy to Tackle Q2b",
    "text": "Strategy to Tackle Q2b\n\nStep 1: Community Detection with Louvain\n\nUse igraph::cluster_louvain() on the communication network built in 2a (undirected).\nAssign a community ID to each node (nodes_vis$community).\n\n\n\nStep 2: Inspect and Interpret Communities\n\nSummarize the composition of each community by:\n\nNumber of persons/vessels\nTop labels in each group\nKnown keywords (e.g., “Green Guardians”, “Sailor Shift”, vessel names like “Aurora” or “Bluefin”)\n\n\n\n\nStep 3: Color-code the Network by Community\n\nAssign a distinct color to each detected community.\nRetain shape encoding (dot = Person, triangle = Vessel).\n\n\n\nStep 4: Interactive Visualization\n\nUse visNetwork to display the full communication network:\n\nColor nodes by community\nTooltip includes label, type, community\nLegend for each detected community\n\n\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Create igraph from person-vessel edges\ng_comm &lt;- graph_from_data_frame(edges_vis, directed = FALSE, vertices = nodes_vis)\n\n# Louvain detection\nlouvain_clusters &lt;- cluster_louvain(g_comm)\nnodes_vis$louvain_comm &lt;- as.factor(membership(louvain_clusters))\n\n# Walktrap detection\nwalktrap_clusters &lt;- cluster_walktrap(g_comm)\nnodes_vis$walktrap_comm &lt;- as.factor(membership(walktrap_clusters))\n\n# Create color palettes\nmax_comm &lt;- max(as.numeric(nodes_vis$louvain_comm), as.numeric(nodes_vis$walktrap_comm))\ncomm_colors &lt;- brewer.pal(n = min(max_comm, 8), name = \"Set2\")\n\n# Assign community color for each method\nnodes_louvain &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(louvain_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Louvain: \", louvain_comm)\n  )\n\nnodes_walktrap &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(walktrap_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Walktrap: \", walktrap_comm)\n  )\n\n\n\n\nShow code\n# Define consistent edge formatting\nedges_format &lt;- edges_vis %&gt;%\n  mutate(arrows = \"to\", width = width)\n\n# Louvain network\nlouvain_net &lt;- visNetwork(nodes_louvain, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Louvain Communities\"), useGroups = FALSE)\n\n# Walktrap network\nwalktrap_net &lt;- visNetwork(nodes_walktrap, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Walktrap Communities\"), useGroups = FALSE)\n\n\n📌 Louvain Community Network\n\n\nShow code\n# Generate cluster legend for Louvain\nlouvain_legend &lt;- unique(nodes_louvain$louvain_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_louvain$color[nodes_louvain$louvain_comm == comm_id])[1]\n    )\n  })\n\n# Render Louvain network\ncat(\"## Louvain Community Detection Network\")\n\n\n## Louvain Community Detection Network\n\n\nShow code\nvisNetwork(nodes_louvain, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = louvain_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )\n\n\n\n\n\n\n📌 Walktrap Community Network\n\n\nShow code\n# Generate cluster legend for Walktrap\nwalktrap_legend &lt;- unique(nodes_walktrap$walktrap_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_walktrap$color[nodes_walktrap$walktrap_comm == comm_id])[1]\n    )\n  })\n\n# Render Walktrap network\ncat(\"## Walktrap Community Detection Network\")\n\n\n## Walktrap Community Detection Network\n\n\nShow code\nvisNetwork(nodes_walktrap, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = walktrap_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-3a",
    "href": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-3a",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 3a",
    "text": "VAST Challenge Task & Question 3a\n\nExpanding upon your prior visual analytics, determine who is using pseudonyms to communicate, and what these pseudonyms are.\n\nSome that Clepper has already identified include: “Boss”, and “The Lookout”, but there appear to be many more.\nTo complicate the matter, pseudonyms may be used by multiple people or vessels.\n\n\n\n1. Cleaning the dataset\nThe code below is to help us to further clean the data first before we can start to answer question 3\n\n\nShow code\n# Step 1: Define pseudonyms\npseudonym_keywords &lt;- c(\"Boss\", \"The Lookout\", \"The Intern\", \"Mrs. Money\", \n                        \"The Accountant\", \"The Middleman\", \"Small Fry\")\n\n# Step 2: Filter pseudonym nodes (from mc3_nodes_final)\npseudonym_nodes &lt;- mc3_nodes_final %&gt;%\n  filter(\n    sub_type == \"Person\",\n    str_detect(name, regex(paste(pseudonym_keywords, collapse = \"|\"), ignore_case = TRUE))\n  )\n\n# Step 3: Get all edge rows where from/to match pseudonym node indices\npseudonym_node_indices &lt;- pseudonym_nodes$new_index\n\npseudonym_edges_final &lt;- mc3_edges_final %&gt;%\n  filter(from %in% pseudonym_node_indices | to %in% pseudonym_node_indices)\n\n# Step 4: Get only nodes that are involved in these edges\nused_node_indices &lt;- unique(c(pseudonym_edges_final$from, pseudonym_edges_final$to))\n\npseudonym_nodes_final &lt;- mc3_nodes_final %&gt;%\n  filter(new_index %in% used_node_indices) %&gt;%\n  mutate(label_type = ifelse(new_index %in% pseudonym_node_indices, \"Pseudonym\", \"Regular\"))\n\n# Step 5: Reindex nodes to match edge structure (0-based problem fix)\npseudonym_nodes_final &lt;- pseudonym_nodes_final %&gt;%\n  mutate(temp_index = row_number())\n\n# Mapping old new_index to new temp_index (for tbl_graph alignment)\nindex_map &lt;- pseudonym_nodes_final %&gt;%\n  select(old = new_index, new = temp_index)\n\n# Update edges to new 1-based index\npseudonym_edges_final &lt;- pseudonym_edges_final %&gt;%\n  left_join(index_map, by = c(\"from\" = \"old\")) %&gt;%\n  rename(from_new = new) %&gt;%\n  left_join(index_map, by = c(\"to\" = \"old\")) %&gt;%\n  rename(to_new = new) %&gt;%\n  filter(!is.na(from_new), !is.na(to_new)) %&gt;%\n  select(from = from_new, to = to_new, type)\n\n# Step 6: Build graph\npseudonym_graph &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n)\n\n\nBefore we start to answer the questions, let us first test out if the data cleaning is effective, which should be if not you wil not be able to see this!\n\nTest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisations below shows the entities labelled based on their real names or pseudinyms which are labelled differently using color codes so as for easier visualisation.\n\nMethod 1Method 2\n\n\n\n\nShow code\n# Count how many connections each pseudonym has\npseudonym_links &lt;- pseudonym_edges_final %&gt;%\n  left_join(pseudonym_nodes_final, by = c(\"from\" = \"temp_index\")) %&gt;%\n  rename(pseudonym = name) %&gt;%\n  filter(!is.na(pseudonym)) %&gt;%   # ✅ Only valid pseudonym nodes\n  group_by(pseudonym) %&gt;%\n  summarise(connection_count = n()) %&gt;%\n  arrange(desc(connection_count))\n\n\n# Plot it\nggplot(pseudonym_links, aes(x = reorder(pseudonym, connection_count), y = connection_count)) +\n  geom_col(fill = \"tomato\") +\n  coord_flip() +\n  labs(\n    title = \"Communication Frequency by Pseudonym\",\n    x = \"Pseudonym Name\",\n    y = \"Number of Connections\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Prepare node dataframe\nnodes_vis &lt;- pseudonym_nodes_final %&gt;%\n  transmute(\n    id = temp_index,\n    label = name,\n    group = ifelse(label_type == \"Pseudonym\", \"Pseudonym\", \"Regular\"),\n    title = paste(\"Name:\", name, \"&lt;br&gt;Type:\", label_type)\n  )\n\n# Prepare edge dataframe\nedges_vis &lt;- pseudonym_edges_final %&gt;%\n  transmute(\n    from = from,\n    to = to,\n    label = type,\n    arrows = \"to\"\n  )\n\n# Create visNetwork\nvisNetwork(nodes_vis, edges_vis, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visGroups(groupname = \"Regular\", color = \"steelblue\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\"),\n    list(label = \"Regular\", shape = \"dot\", color = \"steelblue\")\n  )) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visPhysics(stabilization = TRUE)\n\n\n\n\n\n\n\n\n\nAs we can see, there are 2 methods that we can use to visualise this case. The aim of this visualisation is to help clepper to visually identufy which nodes are pseudonuyms, and how are they connected to the real identity. Suspicious names or aliases will appear isolated\n\nFrom this visualisation, we can easily determine which names are Pseudonyms. These names can be easily identified via the color codes\nWe can easily trace who talks to and/or through aliases\nThis visualisation makes it easier for Clepper to spot suspicious names\n\n\n\n2. Question 3b\n\nDescribe how your visualizations make it easier for Clepper to identify common entities in the knowledge graph.\n\n\nCodeVisualisation output\n\n\n\n\nShow code\n# Q3b: Extract edges involving those pseudonyms\n# Build pseudonym network using tidygraph\npseudonym_graph_tbl &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n) %&gt;%\n  mutate(degree_centrality = centrality_degree(mode = \"all\"))  # centrality values added to nodes\n\n# Turn into tibble for ggplot\ntop_central &lt;- pseudonym_graph_tbl %&gt;%\n  as_tibble() %&gt;%\n  filter(label_type == \"Pseudonym\") %&gt;%\n  arrange(desc(degree_centrality)) %&gt;%\n  slice_head(n = 10)\n\n# Plot\nggplot(top_central, aes(x = reorder(name, degree_centrality), y = degree_centrality)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Central Pseudonym Entities\",\n    x = \"Pseudonym Name\",\n    y = \"Degree Centrality\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Q3b: Extract edges involving those pseudonyms\n# Build pseudonym network using tidygraph\npseudonym_graph_tbl &lt;- tbl_graph(\n  nodes = pseudonym_nodes_final,\n  edges = pseudonym_edges_final,\n  directed = TRUE\n) %&gt;%\n  mutate(degree_centrality = centrality_degree(mode = \"all\"))  # centrality values added to nodes\n\n# Turn into tibble for ggplot\ntop_central &lt;- pseudonym_graph_tbl %&gt;%\n  as_tibble() %&gt;%\n  filter(label_type == \"Pseudonym\") %&gt;%\n  arrange(desc(degree_centrality)) %&gt;%\n  slice_head(n = 10)\n\n# Plot\nggplot(top_central, aes(x = reorder(name, degree_centrality), y = degree_centrality)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Central Pseudonym Entities\",\n    x = \"Pseudonym Name\",\n    y = \"Degree Centrality\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nThe visualisation shows a bar chart of degree centrality that shows the tiop 10 most connectd pseudonyms. The aim of this graph is to heko clepper to quantify influence by measuring the cetrakity of the pseudonyms for deeper investigation. It also helps Clepper t identify who are the key players who may be controlling the flow of information\n\nThese visualisation helps Clepper to identify wich of the pseudonyms are most active\nWe can see that the nodes act as central hubs wihin the pseudonym network\nThis visualisation can help clepper to prioritize pseudionyms first as part of his investigations\n\n\n\n3. Question 3c\nCode\n\n\nShow code\nshared_pseudonyms &lt;- pseudonym_nodes_final %&gt;%\n  group_by(name) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\n# Create nodes: both entities and pseudonyms\nvis_nodes_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(id = id, \n            label = id, \n            group = \"Entity\",\n            title = paste(\"Entity ID:\", id)) %&gt;%\n  bind_rows(\n    shared_pseudonyms %&gt;%\n      select(id = name) %&gt;%\n      distinct() %&gt;%\n      mutate(label = id,\n             group = \"Pseudonym\",\n             title = paste(\"Pseudonym:\", id))\n  )\n\nvis_edges_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(from = id, to = name)\n\nvisNetwork(vis_nodes_3c, vis_edges_3c, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Entity\", color = \"steelblue\") %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Entity\", shape = \"dot\", color = \"steelblue\"),\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\")\n  )) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisualisation Output\n\n\nShow code\nshared_pseudonyms &lt;- pseudonym_nodes_final %&gt;%\n  group_by(name) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\n# Create nodes: both entities and pseudonyms\nvis_nodes_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(id = id, \n            label = id, \n            group = \"Entity\",\n            title = paste(\"Entity ID:\", id)) %&gt;%\n  bind_rows(\n    shared_pseudonyms %&gt;%\n      select(id = name) %&gt;%\n      distinct() %&gt;%\n      mutate(label = id,\n             group = \"Pseudonym\",\n             title = paste(\"Pseudonym:\", id))\n  )\n\nvis_edges_3c &lt;- shared_pseudonyms %&gt;%\n  transmute(from = id, to = name)\n\nvisNetwork(vis_nodes_3c, vis_edges_3c, height = \"600px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visGroups(groupname = \"Entity\", color = \"steelblue\") %&gt;%\n  visGroups(groupname = \"Pseudonym\", color = \"tomato\") %&gt;%\n  visLegend(addNodes = list(\n    list(label = \"Entity\", shape = \"dot\", color = \"steelblue\"),\n    list(label = \"Pseudonym\", shape = \"dot\", color = \"tomato\")\n  )) %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nThe visualisation used for this part of the question is an interactive graph using the visNetwork entity which shows the edges and nodes. The blue nodes indicates the entities (may be people or vessels), red nodes which is the pseudonym names and edges which indicates which entity uses what pseudonym. The aim of this visualisation is to expose the reusing of an alias whereby the same pseudonym is tied and connected to multiple entities\n\nThis visualisation helps Clepper to easily identify which pseudonyms are reused by multiple entities\nThis breaks the assumed connection between identity and name revealing many one-to-one mapping\nThis therefore can help Clepper to detect deception strategies such as multiple people pretending to have one single alias, hence minimising the risks of impersonation."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-4a",
    "href": "main_project_qmd/main_project_qmd/main.html#vast-challenge-task-question-4a",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "VAST Challenge Task & Question 4a",
    "text": "VAST Challenge Task & Question 4a\n\nClepper suspects that Nadia Conti, who was formerly entangled in an illegal fishing scheme, may have continued illicit activity within Oceanus.\n\nThrough visual analytics, provide evidence that Nadia is, or is not, doing something illegal.\n\n\n\n1. Extracting Nadia’s data\n\n\nShow code\nnodes &lt;- MC3$nodes\nedges &lt;- MC3$edges\n\n# Extract communication events\ncomms &lt;- nodes %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, content)\n\n# Link to sender & receiver\nsent_edges &lt;- edges %&gt;% filter(type == \"sent\") %&gt;%\n  select(source = source, comm_id = target)\n\nrecv_edges &lt;- edges %&gt;% filter(type == \"received\") %&gt;%\n  select(comm_id = source, target = target)\n\n# Merge\ncomms_data &lt;- comms %&gt;%\n  left_join(sent_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(sender = source) %&gt;%\n\n  left_join(recv_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(receiver = target)\n\n# Add sender/receiver names\nmc3_nodes_cleaned &lt;- nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE)\n\ncomms_data &lt;- comms_data %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver\" = \"id\"))\n\n# Count Nadia's messages\nnadia_counts &lt;- comms_data %&gt;%\n  summarise(\n    Sent = sum(sender_label == \"Nadia Conti\", na.rm = TRUE),\n    Received = sum(receiver_label == \"Nadia Conti\", na.rm = TRUE)\n  ) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Type\", values_to = \"Count\") %&gt;%\n  mutate(\n    Percent = Count / sum(Count),\n    Label = paste0(round(Percent * 100), \"%\\n(\", Count, \" msgs)\")\n  )\n\n\n\n\n2. Message count of Nadia\n\n\nShow code\nggplot(nadia_counts, aes(x = Count, y = reorder(Type, Count), fill = Type)) +\n  geom_col(color = \"white\") +\n  geom_text(aes(label = paste0(Count, \" msgs (\", round(Percent * 100), \"%)\")),\n            hjust = -0.1, size = 4) +\n  scale_fill_manual(values = c(\"Sent\" = \"deepskyblue3\", \"Received\" = \"cyan\")) +\n  labs(title = paste0(\"Nadia Conti's Messages (Total: \", sum(nadia_counts$Count), \")\"),\n       x = \"Message Count\", y = NULL) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(face = \"bold\")) +\n  xlim(0, max(nadia_counts$Count) * 1.2)\n\n\n\n\n\n\n\n\n\n\n\n3. Message frequency of Nadia\n\n\nShow code\n# Make sure nadia_data is created\nnadia_data &lt;- comms_data %&gt;%\n  filter(sender_label == \"Nadia Conti\" | receiver_label == \"Nadia Conti\") %&gt;%\n  left_join(nodes %&gt;% select(id, timestamp), by = c(\"id\" = \"id\")) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(date = as.Date(timestamp), hour = hour(timestamp))\n\n# Create daily_freq\ndaily_freq &lt;- nadia_data %&gt;%\n  group_by(date) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n# Create hourly_freq\nhourly_freq &lt;- nadia_data %&gt;%\n  group_by(date, hour) %&gt;%\n  summarise(count = n(), .groups = \"drop\")\n\n\n\n3.1 Daily\n\n\nShow code\nggplot(daily_freq, aes(x = date, y = count)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = count), vjust = -0.5, size = 3) +\n  labs(\n    title = \"Nadia Conti's Daily Message Frequency\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n3.2 Hourly\n\n\nShow code\nlibrary(plotly)\n\nplot_ly(\n  data = hourly_freq,\n  x = ~hour,\n  y = ~count,\n  color = ~as.factor(date),\n  type = 'bar',\n  text = ~paste(\"Date:\", date, \"&lt;br&gt;Hour:\", hour, \"&lt;br&gt;Messages:\", count),\n  hoverinfo = 'text'\n) %&gt;%\n  layout(\n    barmode = 'dodge',  # use 'stack' if you prefer stacked bars\n    title = \"Nadia Conti's Hourly Message Frequency\",\n    xaxis = list(title = \"Hour of Day\"),\n    yaxis = list(title = \"Message Count\"),\n    legend = list(title = list(text = \"Date\"))\n  )\n\n\n\n\n\n\n\n\n\n4. Nadia’s relationship pattern\n\n\nShow code\nlibrary(ggplot2)\n\n# Count relationships by type\nrelationship_counts &lt;- mc3_edges_cleaned %&gt;%\n  filter(type != \"sent\", type != \"received\") %&gt;%  # Focus on relationships, not communication\n  count(type, sort = TRUE)\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(visNetwork)\n\n# Summarise Nadia's communication edges\nnadia_edges &lt;- nadia_data %&gt;%\n  count(sender_label, receiver_label) %&gt;%\n  filter(!is.na(sender_label), !is.na(receiver_label)) %&gt;%\n  rename(from = sender_label, to = receiver_label, value = n)\n\n# Get sender + receiver entity info\n# Get type info for sender and receiver\nentity_info &lt;- bind_rows(\n  nadia_data %&gt;%\n    left_join(mc3_nodes_cleaned %&gt;% select(id, name = label, type = sub_type),\n              by = c(\"sender\" = \"id\")) %&gt;%\n    select(name, type),\n  nadia_data %&gt;%\n    left_join(mc3_nodes_cleaned %&gt;% select(id, name = label, type = sub_type),\n              by = c(\"receiver\" = \"id\")) %&gt;%\n    select(name, type)\n) %&gt;%\n  distinct()\n\n# Build node table\nnadia_nodes &lt;- tibble(name = unique(c(nadia_edges$from, nadia_edges$to))) %&gt;%\n  left_join(entity_info, by = \"name\") %&gt;%\n  mutate(\n    group = ifelse(name == \"Nadia Conti\", \"Nadia Conti\", type),\n    id = name,\n    label = name,\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",       \n      group == \"Organization\" ~ \"#6baed6\",\n      group == \"Vessel\" ~ \"#66c2a2\",      \n      group == \"Location\" ~ \"#c6dbef\",    \n      group == \"Nadia Conti\" ~ \"#ffd92f\", \n      TRUE ~ \"#d9d9d9\"\n    ),\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Organization\" ~ \"square\",\n      group == \"Vessel\" ~ \"triangle\",\n      group == \"Location\" ~ \"diamond\",\n      group == \"Nadia Conti\" ~ \"star\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Render network\nvisNetwork(nodes = nadia_nodes, edges = nadia_edges) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(gravitationalConstant = -25, centralGravity = 0.01, springLength = 50, springConstant = 0.02),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Organization\", shape = \"square\", color = \"#6baed6\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\"),\n      list(label = \"Location\", shape = \"diamond\", color = \"#c6dbef\"),\n      list(label = \"Nadia Conti\", shape = \"star\", color = \"#ffd92f\")\n    ),\n    width = 0.2,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\n\n5. Nadia’s most frequent commuter\n\n\nShow code\n# Get communication events linked to Nadia\nnadia_comm_ids &lt;- edges %&gt;%\n  filter(type == \"sent\" | type == \"received\") %&gt;%\n  filter(source == mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"] |\n         target == mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]) %&gt;%\n  mutate(comm_id = ifelse(type == \"sent\", target, source)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Get edges related to these communications\nnadia_related_edges &lt;- edges %&gt;%\n  filter(source %in% nadia_comm_ids | target %in% nadia_comm_ids)\n\n# Get people connected (excluding comm events + Nadia herself)\nnadia_id &lt;- mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]\n\nnadia_contacts_ids &lt;- nadia_related_edges %&gt;%\n  mutate(person_id = ifelse(source %in% nadia_comm_ids, target, source)) %&gt;%\n  filter(!person_id %in% nadia_comm_ids, person_id != nadia_id) %&gt;%\n  count(person_id, sort = TRUE)\n\n# Join with node labels\ntop_contacts_named &lt;- nadia_contacts_ids %&gt;%\n  left_join(nodes %&gt;% filter(sub_type == \"Person\") %&gt;% select(id, name = label),\n            by = c(\"person_id\" = \"id\")) %&gt;%\n  filter(!is.na(name))\n\n\n\n\nShow code\ntop_contacts_named %&gt;%\n  slice_max(n, n = 3) %&gt;%\n  ggplot(aes(x = reorder(name, n), y = n)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 3 Contacts Communicating with Nadia Conti\",\n    x = \"Contact Person\",\n    y = \"Number of Messages\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(DT)\n\nnadia_id &lt;- mc3_nodes_cleaned$id[mc3_nodes_cleaned$label == \"Nadia Conti\"]\n\n# Nadia's communication event IDs\nnadia_comm_ids &lt;- edges %&gt;%\n  filter(type == \"sent\" | type == \"received\") %&gt;%\n  filter(source == nadia_id | target == nadia_id) %&gt;%\n  mutate(comm_id = ifelse(type == \"sent\", target, source)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Top contact comm IDs\ntop_contact_comm_ids &lt;- edges %&gt;%\n  filter(\n    (source %in% nadia_comm_ids & target %in% top_contacts_named$person_id) |\n    (target %in% nadia_comm_ids & source %in% top_contacts_named$person_id)\n  ) %&gt;%\n  mutate(comm_id = ifelse(source %in% nadia_comm_ids, source, target)) %&gt;%\n  pull(comm_id) %&gt;%\n  unique()\n\n# Get comm event details\nnadia_messages &lt;- nodes %&gt;%\n  filter(id %in% top_contact_comm_ids) %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, timestamp, content) %&gt;%\n  left_join(edges %&gt;% filter(type == \"sent\") %&gt;% select(id = target, sender = source),\n            by = \"id\") %&gt;%\n  left_join(edges %&gt;% filter(type == \"received\") %&gt;% select(id = source, receiver = target),\n            by = \"id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_name = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_name = label), by = c(\"receiver\" = \"id\")) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    sender_receiver = paste(sender_name, \"→\", receiver_name)\n  ) %&gt;%\n  arrange(timestamp) %&gt;%\n  select(timestamp, sender_receiver, content)\n\n# Display\nDT::datatable(\n  nadia_messages,\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE,\n    initComplete = htmlwidgets::JS(\n      \"function(settings, json) {\",\n      \"$(this.api().table().header()).css({'background-color': '#f8f9fa', 'color': '#333'});\",\n      \"}\"\n    )\n  ),\n  rownames = FALSE,\n  class = 'stripe hover compact',\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:16px; color:#444;',\n    'Messages'\n  )\n)\n\n\n\n\n\n\n\n\n6. Temporal + suspicious event alignment\n\n6.1 Showing Nadia’s unusually active days\n\n\nShow code\n# Compute mean + SD of daily messages\ndaily_summary &lt;- daily_freq %&gt;%\n  summarise(mean_count = mean(count), sd_count = sd(count))\n\n# Flag days with unusually high message counts\nspike_days &lt;- daily_freq %&gt;%\n  filter(count &gt; daily_summary$mean_count + 2 * daily_summary$sd_count)\n\n# Show spike days\nprint(spike_days)\n\n\n# A tibble: 1 × 2\n  date       count\n  &lt;date&gt;     &lt;int&gt;\n1 2040-10-08     9\n\n\n\n\n6.2 Suspicious dates\n\n\nShow code\nsuspicious_dates &lt;- as.Date(c(\"2040-10-05\", \"2040-10-08\", \"2040-10-11\")) # example reef closure, approvals, etc.\n\n\n\n\nShow code\nspike_days %&gt;%\n  mutate(suspicious = ifelse(date %in% suspicious_dates, \"YES\", \"NO\"))\n\n\n# A tibble: 1 × 3\n  date       count suspicious\n  &lt;date&gt;     &lt;int&gt; &lt;chr&gt;     \n1 2040-10-08     9 YES       \n\n\n\n\nShow code\nlibrary(plotly)\nlibrary(dplyr)\n\n# Suppose suspicious dates (replace with real ones)\nsuspicious_dates &lt;- as.Date(c(\"2040-10-05\", \"2040-10-08\", \"2040-10-11\"))\n\n# Compute threshold\ndaily_summary &lt;- daily_freq %&gt;%\n  summarise(mean_count = mean(count), sd_count = sd(count))\n\nthreshold &lt;- daily_summary$mean_count + 2 * daily_summary$sd_count\n\n# Add status column\ndaily_freq_plot &lt;- daily_freq %&gt;%\n  mutate(\n    status = case_when(\n      date %in% suspicious_dates ~ \"Suspicious Date\",\n      count &gt; threshold ~ \"Spike\",\n      TRUE ~ \"Normal\"\n    )\n  )\n\n# Assign colors\nstatus_colors &lt;- c(\n  \"Normal\" = \"steelblue\",\n  \"Spike\" = \"red\",\n  \"Suspicious Date\" = \"orange\"\n)\n\n# Build Plotly bar chart\nplot_ly(\n  data = daily_freq_plot,\n  x = ~date,\n  y = ~count,\n  type = 'bar',\n  color = ~status,\n  colors = status_colors,\n  text = ~paste(\"Date:\", date, \"&lt;br&gt;Messages:\", count, \"&lt;br&gt;Status:\", status),\n  hoverinfo = 'text'\n) %&gt;%\n  layout(\n    title = \"Nadia Conti's Daily Communication\",\n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"Message Count\"),\n    barmode = 'group',\n    legend = list(title = list(text = \"Status\"))\n  ) %&gt;%\n  add_lines(\n    x = ~date,\n    y = rep(threshold, nrow(daily_freq_plot)),\n    line = list(dash = 'dash', color = 'red'),\n    name = 'Spike Threshold',\n    inherit = FALSE\n  )\n\n\n\n\n\n\n\n\n\n7. Drilling down on spike + flagged date\n\n7.1 Extract Nadia’s message from Oct 8\n\n\nShow code\n# Build fresh nadia_data with content included at the start\nnadia_data &lt;- comms %&gt;%\n  left_join(sent_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(sender = source) %&gt;%\n  left_join(recv_edges, by = c(\"id\" = \"comm_id\")) %&gt;%\n  rename(receiver = target) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver\" = \"id\")) %&gt;%\n  left_join(nodes %&gt;% select(id, timestamp), by = \"id\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    hour = hour(timestamp)\n  ) %&gt;%\n  filter(sender_label == \"Nadia Conti\" | receiver_label == \"Nadia Conti\") %&gt;%\n  filter(!is.na(timestamp))\n\n\n\n\nShow code\noct8_msgs &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  select(timestamp, sender_label, receiver_label, content) %&gt;%\n  arrange(timestamp)\n\nDT::datatable(\n  oct8_msgs,\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE,\n    columnDefs = list(\n      list(\n        targets = 3,  # adjust if content is not 3rd col\n        render = JS(\n          \"function(data, type, row, meta) {\",\n          \"return type === 'display' && data.length &gt; 50 ?\",\n          \"'&lt;span title=\\\"' + data + '\\\"&gt;' + data.substr(0, 50) + '...&lt;/span&gt;' : data;\",\n          \"}\"\n        )\n      )\n    )\n  ),\n  rownames = FALSE,\n  class = 'stripe hover compact',\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:14px; color:#444;',\n    '📌 Nadia Conti Messages on Oct 8, 2040'\n  )\n)\n\n\n\n\n\n\n\n\n7.2 Keywords of Oct 8\nShowing messages on Oct 8 mentioning suspicious terms of:\n\npermit\napproval\nreef\ncargo\nshipment\nillegal\n\n\n\nShow code\n# Define suspicious keywords\nkeywords &lt;- c(\"permit\", \"approval\", \"reef\", \"cargo\", \"shipment\", \"dock\", \"illegal\")\n\n# Filter messages on Oct 8 with suspicious terms\noct8_flagged_msgs &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  filter(!is.na(content)) %&gt;%\n  filter(grepl(paste(keywords, collapse = \"|\"), content, ignore.case = TRUE)) %&gt;%\n  select(timestamp, sender_label, receiver_label, content) %&gt;%\n  arrange(timestamp)\n\n# Display in interactive table\nDT::datatable(\n  oct8_flagged_msgs,\n  options = list(pageLength = 5, autoWidth = TRUE),\n  rownames = FALSE,\n  caption = htmltools::tags$caption(\n    style = 'caption-side: top; text-align: left; font-size:16px; color:#444;',\n    '📌 Oct 8 Messages with Suspicious Keywords'\n  )\n)\n\n\n\n\n\n\n\n\n7.3 Network of Oct 8 communication\n\n\nShow code\nlibrary(visNetwork)\n\n# Summarize comms on Oct 8\noct8_edges &lt;- nadia_data %&gt;%\n  filter(date == as.Date(\"2040-10-08\")) %&gt;%\n  count(sender_label, receiver_label) %&gt;%\n  filter(!is.na(sender_label), !is.na(receiver_label)) %&gt;%\n  rename(from = sender_label, to = receiver_label, value = n)\n\n# Build node list\noct8_nodes &lt;- tibble(name = unique(c(oct8_edges$from, oct8_edges$to))) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(label, sub_type), by = c(\"name\" = \"label\")) %&gt;%\n  mutate(\n    group = ifelse(name == \"Nadia Conti\", \"Nadia Conti\", sub_type),\n    id = name,\n    label = name\n  )\n\n# Render network\nvisNetwork(oct8_nodes, oct8_edges) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 456) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLegend()\n\n\n\n\n\n\nNadia is heavily involved in:\n\nDiscussion of Nemo Reef, permits, foundation work\nCoordinating payments, doubling fees, Harbor Master cooperation\nAdjusting schedules to avoid council suspicion\n\nHighly suspicious tone: manipulation, concealment, operational coordination beyond scope.\n\n\n\n8. Linking Oct 8 comms to permits, approvals, or vessel activity\n\n\nShow code\nsuspicious_events_alt &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type %in% c(\"VesselMovement\", \"Monitoring\", \"HarborReport\", \"Fishing\", \"Enforcement\")) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(timestamp &gt;= as.POSIXct(\"2040-10-08\"))\n\nDT::datatable(\n  suspicious_events_alt %&gt;%\n    select(type, label, sub_type, id, timestamp, monitoring_type, findings),\n  options = list(\n    pageLength = 5,\n    autoWidth = TRUE,\n    scrollX = TRUE\n  ),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\nShow code\nlibrary(dplyr)\nlibrary(plotly)\n\n# 1️⃣ Prepare entity-related vessel/harbor events\nentity_events &lt;- suspicious_events_alt %&gt;%\n  filter(str_detect(findings, regex(\"Neptune|Miesel|Mako\", ignore_case = TRUE))) %&gt;%\n  mutate(entity = case_when(\n    str_detect(findings, regex(\"Neptune\", ignore_case = TRUE)) ~ \"Neptune\",\n    str_detect(findings, regex(\"Miesel\", ignore_case = TRUE)) ~ \"Miesel\",\n    str_detect(findings, regex(\"Mako\", ignore_case = TRUE)) ~ \"Mako\",\n    TRUE ~ \"Other\"\n  ))\n\n# 2️⃣ Build interactive plot\nplot_ly() %&gt;%\n  # Nadia comms\n  add_markers(\n    data = nadia_data,\n    x = ~timestamp,\n    y = ~\"Nadia Message\",\n    marker = list(color = \"red\", size = 10),\n    text = ~paste0(\"Nadia Message&lt;br&gt;\", timestamp),\n    hoverinfo = \"text\",\n    name = \"Nadia Message\"\n  ) %&gt;%\n  # Neptune events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Neptune\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#1f77b4\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Neptune Event\"\n  ) %&gt;%\n  # Miesel events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Miesel\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#17becf\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Miesel Event\"\n  ) %&gt;%\n  # Mako events\n  add_markers(\n    data = entity_events %&gt;% filter(entity == \"Mako\"),\n    x = ~timestamp,\n    y = ~entity,\n    marker = list(color = \"#7f7f7f\", size = 10),\n    text = ~paste0(entity, \" Event&lt;br&gt;\", findings),\n    hoverinfo = \"text\",\n    name = \"Mako Event\"\n  ) %&gt;%\n  layout(\n    title = \"Nadia Comms + Vessel/Harbor Events\",\n    xaxis = list(title = \"Time\"),\n    yaxis = list(title = \"\"),\n    legend = list(orientation = \"h\", x = 0.1, y = -0.3)\n  )\n\n\n\n\n\n\nThe interactive timeline highlights that Nadia Conti’s communications were closely followed by vessel/harbor events involving Neptune, V. Miesel Shipping, and Mako. Notably:\n•   On **Oct 8**, Nadia’s messages spiked, coinciding with planned operations at Nemo Reef.\n\n•   Shortly afterward, vessel activities linked to **Neptune, Miesel, and Mako** were logged.\n\n•   This temporal proximity strongly suggests coordination between Nadia and these entities.\nThere is no evidence of formal approvals or permits linked to these activities, pointing to potential covert operations."
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#question-4b---are-cleppers-suspicions-justified",
    "href": "main_project_qmd/main_project_qmd/main.html#question-4b---are-cleppers-suspicions-justified",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Question 4B - Are Clepper’s suspicions justified?",
    "text": "Question 4B - Are Clepper’s suspicions justified?\n\n1. Findings\n1.1 Communication Activity\n\nNadia exchanged a total of 26 messages, of which 31% were sent and 69% received.\nAn unusually high volume of messages was recorded on 2040-10-08 (9 messages), exceeding the normal daily message count and crossing the defined spike threshold.\nMessaging patterns were concentrated between 08:00 and 12:00, suggesting focused coordination during operational hours.\n\n1.2 Relationship Network\n\nNetwork visualizations indicate Nadia as a central figure in communications with key individuals (Davis, Liam Thorne, Elise) and entities (Neptune, Marlin, V. Miesel Shipping).\nThe strongest links were observed between Nadia and Davis, Neptune, and Liam Thorne, with frequent exchanges regarding sensitive operational matters.\n\n1.3 Content of Communication\n\nThematic analysis identified frequent mentions of permits, approvals, reef, foundation work, shipment, and cargo.\nSeveral messages contained concerning elements, including discussions of doubling fees for cooperation, adjustments to patrol schedules, and concealing operations from the council.\n\n1.4 Temporal and Event Alignment\n\nTimeline analysis shows that Nadia’s communication spikes closely preceded vessel activities involving Neptune, V. Miesel Shipping, and Mako.\nThis temporal alignment strongly suggests a coordinated effort linked to unauthorized operations at Nemo Reef.\n\n\n\nConclusion\nThe evidence supports Clepper’s suspicions. Nadia’s communication patterns, network centrality, message content, and the alignment with vessel activity point to her active involvement in potentially covert and unauthorized operations. There is no indication of formal approvals associated with these activities, raising further concerns about compliance and legality."
  },
  {
    "objectID": "Mtg_Minutes/Meeting01.html",
    "href": "Mtg_Minutes/Meeting01.html",
    "title": "Minutes 1",
    "section": "",
    "text": "Meeting Minutes 1"
  },
  {
    "objectID": "Mtg_Minutes/Meeting03.html",
    "href": "Mtg_Minutes/Meeting03.html",
    "title": "Minutes 3",
    "section": "",
    "text": "Meeting Minutes 3"
  },
  {
    "objectID": "project_proposal/Proposal_DC.html",
    "href": "project_proposal/Proposal_DC.html",
    "title": "Proposal",
    "section": "",
    "text": "“When you have eliminated the impossible, whatever remains, however improbable, must be the truth.”\n— Sherlock Holmes\nThey call it paradise. Oceanus — a remote island once known for its fishing heritage — now hosts yacht parties, drone shoots, and conservation protests. But for me, Clepper Jessen, it’s something else entirely: a mystery waiting to be unravelled.\nTwo weeks ago, something changed. Nemo Reef was abruptly shut down. Sailor Shift’s glamorous arrival was followed by a sudden storm of encrypted radio chatter, midnight movements, and fast-tracked approvals. Names I thought were long gone began to reappear — only this time, hidden behind pseudonyms like “The Boss” and “The Lookout.”\nWith my intern, I intercepted and parsed every message I could get my hands on. But a pile of transcripts, no matter how detailed, is like a thousand-piece puzzle without the picture on the box. I needed a new tool — one that could see what I couldn’t and connect what others wouldn’t.\nThat’s where this application comes in.\nThis is no ordinary dashboard. It is an investigative lens — built to:\n\nUncover temporal anomalies that hint at coordination,\nTrace power and influence through hidden networks,\nDecode aliases and reveal who’s hiding behind what name,\nSurface clusters of collaboration, dissent, or manipulation, and\nPiece together a case around suspects like Nadia Conti, whose past criminal ties may not be so past after all.\n\nWith every filter I apply and every link I explore, I come closer to the truth.\nOceanus wants to forget. My team is here to remember.\n\n\n\nOceanus is at a crossroads. Once a tranquil fishing haven, it now stands as a microcosm of modern tension — a battleground between commercial tourism, environmental activism, and quiet corruption. The sudden influx of celebrities, bureaucrats, and shadowy middlemen has triggered suspicion, particularly after the abrupt closure of Nemo Reef.\nAs an investigative journalist, I’ve seen patterns before. But this one? It’s tangled in layers of aliases, logistics, and unlikely partnerships. That’s why I needed a visual analytics tool — not just to read the data, but to interrogate it.\nThis project is driven by a desire to democratize investigative intelligence. Through interactive and intuitive visuals, it empowers those like me — and anyone who seeks truth — to:\n\nDetect daily patterns that ordinary eyes miss,\nFollow the thread of influence across vessels, people, and organizations,\nReveal pseudonyms and hold disguised actors accountable,\nMap out group behaviour and thematic alliances, and\nCollect visual evidence that separates fact from fabrication — especially in the case of Nadia Conti.\n\nBecause data may tell a story. But visual analytics lets us solve the case.\n\n\n\nThe intercepted radio communications have been transformed into a knowledge graph, capturing two weeks of activity between individuals, vessels, and organizations in Oceanus. Each node represents an entity, while edges represent relationships such as communication, approvals, or co-mentioning events. This knowledge graph also captures metadata like timestamps, topics, and pseudonyms.\nClepper Jessen suspects that behind the benign front of ocean tourism lies an orchestrated effort involving corruption, covert coordination, and manipulation of identity. Our task is to convert this static graph into an interactive investigative tool that surfaces hidden patterns and supports journalistic inquiry.\nInvestigative Problems include:\n🔸 Temporal Anomalies & Daily Rhythms\nMessages cluster around the same time daily, suggesting habitual or coordinated behaviour. Tracking shifts over time may expose operational changes before and after critical events (e.g., the filming announcement).\nGoal: Uncover periodic communication spikes, shifts in timing patterns, and correlation to entity activity.\n🔸Influence Mapping & Relationship Flows\nPower dynamics can be inferred from communication directionality and frequency. Entities like Sailor Shift, officials, and conservationists may be central nodes with high influence.\nGoal: Use graph metrics (e.g., betweenness, eigenvector centrality) to identify influencers and track their evolving roles.\n🔸Group Affiliation & Topic Clustering\nEntities form clusters — such as the Green Guardians or celebrity entourages — based on shared contacts or themes. Group-specific topics and interaction patterns can reveal operational roles.\nGoal: Detect communities using clustering algorithms and associate them with dominant discussion themes (e.g., tourism logistics vs. environmental protests).\n🔸Pseudonym Usage & Identity Masking\nPseudonyms like “The Boss” or “The Lookout” conceal true identities and complicate accountability. Some aliases may be reused across actors or tied to specific event types.\nGoal: Identify single or multi-user pseudonyms, map their activity and cross-compare behaviourally with known entities to uncover deception.\n🔸Evidence of Misconduct – Nadia Conti Focus\nClepper believes Nadia Conti may be covertly operating under new identities or aliases. Her history with illegal fishing makes her a person of interest in new corruption schemes.\nGoal: Map Nadia’s communication footprint, link indirect relationships via pseudonyms, and surface anomalies suggesting concealment or collusion.\n\n\n\nWe will develop a modular Shiny web app to convert the static knowledge graph into an interactive, investigative interface tailored to Clepper’s needs. Each module corresponds to a key problem statement.\nModule A: Temporal Pattern Explorer\nGoal: Visualize daily cycles and anomalies in communication frequency and topic intensity.\n\nInput: Message timestamp, sender, topic\nVisualization:\n\n-   Heatmap (Hour of day × Day) showing volume of messages\n-   Line chart overlay per sender/group (faceted if needed)\n-   Interactive brush to zoom into specific dates/times\n\nAdditional Feature: Compare activity of individual entities vs. global baseline\n\nModule B: Entity Influence Dashboard\nGoal: Reveal who influences whom across people, vessels, and organizations.\n\nInput: Entity-entity edges, directionality, frequency, topic weight\nBackend:\n\nCompute centrality metrics (degree, betweenness, eigenvector)\nFilter by direction, topic, or message count\n\nVisualization:\n\nInteractive visNetwork graph with dynamic node sizing (influence) and colouring (group affiliation or topic)\nClickable entity profile cards that update to show:\n\nTop connections\nCommunication timeline\nTopics discussed\n\n\n\nModule C: Pseudonym Tracker\nGoal: Detect and decode pseudonym usage and role masking.\n\nInput: Entity-pseudonym mappings, message co-occurrence, behavioural similarity\nAlgorithm:\n\nIdentify pseudonyms via string detection, co-use clustering\nInfer multi-usage by examining shared communication patterns\n\nVisualization:\n\nNode-link diagram with toggle between “real” and “alias” modes\nHighlight shared aliases and suspicious handoffs of pseudonym identity\nTextual summary of evidence linking alias to probable identity\n\n\nModule D: Community & Topic Association\nGoal: Uncover hidden group structures and topic themes.\n\nBackend:\n\nApply Louvain clustering to full entity graph\nTag clusters with dominant communication themes (NLP topic tagging or keyword extraction)\n\nVisualization:\n\nFaceted layout by cluster: each showing node graph + summary\nBar chart of top topics per group\nHover tooltips to explain inter-group bridges (e.g., actors linking Sailor Shift’s crew with Green Guardians)\n\nModule E: Nadia Conti Activity Tracker\n\nGoal: Gather and visualize evidence of Nadia’s potential wrongdoing.\n\nInput: All messages involving or referring to Nadia or her aliases\nBackend:\n\nCreate Nadia subgraph: direct links, pseudonym usage, temporal footprint\nCompute abnormal communication patterns vs. baseline\n\nVisualization:\n\nTimeline of Nadia’s communications: who, when, and topic\nHighlight high-risk pseudonym periods or clandestine approvals\nSummary insight box: “Evidence Level: Moderate/Strong/None”\n\n\n\n\n\n\nFully interactive network graph with edge filters (time, entity, topic)\nDynamic search for people, vessels, or pseudonyms\nSide panels showing metadata and inferred roles\nDownloadable visual summaries\nStoryboarding feature: Clepper can save key frames or views for investigation reports\n\n\n\n\n🔹 6.1 Home (Overview & Narrative Context)\n\nPurpose: Anchor the user with contextual background and investigative framing.\nComponents:\n\nShort narrative summary with quote from Clepper\nOptional interactive map of Oceanus (for future enhancement)\nInfoboxes showing key facts (e.g., number of entities, time span, known pseudonyms)\nNavigation buttons or sidebar leading to investigative tabs\n\nValue: Orients the user to the setting and stakes of the case; sets an investigative tone.\n\n🔹 6.2 Timeline Explorer Tab\n\nPurpose: Uncover daily and hourly communication patterns across the two-week observation window.\nComponents:\n\n📅 Heatmap: Date × Hour grid showing communication intensity\n📈 Line charts: Message frequency over time (overall or by entity/group)\n🔎 Interactive filters: Select entity type (people, vessels), specific names, or keyword topics\n🧭 Timeline brushing: Zoom in on specific dates to transition into more detailed tab\n\nValue: Highlights coordination patterns and anomalies\n\n🔹 6.3 Influence Drilldown Tab\n\nPurpose: Map out who holds power, and how they influence others within the knowledge graph.\nComponents:\n\n🕸️ Interactive visNetwork graph:\n\nNodes sized by centrality (influence)\nDirected edges colored by topic category (e.g., environmental, celebrity, logistics)\n\n🔁 Switch view: “Inbound” vs. “Outbound” influence\n📊 Side panel: Top 5 influencers, ego network for selected entity\n🗂️ Entity profile card: When clicked, show timeline of messages, role type, key connection\n\nValue: Supports influence tracing and actor prioritization, especially for figures like Sailor Shift, conservation leaders, and anonymous bureaucrats.\n\n🔹 6.4 Pseudonym Tracker Tab\n\nPurpose: Detect and decode the use of aliases and multi-identity patterns.\nComponents:\n\n👤 Alias network: Links pseudonyms to likely real-world identities based on co-activity\n🧬 Shared pseudonym highlighting (multiple entities using “Boss” at different hours)\n📅 Pseudonym timeline: Track when and how often each alias was used\n🛠️ Optional toggle: Show/hide pseudonyms in other tabs (global control)\n\nValue: Aids in exposing hidden actors and strengthens the foundation for behavioral de-anonymization.\n\n🔹 6.5 Community & Topic Cluster Tab\n\nPurpose: Visualize thematic groupings and entity communities within the network.\nComponents:\n\n🧠 Clustered graph layout (Louvain or Walktrap output)\n🎨 Color-coded communities with legend (e.g., Green = Environmentalists, Blue = Leisure Vessels)\n📚 Wordcloud or bar chart: Top keywords or message themes per group\n🔗 Bridge node detection: Show entities linking multiple clusters\n\nValue: Supports exploratory investigation into potential collaboration or conflict between stakeholder groups.\n\n🔹 6.6 Nadia Conti Case Dashboard\n\nPurpose: Build a narrative case file centered around Nadia Conti.\nComponents:\n\n🔍 Nadia’s entity profile + aliases\n📊 Summary panel: Activity volume, indirect connections, known pseudonyms\n⏳ Timeline view: Messages involving or referencing Nadia\n🧩 Inference section: Summary of potential illicit actions or suspicious interactions\n\nValue: Synthesizes cross-tab insights to evaluate the core investigative hypothesis: Is Nadia still engaging in illegal activity?\n\n🔹 6.7 (Optional) Evidence Builder Tab\n\nPurpose: Enable Clepper or the user to export selected visuals and insights for report writing or news publishing.\nComponents:\n\n📌 Bookmark key views from any tab\n📝 Generate narrative summaries or “case snapshots”\n📤 Export PDF/PNG visuals\n\nValue: Supports storytelling, publication, or handover to law enforcement or editorial teams.\n\n\n\n\nThis project proposes a purpose-built, investigative visual analytics application designed to illuminate the hidden relationships, pseudonym usage, and potential corruption embedded in the Oceanus radio communication dataset. By combining interactive graph-based exploration with temporal and entity-level analysis, the tool enables investigative users like Clepper Jessen to transition from static information to dynamic, evidence-based storytelling.\nBeyond solving the specific case of Nadia Conti and the suspicious activity around Nemo Reef, this application demonstrates how visual analytics can serve as a powerful ally in data-driven journalism, enabling the detection of influence, identity masking, and organized behaviour in semi-structured communications. Its modular design ensures adaptability for future investigative contexts, whether in civic watchdog efforts, environmental intelligence, or geopolitical monitoring.\nUltimately, this project aligns with the broader goal of democratizing data and analytics, offering a transparent and intuitive interface for domain experts to extract actionable insights from complex knowledge graphs — and to do so without requiring technical expertise in coding or graph theory."
  },
  {
    "objectID": "project_proposal/Proposal_DC.html#introduction",
    "href": "project_proposal/Proposal_DC.html#introduction",
    "title": "Proposal",
    "section": "",
    "text": "“When you have eliminated the impossible, whatever remains, however improbable, must be the truth.”\n— Sherlock Holmes\nThey call it paradise. Oceanus — a remote island once known for its fishing heritage — now hosts yacht parties, drone shoots, and conservation protests. But for me, Clepper Jessen, it’s something else entirely: a mystery waiting to be unravelled.\nTwo weeks ago, something changed. Nemo Reef was abruptly shut down. Sailor Shift’s glamorous arrival was followed by a sudden storm of encrypted radio chatter, midnight movements, and fast-tracked approvals. Names I thought were long gone began to reappear — only this time, hidden behind pseudonyms like “The Boss” and “The Lookout.”\nWith my intern, I intercepted and parsed every message I could get my hands on. But a pile of transcripts, no matter how detailed, is like a thousand-piece puzzle without the picture on the box. I needed a new tool — one that could see what I couldn’t and connect what others wouldn’t.\nThat’s where this application comes in.\nThis is no ordinary dashboard. It is an investigative lens — built to:\n\nUncover temporal anomalies that hint at coordination,\nTrace power and influence through hidden networks,\nDecode aliases and reveal who’s hiding behind what name,\nSurface clusters of collaboration, dissent, or manipulation, and\nPiece together a case around suspects like Nadia Conti, whose past criminal ties may not be so past after all.\n\nWith every filter I apply and every link I explore, I come closer to the truth.\nOceanus wants to forget. My team is here to remember."
  },
  {
    "objectID": "project_proposal/Proposal_DC.html#motivation",
    "href": "project_proposal/Proposal_DC.html#motivation",
    "title": "Proposal",
    "section": "",
    "text": "Oceanus is at a crossroads. Once a tranquil fishing haven, it now stands as a microcosm of modern tension — a battleground between commercial tourism, environmental activism, and quiet corruption. The sudden influx of celebrities, bureaucrats, and shadowy middlemen has triggered suspicion, particularly after the abrupt closure of Nemo Reef.\nAs an investigative journalist, I’ve seen patterns before. But this one? It’s tangled in layers of aliases, logistics, and unlikely partnerships. That’s why I needed a visual analytics tool — not just to read the data, but to interrogate it.\nThis project is driven by a desire to democratize investigative intelligence. Through interactive and intuitive visuals, it empowers those like me — and anyone who seeks truth — to:\n\nDetect daily patterns that ordinary eyes miss,\nFollow the thread of influence across vessels, people, and organizations,\nReveal pseudonyms and hold disguised actors accountable,\nMap out group behaviour and thematic alliances, and\nCollect visual evidence that separates fact from fabrication — especially in the case of Nadia Conti.\n\nBecause data may tell a story. But visual analytics lets us solve the case."
  },
  {
    "objectID": "project_proposal/Proposal_DC.html#problem-statement",
    "href": "project_proposal/Proposal_DC.html#problem-statement",
    "title": "Proposal",
    "section": "",
    "text": "The intercepted radio communications have been transformed into a knowledge graph, capturing two weeks of activity between individuals, vessels, and organizations in Oceanus. Each node represents an entity, while edges represent relationships such as communication, approvals, or co-mentioning events. This knowledge graph also captures metadata like timestamps, topics, and pseudonyms.\nClepper Jessen suspects that behind the benign front of ocean tourism lies an orchestrated effort involving corruption, covert coordination, and manipulation of identity. Our task is to convert this static graph into an interactive investigative tool that surfaces hidden patterns and supports journalistic inquiry.\nInvestigative Problems include:\n🔸 Temporal Anomalies & Daily Rhythms\nMessages cluster around the same time daily, suggesting habitual or coordinated behaviour. Tracking shifts over time may expose operational changes before and after critical events (e.g., the filming announcement).\nGoal: Uncover periodic communication spikes, shifts in timing patterns, and correlation to entity activity.\n🔸Influence Mapping & Relationship Flows\nPower dynamics can be inferred from communication directionality and frequency. Entities like Sailor Shift, officials, and conservationists may be central nodes with high influence.\nGoal: Use graph metrics (e.g., betweenness, eigenvector centrality) to identify influencers and track their evolving roles.\n🔸Group Affiliation & Topic Clustering\nEntities form clusters — such as the Green Guardians or celebrity entourages — based on shared contacts or themes. Group-specific topics and interaction patterns can reveal operational roles.\nGoal: Detect communities using clustering algorithms and associate them with dominant discussion themes (e.g., tourism logistics vs. environmental protests).\n🔸Pseudonym Usage & Identity Masking\nPseudonyms like “The Boss” or “The Lookout” conceal true identities and complicate accountability. Some aliases may be reused across actors or tied to specific event types.\nGoal: Identify single or multi-user pseudonyms, map their activity and cross-compare behaviourally with known entities to uncover deception.\n🔸Evidence of Misconduct – Nadia Conti Focus\nClepper believes Nadia Conti may be covertly operating under new identities or aliases. Her history with illegal fishing makes her a person of interest in new corruption schemes.\nGoal: Map Nadia’s communication footprint, link indirect relationships via pseudonyms, and surface anomalies suggesting concealment or collusion."
  },
  {
    "objectID": "project_proposal/Proposal_DC.html#proposed-approach",
    "href": "project_proposal/Proposal_DC.html#proposed-approach",
    "title": "Proposal",
    "section": "",
    "text": "We will develop a modular Shiny web app to convert the static knowledge graph into an interactive, investigative interface tailored to Clepper’s needs. Each module corresponds to a key problem statement.\nModule A: Temporal Pattern Explorer\nGoal: Visualize daily cycles and anomalies in communication frequency and topic intensity.\n\nInput: Message timestamp, sender, topic\nVisualization:\n\n-   Heatmap (Hour of day × Day) showing volume of messages\n-   Line chart overlay per sender/group (faceted if needed)\n-   Interactive brush to zoom into specific dates/times\n\nAdditional Feature: Compare activity of individual entities vs. global baseline\n\nModule B: Entity Influence Dashboard\nGoal: Reveal who influences whom across people, vessels, and organizations.\n\nInput: Entity-entity edges, directionality, frequency, topic weight\nBackend:\n\nCompute centrality metrics (degree, betweenness, eigenvector)\nFilter by direction, topic, or message count\n\nVisualization:\n\nInteractive visNetwork graph with dynamic node sizing (influence) and colouring (group affiliation or topic)\nClickable entity profile cards that update to show:\n\nTop connections\nCommunication timeline\nTopics discussed\n\n\n\nModule C: Pseudonym Tracker\nGoal: Detect and decode pseudonym usage and role masking.\n\nInput: Entity-pseudonym mappings, message co-occurrence, behavioural similarity\nAlgorithm:\n\nIdentify pseudonyms via string detection, co-use clustering\nInfer multi-usage by examining shared communication patterns\n\nVisualization:\n\nNode-link diagram with toggle between “real” and “alias” modes\nHighlight shared aliases and suspicious handoffs of pseudonym identity\nTextual summary of evidence linking alias to probable identity\n\n\nModule D: Community & Topic Association\nGoal: Uncover hidden group structures and topic themes.\n\nBackend:\n\nApply Louvain clustering to full entity graph\nTag clusters with dominant communication themes (NLP topic tagging or keyword extraction)\n\nVisualization:\n\nFaceted layout by cluster: each showing node graph + summary\nBar chart of top topics per group\nHover tooltips to explain inter-group bridges (e.g., actors linking Sailor Shift’s crew with Green Guardians)\n\nModule E: Nadia Conti Activity Tracker\n\nGoal: Gather and visualize evidence of Nadia’s potential wrongdoing.\n\nInput: All messages involving or referring to Nadia or her aliases\nBackend:\n\nCreate Nadia subgraph: direct links, pseudonym usage, temporal footprint\nCompute abnormal communication patterns vs. baseline\n\nVisualization:\n\nTimeline of Nadia’s communications: who, when, and topic\nHighlight high-risk pseudonym periods or clandestine approvals\nSummary insight box: “Evidence Level: Moderate/Strong/None”"
  },
  {
    "objectID": "project_proposal/Proposal_DC.html#expected-features",
    "href": "project_proposal/Proposal_DC.html#expected-features",
    "title": "Proposal",
    "section": "",
    "text": "Fully interactive network graph with edge filters (time, entity, topic)\nDynamic search for people, vessels, or pseudonyms\nSide panels showing metadata and inferred roles\nDownloadable visual summaries\nStoryboarding feature: Clepper can save key frames or views for investigation reports"
  },
  {
    "objectID": "project_proposal/Proposal_DC.html#early-wireframe-sketches-and-user-flow",
    "href": "project_proposal/Proposal_DC.html#early-wireframe-sketches-and-user-flow",
    "title": "Proposal",
    "section": "",
    "text": "🔹 6.1 Home (Overview & Narrative Context)\n\nPurpose: Anchor the user with contextual background and investigative framing.\nComponents:\n\nShort narrative summary with quote from Clepper\nOptional interactive map of Oceanus (for future enhancement)\nInfoboxes showing key facts (e.g., number of entities, time span, known pseudonyms)\nNavigation buttons or sidebar leading to investigative tabs\n\nValue: Orients the user to the setting and stakes of the case; sets an investigative tone.\n\n🔹 6.2 Timeline Explorer Tab\n\nPurpose: Uncover daily and hourly communication patterns across the two-week observation window.\nComponents:\n\n📅 Heatmap: Date × Hour grid showing communication intensity\n📈 Line charts: Message frequency over time (overall or by entity/group)\n🔎 Interactive filters: Select entity type (people, vessels), specific names, or keyword topics\n🧭 Timeline brushing: Zoom in on specific dates to transition into more detailed tab\n\nValue: Highlights coordination patterns and anomalies\n\n🔹 6.3 Influence Drilldown Tab\n\nPurpose: Map out who holds power, and how they influence others within the knowledge graph.\nComponents:\n\n🕸️ Interactive visNetwork graph:\n\nNodes sized by centrality (influence)\nDirected edges colored by topic category (e.g., environmental, celebrity, logistics)\n\n🔁 Switch view: “Inbound” vs. “Outbound” influence\n📊 Side panel: Top 5 influencers, ego network for selected entity\n🗂️ Entity profile card: When clicked, show timeline of messages, role type, key connection\n\nValue: Supports influence tracing and actor prioritization, especially for figures like Sailor Shift, conservation leaders, and anonymous bureaucrats.\n\n🔹 6.4 Pseudonym Tracker Tab\n\nPurpose: Detect and decode the use of aliases and multi-identity patterns.\nComponents:\n\n👤 Alias network: Links pseudonyms to likely real-world identities based on co-activity\n🧬 Shared pseudonym highlighting (multiple entities using “Boss” at different hours)\n📅 Pseudonym timeline: Track when and how often each alias was used\n🛠️ Optional toggle: Show/hide pseudonyms in other tabs (global control)\n\nValue: Aids in exposing hidden actors and strengthens the foundation for behavioral de-anonymization.\n\n🔹 6.5 Community & Topic Cluster Tab\n\nPurpose: Visualize thematic groupings and entity communities within the network.\nComponents:\n\n🧠 Clustered graph layout (Louvain or Walktrap output)\n🎨 Color-coded communities with legend (e.g., Green = Environmentalists, Blue = Leisure Vessels)\n📚 Wordcloud or bar chart: Top keywords or message themes per group\n🔗 Bridge node detection: Show entities linking multiple clusters\n\nValue: Supports exploratory investigation into potential collaboration or conflict between stakeholder groups.\n\n🔹 6.6 Nadia Conti Case Dashboard\n\nPurpose: Build a narrative case file centered around Nadia Conti.\nComponents:\n\n🔍 Nadia’s entity profile + aliases\n📊 Summary panel: Activity volume, indirect connections, known pseudonyms\n⏳ Timeline view: Messages involving or referencing Nadia\n🧩 Inference section: Summary of potential illicit actions or suspicious interactions\n\nValue: Synthesizes cross-tab insights to evaluate the core investigative hypothesis: Is Nadia still engaging in illegal activity?\n\n🔹 6.7 (Optional) Evidence Builder Tab\n\nPurpose: Enable Clepper or the user to export selected visuals and insights for report writing or news publishing.\nComponents:\n\n📌 Bookmark key views from any tab\n📝 Generate narrative summaries or “case snapshots”\n📤 Export PDF/PNG visuals\n\nValue: Supports storytelling, publication, or handover to law enforcement or editorial teams."
  },
  {
    "objectID": "project_proposal/Proposal_DC.html#conclusion",
    "href": "project_proposal/Proposal_DC.html#conclusion",
    "title": "Proposal",
    "section": "",
    "text": "This project proposes a purpose-built, investigative visual analytics application designed to illuminate the hidden relationships, pseudonym usage, and potential corruption embedded in the Oceanus radio communication dataset. By combining interactive graph-based exploration with temporal and entity-level analysis, the tool enables investigative users like Clepper Jessen to transition from static information to dynamic, evidence-based storytelling.\nBeyond solving the specific case of Nadia Conti and the suspicious activity around Nemo Reef, this application demonstrates how visual analytics can serve as a powerful ally in data-driven journalism, enabling the detection of influence, identity masking, and organized behaviour in semi-structured communications. Its modular design ensures adaptability for future investigative contexts, whether in civic watchdog efforts, environmental intelligence, or geopolitical monitoring.\nUltimately, this project aligns with the broader goal of democratizing data and analytics, offering a transparent and intuitive interface for domain experts to extract actionable insights from complex knowledge graphs — and to do so without requiring technical expertise in coding or graph theory."
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "For the purpose of this assignment, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\npacman::p_load(tidyverse, jsonlite, \n               tidygraph, ggraph, SmartEDA, \n               ggrepel, scales, lubridate, dplyr, viridis)\n\n\n\n\nFor the purpose of this exercise, mc3.json file will be used. Before getting started, you should have the data set in the data sub-folder.\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc3.json file into R and save the output object\n\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")\n\n\n\n\nThe dataset was provided by VAST Challenge for MC3. This report utilizes two core datasets: MC3_graph.json, which encodes the knowledge graph of communications, events, and relationships; and MC3_schema.json, which defines the structure, subtypes, and attributes of each node and edge type within the graph. There ngraph contains a total of 1159 nodes and 3226 edges. Full description of node attributes and edge attributes is shown below.\nNodes Attributes are as such:\n\n\n\nNode Subtypes\n\n\nEdge Attributes are as such:\n\n\n\nNode-Edge-Node Matrix\n\n\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of mc3 knowledge graph.\nIn the code chunk below glimpse() is used to reveal the structure of mc3 knowledge graph.\n\nglimpse(MC3)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that Industry field is in list data type. In general, this data type is not acceptable by tbl_graph() of tidygraph. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis.\n\n\n\n\n\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc3 tibble dataframe into two separate tibble dataframes called mc3_nodes and mc3_edges respectively.\n\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)\n\n\n\n\nIt is time for us to apply appropriate EDA methods to examine the data.\nNodes:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?\n\n\n\n\n\nEdges:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n\n\n\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below performs the following data cleaning tasks:\n\nconvert values in id field into character data type,\nexclude records with id value are na,\nexclude records with similar id values,\nexclude thing_collected field, and\nsave the cleaned tibble dataframe into a new tibble datatable called mc3_nodes_cleaned.\n\n\n\nCode\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n\n\n\n\nNext, the code chunk below will be used to:\n\nrename source and target fields to from_id and to_id respectively,\nconvert values in from_id and to_id fields to character data type,\nexclude values in from_id and to_id which not found in the id field of mc3_nodes_cleaned,\nexclude records whereby from_id and/or to_id values are missing, and\nsave the cleaned tibble dataframe and called it mc3_edges_cleaned.\n\n\n\nCode\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source, \n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), \n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\nNext, code chunk below will be used to create mapping of character id in mc3_nodes_cleaned to row index.\n\n\nCode\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nNext, the code chunk below will be used to join and convert from_id and to_id to integer indices. At the same time we also drop rows with unmatched nodes.\n\n\nCode\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to))  \n\n\nNext the code chunk below is used to subset nodes to only those referenced by edges.\n\n\nCode\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nWe will then use the code chunk below to rebuild lookup from old index to new index.\n\n\nCode\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n\nLastly, the code chunk below will be used to update edge indices to match new node table.\n\n\nCode\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\n\nNow we are ready to build the tidygraph object by using the code chunk below.\n\nmc3_graph &lt;- tbl_graph(\n  nodes = mc3_nodes_final,\n  edges = mc3_edges_final,\n  directed = TRUE\n)\n\nAfter the tidygraph object is created, it is always a good practice to examine the object by using str().\n\nstr(mc3_graph)\n\nClasses 'tbl_graph', 'igraph'  hidden list of 10\n $ : num 1159\n $ : logi TRUE\n $ : num [1:3226] 0 0 0 0 0 0 0 1 1 1 ...\n $ : num [1:3226] 1137 356 746 894 875 ...\n $ : NULL\n $ : NULL\n $ : NULL\n $ : NULL\n $ :List of 4\n  ..$ : num [1:3] 1 0 1\n  ..$ : Named list()\n  ..$ :List of 31\n  .. ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  .. ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  .. ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  .. ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ findings         : chr [1:1159] NA NA NA NA ...\n  .. ..$ content          : chr [1:1159] NA NA NA NA ...\n  .. ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ results          : chr [1:1159] NA NA NA NA ...\n  .. ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ destination      : chr [1:1159] NA NA NA NA ...\n  .. ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  .. ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  .. ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  .. ..$ reference        : chr [1:1159] NA NA NA NA ...\n  .. ..$ date             : chr [1:1159] NA NA NA NA ...\n  .. ..$ time             : chr [1:1159] NA NA NA NA ...\n  .. ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  .. ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  .. ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  .. ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  .. ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  .. ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ operational_role : chr [1:1159] NA NA NA NA ...\n  .. ..$ new_index        : int [1:1159] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ :List of 2\n  .. ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  .. ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n $ :&lt;environment: 0x000002294cb8f620&gt; \n - attr(*, \"active\")= chr \"nodes\"\n\n\n\n\n\n\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1818)\n\n\n\nShows how many nodes are of type Entity, Event, or Relationship.\n\n\nCode\nmc3_nodes_final %&gt;%\n  count(type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(type, -n), y = n, fill = type)) +\n  geom_col() +\n  geom_text(aes(label = n), vjust = -0.3) +\n  labs(title = \"Node Type Distribution\", x = \"Type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggraph functions are used to create the whole graph.\n\n\nCode\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nFocuses on what kinds of actors are in the graph — Person, Vessel, Organization, etc.\n\n\nCode\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo understand what kinds of actions dominate — Communication, Monitoring, Assessment, etc.\n\n\nCode\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis finds all Entities that sent or received communication events — i.e., actors who participated in messaging.\n\n\nCode\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\n\n\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\nMessage Senders are arranged from most to the least number of messages sent.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAST Challenge Task & Question 1a and 1b\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nDevelop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\nHow do these patterns shift over the two weeks of observations?\n\n\n\nObjective\n\nIdentify when communications happen most often during each day.\nDetect shifts in these patterns over the 2-week period.\nLater: Focus on a specific entity (e.g., Nadia Conti) and explore who influences them.\n\n\n\nExtract the Communication Timestamps from mc3_nodes_final and filter for communication events.\n\n# Filter for Communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n\nParse the Communication Timestamp into the format “dd/mm/yyy (ddd)” for ease of reference.\n\n# Communication events with parsed date and time\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n\n\n\n\n\n\n\n\nCode\n# Step 1: Prepare daily message volume data\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count &lt;- mean(daily_message_volume$message_count)\ntotal_msg_count &lt;- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %&gt;% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender–receiver–timestamp structure\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender–receiver–timestamp\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(sender_id = id, sender_label = label), by = \"sender_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, hour) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;⏰ Hour: \", sprintf(\"%02d:00\", hour),\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np &lt;- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nWe will increase the resolution to half-hour time slots.\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count.\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)  # ✅ fixed receiver_id\n\n# Step 2: Reconstruct sender–receiver–event linkage\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, time_bin, time_label) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;🕒 Time: \", time_label,\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np &lt;- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nThe faceted density plot that shows the distribution of communication events by time of day, broken down for each day in the dataset. It helps to visually detect temporal communication patterns, intensity, and consistency over multiple days.\n\nOverview of the 2 week periodDay 1 - 01/10/2040Day 2 - 02/10/2040Day 3 - 03/10/2040Day 4 - 04/10/2040Day 5 - 05/10/2040Day 6 - 06/10/2040Day 7 - 07/10/2040Day 8 - 08/10/2040Day 9 - 09/10/2040Day 10 - 10/10/2040Day 11 - 11/10/2040Day 12 - 12/10/2040Day 13 - 13/10/2040Day 14 - 14/10/2040\n\n\n\n\nCode\n# Step 1: Preprocess communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats &lt;- comm_events %&gt;%\n  group_by(date_label) %&gt;%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n📈 Insights This Visualization Offers\n\n\n\n\nBar Plot of combined hourly message volume over the 2 weeks period:\n\n\nCode\n# Prepare data\ncomm_hourly &lt;- comm_events %&gt;%\n  count(hour) %&gt;%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nBar Plot of combined half-hourly message volume in the 2 weeks period.\n\n\nCode\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute &lt; 30, 0, 30))\n  )\n\ncomm_halfhour &lt;- comm_events %&gt;%\n  count(time_bin) %&gt;%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1a. What are the identifiable daily temporal patterns in communications?\n\n\n\n\nThe daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)—a sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\nThe temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\nFor instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends—communication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n\n\n\n\n\n\n\n\n\n1b. How do these patterns shift over the two weeks of observations?\n\n\n\n\nOver the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of “surge” (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation—an analytical signal that warrants closer inspection of event logs or external triggers for those dates.\nAnother notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule—potentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures.\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAST Challenge Task & Question 1c\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nFocus on a specific entity and use this information to determine who has influence over them.\n\n\n\n\n\nWe first extracted the relevant communication edges from the dataset, pairing “sent” and “received” communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\nCode\n# Extract sent and received communication event edges\nsent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges &lt;- sent_edges %&gt;%\n  inner_join(received_edges, by = \"event\") %&gt;%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges &lt;- sent_edges %&gt;%\n  select(from = source_entity, to = event)\nsingle_received_edges &lt;- received_edges %&gt;%\n  select(from = event, to = target_entity)\n\nall_edges &lt;- bind_rows(paired_edges, single_sent_edges, single_received_edges) %&gt;%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  pull(id) %&gt;% as.character()\n\nentity_edges &lt;- all_edges %&gt;%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  select(id, label, sub_type)\n\n\n\n\n\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node—PageRank, betweenness, and degree—quantifying the influence and connectivity of every entity in the overall network.\n\n\nCode\nlibrary(igraph)\n\ng &lt;- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank &lt;- page_rank(g)$vector\nV(g)$betweenness &lt;- betweenness(g)\nV(g)$degree &lt;- degree(g)\n\n\n\n\n\nFocusing on “Nadia Conti”, we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia’s immediate sphere of influence and the key players connected to her.\n\n\nCode\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\nego_graph &lt;- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n\n\n\n\n\nWe visualized Nadia’s ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti’s communication environment.\n\n\nCode\nnodes_df &lt;- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_graph)$label, \"&lt;/b&gt;&lt;br&gt;\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"&lt;br&gt;\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"&lt;br&gt;\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df &lt;- as_data_frame(ego_graph, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %&gt;%\n  visNodes(scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %&gt;%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal and Ego-Network Structure\n\n\n\nThe overview network visualization reveals that Nadia Conti is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia’s influence neighborhood.\n\n\n\n\n\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\nPageRank (overall influence),\nBetweenness (information brokerage/intermediary role), and\nDegree (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\nCode\n# PageRank table\npagerank_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %&gt;% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %&gt;% arrange(desc(betweenness))\n\n# Degree table\ndegree_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %&gt;% arrange(desc(degree))\n\n\n\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n\n\nPageRank Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\npagerank\n\n\n\n\nMako\nVessel\n0.0687\n\n\nOceanus City Council\nOrganization\n0.0530\n\n\nReef Guardian\nVessel\n0.0454\n\n\nNadia Conti\nPerson\n0.0432\n\n\nRemora\nVessel\n0.0409\n\n\nV. Miesel Shipping\nOrganization\n0.0394\n\n\nNeptune\nVessel\n0.0358\n\n\nHimark Harbor\nLocation\n0.0358\n\n\nLiam Thorne\nPerson\n0.0275\n\n\nBoss\nPerson\n0.0272\n\n\nSentinel\nVessel\n0.0250\n\n\nPaackland Harbor\nLocation\n0.0244\n\n\nDavis\nPerson\n0.0239\n\n\nMarlin\nVessel\n0.0235\n\n\nEcoVigil\nVessel\n0.0233\n\n\nGreen Guardians\nOrganization\n0.0224\n\n\nMrs. Money\nPerson\n0.0192\n\n\nSailor Shifts Team\nOrganization\n0.0186\n\n\nSeawatch\nVessel\n0.0186\n\n\nElise\nPerson\n0.0182\n\n\nSerenity\nVessel\n0.0170\n\n\nHorizon\nVessel\n0.0152\n\n\nThe Middleman\nPerson\n0.0142\n\n\nNorthern Light\nVessel\n0.0135\n\n\nRodriguez\nPerson\n0.0122\n\n\nSamantha Blake\nPerson\n0.0114\n\n\nHaacklee Harbor\nLocation\n0.0111\n\n\nOsprey\nVessel\n0.0088\n\n\nCity Officials\nGroup\n0.0066\n\n\nThe Lookout\nPerson\n0.0062\n\n\nKnowles\nVessel\n0.0051\n\n\nSmall Fry\nPerson\n0.0035\n\n\nGlitters Team\nOrganization\n0.0035\n\n\n\n\n\n\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n\n\nBetweenness Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\nbetweenness\n\n\n\n\nMako\nVessel\n368.50\n\n\nMrs. Money\nPerson\n167.18\n\n\nReef Guardian\nVessel\n139.69\n\n\nBoss\nPerson\n136.18\n\n\nV. Miesel Shipping\nOrganization\n118.70\n\n\nNadia Conti\nPerson\n117.87\n\n\nOceanus City Council\nOrganization\n116.11\n\n\nRemora\nVessel\n90.45\n\n\nNeptune\nVessel\n82.59\n\n\nThe Lookout\nPerson\n80.51\n\n\nHimark Harbor\nLocation\n52.61\n\n\nThe Middleman\nPerson\n50.78\n\n\nLiam Thorne\nPerson\n41.81\n\n\nHaacklee Harbor\nLocation\n41.30\n\n\nSentinel\nVessel\n34.54\n\n\nGreen Guardians\nOrganization\n27.51\n\n\nPaackland Harbor\nLocation\n27.08\n\n\nDavis\nPerson\n22.36\n\n\nEcoVigil\nVessel\n12.63\n\n\nRodriguez\nPerson\n11.75\n\n\nNorthern Light\nVessel\n9.76\n\n\nSailor Shifts Team\nOrganization\n7.34\n\n\nHorizon\nVessel\n6.72\n\n\nMarlin\nVessel\n6.23\n\n\nSeawatch\nVessel\n5.20\n\n\nElise\nPerson\n4.60\n\n\nSamantha Blake\nPerson\n4.49\n\n\nSerenity\nVessel\n0.81\n\n\nKnowles\nVessel\n0.50\n\n\nSmall Fry\nPerson\n0.00\n\n\nGlitters Team\nOrganization\n0.00\n\n\nOsprey\nVessel\n0.00\n\n\nCity Officials\nGroup\n0.00\n\n\n\n\n\n\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n\n\nDegree Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\ndegree\n\n\n\n\nMako\nVessel\n37\n\n\nOceanus City Council\nOrganization\n28\n\n\nReef Guardian\nVessel\n27\n\n\nRemora\nVessel\n21\n\n\nV. Miesel Shipping\nOrganization\n19\n\n\nNeptune\nVessel\n19\n\n\nNadia Conti\nPerson\n17\n\n\nGreen Guardians\nOrganization\n17\n\n\nHimark Harbor\nLocation\n17\n\n\nDavis\nPerson\n16\n\n\nSentinel\nVessel\n16\n\n\nBoss\nPerson\n13\n\n\nEcoVigil\nVessel\n13\n\n\nPaackland Harbor\nLocation\n13\n\n\nMrs. Money\nPerson\n12\n\n\nHorizon\nVessel\n12\n\n\nLiam Thorne\nPerson\n11\n\n\nRodriguez\nPerson\n10\n\n\nMarlin\nVessel\n10\n\n\nSeawatch\nVessel\n9\n\n\nThe Middleman\nPerson\n8\n\n\nSerenity\nVessel\n8\n\n\nNorthern Light\nVessel\n8\n\n\nHaacklee Harbor\nLocation\n8\n\n\nElise\nPerson\n7\n\n\nThe Lookout\nPerson\n7\n\n\nSailor Shifts Team\nOrganization\n7\n\n\nSamantha Blake\nPerson\n6\n\n\nGlitters Team\nOrganization\n4\n\n\nKnowles\nVessel\n4\n\n\nSmall Fry\nPerson\n3\n\n\nOsprey\nVessel\n3\n\n\nCity Officials\nGroup\n1\n\n\n\n\n\n\n\n\n\n\n\nCentrality Metrics and Direct & Indirect Influences\n\n\n\nBy calculating centrality metrics within Nadia’s two-hop ego network, we observe that the most influential nodes in her environment—by PageRank, betweenness, and degree—are Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia’s information flow and access to other parts of the network.\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n\n\n\n\n\n\nCode\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng &lt;- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 &lt;- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank &lt;- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df &lt;- as_data_frame(ego_1, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness &lt;- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Degree for the ego network\nV(ego_1)$degree &lt;- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n1c. With a focus on “Nadia Conti”, the visuals above could determine who has influence over this person.\n\n\n\n\nDegree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\nSeveral other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia’s network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that Nadia’s environment is both diverse and robust.\nDirect Connections\nThese direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti’s node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\nPeople: Elise, Liam Thorne, Davis, Rodriguez\nOrganization: V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\nVessel: Neptune, Marlin, Remora, Sentinel\nLocation: Haacklee Harbor\n\nInterpretation: The PageRank, Betweenness, and Degree centrality plots all consistently show Nadia Conti as a major hub, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\nNadia’s position suggests she is a key connector and influencer but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence—and be influenced—is amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia’s access to information, resources, and strategic decisions.\n\n\n\n\n\n\n\n\nQuestion 2 Goals:\n\nUnderstand and explore interactions and relationships groups between people and vessels.\nIdentify closely associated groups and their thematic focus.\n\n\n\n\n\nEnsure we have a usable network graph:\n\n# Step 1: Convert directed tidygraph to igraph, then undirected\nigraph_undirected &lt;- as.undirected(as.igraph(mc3_graph), mode = \"collapse\")\n\n# Step 2: Convert back to tidygraph (tbl_graph)\nmc3_graph_undirected &lt;- as_tbl_graph(igraph_undirected)\n\n# Step 3: Apply Louvain community detection\nmc3_graph_undirected &lt;- mc3_graph_undirected %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\n\n# Extract node table from graph\npeople_vessels_comm &lt;- mc3_graph_undirected %&gt;%\n  as_tibble() %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(label, sub_type, community)\n\n# Quick look\nhead(people_vessels_comm)\n\n# A tibble: 6 × 3\n  label          sub_type community\n  &lt;chr&gt;          &lt;chr&gt;    &lt;fct&gt;    \n1 Sam            Person   9        \n2 Kelly          Person   9        \n3 Nadia Conti    Person   9        \n4 Elise          Person   9        \n5 Liam Thorne    Person   6        \n6 Samantha Blake Person   1        \n\n\n\n\n\n\n# Community composition\nlibrary(knitr)\n\ngroup_summary &lt;- people_vessels_comm %&gt;%\n  count(community, sub_type, sort = TRUE)\n\nkable(group_summary, caption = \"Distribution of People and Vessels Across Detected Communities\")\n\n\nDistribution of People and Vessels Across Detected Communities\n\n\ncommunity\nsub_type\nn\n\n\n\n\n5\nPerson\n6\n\n\n3\nVessel\n4\n\n\n9\nPerson\n4\n\n\n1\nPerson\n3\n\n\n4\nVessel\n3\n\n\n7\nVessel\n3\n\n\n1\nVessel\n2\n\n\n2\nVessel\n2\n\n\n8\nPerson\n2\n\n\n2\nPerson\n1\n\n\n6\nPerson\n1\n\n\n9\nVessel\n1\n\n\n10\nPerson\n1\n\n\n\n\n\n\n\n\n\nggraph(mc3_graph_undirected, layout = \"fr\") +\n  geom_edge_link(alpha = 0.1, colour = \"grey\") +\n  geom_node_point(aes(color = community, shape = sub_type), size = 3, alpha = 0.9) +\n  geom_node_text(aes(label = ifelse(sub_type %in% c(\"Person\", \"Vessel\"), label, NA_character_)), \n                 size = 2.3, repel = TRUE) +\n  labs(\n    title = \"Community Clusters of People and Vessels in Oceanus\",\n    subtitle = \"Identified using Louvain Algorithm on Undirected Graph\"\n  ) +\n  theme_graph() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nWe will assign themes to nodes and communities based on keywords in label or sub_type. For example:\n\nEntities with “Green” or “Guardian” → Environmental\nLabels with “Sailor Shift” or “Pop” → Sailor Shift\nAny node with sub_type == \"Vessel\" → Vessel\nAll others → Other\n\nCode: Assign Themes to Nodes\n\n# Tag each node in the undirected graph with a thematic label\nmc3_graph_undirected &lt;- mc3_graph_undirected %&gt;%\n  mutate(theme = case_when(\n    str_detect(label, regex(\"Green|Guardian\", ignore_case = TRUE)) ~ \"Environmental\",\n    str_detect(label, regex(\"Sailor Shift|Pop\", ignore_case = TRUE)) ~ \"Sailor Shift\",\n    sub_type == \"Vessel\" ~ \"Vessel\",\n    TRUE ~ \"Other\"\n  ))\n\nCode: Summarize Theme Composition\n\n# Theme breakdown per community\ntheme_summary &lt;- mc3_graph_undirected %&gt;%\n  as_tibble() %&gt;%\n  count(community, theme, sort = TRUE)\n\nknitr::kable(theme_summary, caption = \"Theme Breakdown per Community\")\n\n\nTheme Breakdown per Community\n\n\ncommunity\ntheme\nn\n\n\n\n\n1\nOther\n173\n\n\n2\nOther\n165\n\n\n3\nOther\n152\n\n\n4\nOther\n150\n\n\n5\nOther\n131\n\n\n6\nOther\n113\n\n\n7\nOther\n92\n\n\n8\nOther\n72\n\n\n9\nOther\n65\n\n\n10\nOther\n28\n\n\n3\nVessel\n3\n\n\n4\nVessel\n3\n\n\n7\nVessel\n3\n\n\n1\nSailor Shift\n2\n\n\n1\nVessel\n2\n\n\n2\nVessel\n2\n\n\n3\nEnvironmental\n1\n\n\n4\nEnvironmental\n1\n\n\n9\nVessel\n1\n\n\n\n\n\n\n\n\nWe will now plot faceted or color-coded networks to show how these communities and themes look visually.\n🔹 Option A: Color by Theme\n\nggraph(mc3_graph_undirected, layout = \"fr\") +\n  geom_edge_link(alpha = 0.1, colour = \"grey\") +\n  geom_node_point(aes(color = theme, shape = sub_type), size = 3, alpha = 0.9) +\n  geom_node_text(aes(label = ifelse(sub_type %in% c(\"Person\", \"Vessel\"), label, NA_character_)), \n                 size = 2.3, repel = TRUE) +\n  labs(\n    title = \"Network of People and Vessels in Oceanus\",\n    subtitle = \"Color-coded by Theme (Environmental, Sailor Shift, Vessel)\"\n  ) +\n  theme_graph() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n🔹 Option B: Facet by Theme\n\nggraph(mc3_graph_undirected, layout = \"fr\") +\n  geom_edge_link(alpha = 0.1, colour = \"grey\") +\n  geom_node_point(aes(color = community, shape = sub_type), size = 3, alpha = 0.9) +\n  geom_node_text(aes(label = ifelse(sub_type %in% c(\"Person\", \"Vessel\"), label, NA_character_)), \n                 size = 2.3, repel = TRUE) +\n  facet_nodes(~ theme) +\n  labs(\n    title = \"Community Clusters Faceted by Theme\",\n    subtitle = \"Facets: Environmental, Sailor Shift, Vessel, Other\"\n  ) +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse edges that connect Entity → Event (Communication) and Event (Communication) → Entity.\nFocus only on Communication events and extract senders and receivers.\n\n\n# Extract Communication Events from nodes\ncommunication_events &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, label)\n\n# Extract sent edges: Entity → Communication Event\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% communication_events$id)\n\n# Extract received edges: Communication Event → Entity\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% communication_events$id)\n\n# Join both to get Sender → Communication → Receiver\ncomm_links &lt;- comm_sent_edges %&gt;%\n  select(comm_id = to_id, sender = from_id) %&gt;%\n  inner_join(\n    comm_received_edges %&gt;% select(comm_id = from_id, receiver = to_id),\n    by = \"comm_id\"\n  ) %&gt;%\n  filter(sender != receiver)\n\n\n\n\n\nFrom edges:\n\nSender (Entity) → Communication Event\nCommunication Event → Receiver (Entity)\n\nJoin both directions to link:\nEntity A → Communication Event → Entity B → derive Entity A → Entity B communication links.\n\n\n# Get people and vessel node IDs\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter comm links to include only person ↔ vessel or person ↔ person, etc.\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\n\nNodes: People and Vessels only (from mc3_nodes_cleaned).\nEdges: Summarized links between these nodes based on co-involvement in the same communication event.\n\n\n# Edge weight (number of communications)\nedge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Create node list for graph\nnodes_df &lt;- people_vessels %&gt;%\n  filter(id %in% c(edge_df$sender, edge_df$receiver))\n\n# Build graph object\ncomm_graph &lt;- tbl_graph(nodes = nodes_df, edges = edge_df, directed = FALSE)\n\n\n\n\n\nUse igraph or tidygraph to detect communities.\nAnnotate communities for possible labels (e.g., Green Guardians, Sailor Shift fans) using node metadata.\n\n\ncomm_graph &lt;- comm_graph %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\n\nshape_map &lt;- c(\"Person\" = \"circle\", \"Vessel\" = \"triangle\")\n\ncolor_map &lt;- c(\n  \"Person\" = \"#fc8d62\",\n  \"Organization\" = \"#6baed6\",\n  \"Vessel\" = \"#66c2a2\",\n  \"Location\" = \"#c6dbef\",\n  \"Nadia Conti\" = \"#ffd92f\"\n)\n\nggraph(comm_graph, layout = \"fr\") +\n  geom_edge_link(aes(width = weight), alpha = 0.2, color = \"gray50\") +\n  geom_node_point(aes(color = group, shape = group), size = 4) +\n  geom_node_text(aes(label = label), repel = TRUE, size = 2.5) +\n  scale_shape_manual(values = shape_map) +\n  scale_color_manual(values = color_map) +\n  theme_graph() +\n  labs(title = \"Communication Clusters Between People and Vessels\",\n       subtitle = \"Communities detected using Louvain algorithm\")\n\n\n\n\n\n\n\n\n\n# Get only Person and Vessel nodes\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter communication links for person ↔ vessel/person only\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n# Count number of communications between each sender–receiver pair\ncomm_edge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Build node dataframe from involved IDs only\ncomm_node_df &lt;- people_vessels %&gt;%\n  filter(id %in% unique(c(comm_edge_df$sender, comm_edge_df$receiver))) %&gt;%\n  mutate(\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Vessel\" ~ \"triangle\"\n    ),\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",\n      group == \"Vessel\" ~ \"#66c2a2\",\n      label == \"Nadia Conti\" ~ \"#ffd92f\",\n      TRUE ~ \"#c6dbef\"\n    )\n  )\n\n# Format edges for visNetwork\ncomm_vis_edges &lt;- comm_edge_df %&gt;%\n  rename(from = sender, to = receiver) %&gt;%\n  mutate(width = weight)\n\n\nlibrary(igraph)\n\n# Create igraph object\ngraph_ig &lt;- graph_from_data_frame(comm_vis_edges, directed = FALSE, vertices = comm_node_df)\n\n# Apply Louvain clustering\nlouvain_groups &lt;- cluster_louvain(graph_ig)\ncomm_node_df$group_comm &lt;- as.factor(membership(louvain_groups))\n\n\nlibrary(visNetwork)\n\n# Title heading\ncat(\"### Interactive Network of Communication Between People and Vessels\")\n\n### Interactive Network of Communication Between People and Vessels\n\n# Final interactive visNetwork with consistent styling\nvisNetwork(\n  nodes = comm_node_df,\n  edges = comm_vis_edges\n) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -80,\n      centralGravity = 0.01,\n      springLength = 50,\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n    ),\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\nCode\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nCode\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nCode\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nCode\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -50,   # Increase pull toward center\n      centralGravity = 0.005,        # Lower keeps outer nodes further\n      springLength = 100,            # Length between nodes\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages by sender/receiver\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and label\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Bar plot\nggplot(comm_summary, aes(x = reorder(label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggtext)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages sent and received\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and format\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Create colored labels for x-axis\ncomm_summary &lt;- comm_summary %&gt;%\n  mutate(\n    x_label = paste0(\n      \"&lt;span style='color:\",\n      case_when(\n        sub_type == \"Vessel\" ~ \"#66c2a2\",\n        sub_type == \"Person\" ~ \"#fc8d62\",\n        TRUE ~ \"gray\"\n      ),\n      \"'&gt;\", label, \"&lt;/span&gt;\"\n    )\n  )\n\n# Step 5: Bar Plot with colored axis text\nggplot(comm_summary, aes(x = reorder(x_label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_markdown(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotly)\nlibrary(DT)\n\n# Step 1: Compute message counts\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 2: Combine counts\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\")\n\n# Step 3: Reshape for plotly\ncomm_long &lt;- comm_summary %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Plotly bar chart (interactive)\nplot_ly(\n  comm_long,\n  x = ~label,\n  y = ~count,\n  color = ~direction,\n  colors = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\"),\n  type = 'bar',\n  text = ~paste0(\"Entity: \", label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Count: \", count),\n  hoverinfo = 'text',\n  name = ~direction\n) %&gt;%\n  layout(\n    title = \"Interactive Message Volume by Entity\",\n    barmode = 'group',\n    xaxis = list(title = \"Entity\", tickangle = -45),\n    yaxis = list(title = \"Message Count\")\n  )\n\n\n\n\n\n\n\nCode\ndatatable(\n  comm_summary %&gt;% arrange(desc(sent + received)),\n  options = list(\n    pageLength = 10,\n    autoWidth = TRUE,\n    searchHighlight = TRUE\n  ),\n  colnames = c(\"ID\", \"Name\", \"Sent\", \"Received\", \"Type\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse igraph::cluster_louvain() on the communication network built in 2a (undirected).\nAssign a community ID to each node (nodes_vis$community).\n\n\n\n\n\nSummarize the composition of each community by:\n\nNumber of persons/vessels\nTop labels in each group\nKnown keywords (e.g., “Green Guardians”, “Sailor Shift”, vessel names like “Aurora” or “Bluefin”)\n\n\n\n\n\n\nAssign a distinct color to each detected community.\nRetain shape encoding (dot = Person, triangle = Vessel).\n\n\n\n\n\nUse visNetwork to display the full communication network:\n\nColor nodes by community\nTooltip includes label, type, community\nLegend for each detected community\n\n\n\nlibrary(igraph)\nlibrary(visNetwork)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Create igraph from person-vessel edges\ng_comm &lt;- graph_from_data_frame(edges_vis, directed = FALSE, vertices = nodes_vis)\n\n# Louvain detection\nlouvain_clusters &lt;- cluster_louvain(g_comm)\nnodes_vis$louvain_comm &lt;- as.factor(membership(louvain_clusters))\n\n# Walktrap detection\nwalktrap_clusters &lt;- cluster_walktrap(g_comm)\nnodes_vis$walktrap_comm &lt;- as.factor(membership(walktrap_clusters))\n\n# Create color palettes\nmax_comm &lt;- max(as.numeric(nodes_vis$louvain_comm), as.numeric(nodes_vis$walktrap_comm))\ncomm_colors &lt;- brewer.pal(n = min(max_comm, 8), name = \"Set2\")\n\n# Assign community color for each method\nnodes_louvain &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(louvain_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Louvain: \", louvain_comm)\n  )\n\nnodes_walktrap &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(walktrap_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Walktrap: \", walktrap_comm)\n  )\n\n\n# Define consistent edge formatting\nedges_format &lt;- edges_vis %&gt;%\n  mutate(arrows = \"to\", width = width)\n\n# Louvain network\nlouvain_net &lt;- visNetwork(nodes_louvain, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Louvain Communities\"), useGroups = FALSE)\n\n# Walktrap network\nwalktrap_net &lt;- visNetwork(nodes_walktrap, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Walktrap Communities\"), useGroups = FALSE)\n\n📌 Louvain Community Network\n\n\nCode\n# Generate cluster legend for Louvain\nlouvain_legend &lt;- unique(nodes_louvain$louvain_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_louvain$color[nodes_louvain$louvain_comm == comm_id])[1]\n    )\n  })\n\n# Render Louvain network\ncat(\"## Louvain Community Detection Network\")\n\n\n## Louvain Community Detection Network\n\n\nCode\nvisNetwork(nodes_louvain, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = louvain_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )\n\n\n\n\n\n\n📌 Walktrap Community Network\n\n\nCode\n# Generate cluster legend for Walktrap\nwalktrap_legend &lt;- unique(nodes_walktrap$walktrap_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_walktrap$color[nodes_walktrap$walktrap_comm == comm_id])[1]\n    )\n  })\n\n# Render Walktrap network\ncat(\"## Walktrap Community Detection Network\")\n\n\n## Walktrap Community Detection Network\n\n\nCode\nvisNetwork(nodes_walktrap, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = walktrap_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )"
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#getting-started",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#getting-started",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "For the purpose of this assignment, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\npacman::p_load(tidyverse, jsonlite, \n               tidygraph, ggraph, SmartEDA, \n               ggrepel, scales, lubridate, dplyr, viridis)\n\n\n\n\nFor the purpose of this exercise, mc3.json file will be used. Before getting started, you should have the data set in the data sub-folder.\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc3.json file into R and save the output object\n\nMC3 &lt;- fromJSON(\"data/MC3_graph.json\")\nMC3_schema &lt;- fromJSON(\"data/MC3_schema.json\")\n\n\n\n\nThe dataset was provided by VAST Challenge for MC3. This report utilizes two core datasets: MC3_graph.json, which encodes the knowledge graph of communications, events, and relationships; and MC3_schema.json, which defines the structure, subtypes, and attributes of each node and edge type within the graph. There ngraph contains a total of 1159 nodes and 3226 edges. Full description of node attributes and edge attributes is shown below.\nNodes Attributes are as such:\n\n\n\nNode Subtypes\n\n\nEdge Attributes are as such:\n\n\n\nNode-Edge-Node Matrix\n\n\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of mc3 knowledge graph.\nIn the code chunk below glimpse() is used to reveal the structure of mc3 knowledge graph.\n\nglimpse(MC3)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice that Industry field is in list data type. In general, this data type is not acceptable by tbl_graph() of tidygraph. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis.\n\n\n\n\n\nNext, as_tibble() of tibble package package is used to extract the nodes and links tibble data frames from mc3 tibble dataframe into two separate tibble dataframes called mc3_nodes and mc3_edges respectively.\n\nmc3_nodes &lt;- as_tibble(MC3$nodes)\nmc3_edges &lt;- as_tibble(MC3$edges)\n\n\n\n\nIt is time for us to apply appropriate EDA methods to examine the data.\nNodes:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n\n\n\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?\n\n\n\n\n\nEdges:\n\nThe Code ChunkThe Plots\n\n\n\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n\n\n\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat useful discovery can you obtained from the visualisation above?"
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#data-cleaning-and-wrangling",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#data-cleaning-and-wrangling",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "Code chunk below performs the following data cleaning tasks:\n\nconvert values in id field into character data type,\nexclude records with id value are na,\nexclude records with similar id values,\nexclude thing_collected field, and\nsave the cleaned tibble dataframe into a new tibble datatable called mc3_nodes_cleaned.\n\n\n\nCode\nmc3_nodes_cleaned &lt;- mc3_nodes %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n\n\n\n\nNext, the code chunk below will be used to:\n\nrename source and target fields to from_id and to_id respectively,\nconvert values in from_id and to_id fields to character data type,\nexclude values in from_id and to_id which not found in the id field of mc3_nodes_cleaned,\nexclude records whereby from_id and/or to_id values are missing, and\nsave the cleaned tibble dataframe and called it mc3_edges_cleaned.\n\n\n\nCode\nmc3_edges_cleaned &lt;- mc3_edges %&gt;%\n  rename(from_id = source, \n         to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), \n                as.character)) %&gt;%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n\nNext, code chunk below will be used to create mapping of character id in mc3_nodes_cleaned to row index.\n\n\nCode\nnode_index_lookup &lt;- mc3_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n\nNext, the code chunk below will be used to join and convert from_id and to_id to integer indices. At the same time we also drop rows with unmatched nodes.\n\n\nCode\nmc3_edges_indexed &lt;- mc3_edges_cleaned %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from) & !is.na(to))  \n\n\nNext the code chunk below is used to subset nodes to only those referenced by edges.\n\n\nCode\nused_node_indices &lt;- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final &lt;- mc3_nodes_cleaned %&gt;%\n  slice(used_node_indices) %&gt;%\n  mutate(new_index = row_number())\n\n\nWe will then use the code chunk below to rebuild lookup from old index to new index.\n\n\nCode\nold_to_new_index &lt;- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n\n\nLastly, the code chunk below will be used to update edge indices to match new node table.\n\n\nCode\nmc3_edges_final &lt;- mc3_edges_indexed %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n\n\n\n\n\nNow we are ready to build the tidygraph object by using the code chunk below.\n\nmc3_graph &lt;- tbl_graph(\n  nodes = mc3_nodes_final,\n  edges = mc3_edges_final,\n  directed = TRUE\n)\n\nAfter the tidygraph object is created, it is always a good practice to examine the object by using str().\n\nstr(mc3_graph)\n\nClasses 'tbl_graph', 'igraph'  hidden list of 10\n $ : num 1159\n $ : logi TRUE\n $ : num [1:3226] 0 0 0 0 0 0 0 1 1 1 ...\n $ : num [1:3226] 1137 356 746 894 875 ...\n $ : NULL\n $ : NULL\n $ : NULL\n $ : NULL\n $ :List of 4\n  ..$ : num [1:3] 1 0 1\n  ..$ : Named list()\n  ..$ :List of 31\n  .. ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  .. ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  .. ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  .. ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  .. ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ findings         : chr [1:1159] NA NA NA NA ...\n  .. ..$ content          : chr [1:1159] NA NA NA NA ...\n  .. ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ results          : chr [1:1159] NA NA NA NA ...\n  .. ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ destination      : chr [1:1159] NA NA NA NA ...\n  .. ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  .. ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  .. ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  .. ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  .. ..$ reference        : chr [1:1159] NA NA NA NA ...\n  .. ..$ date             : chr [1:1159] NA NA NA NA ...\n  .. ..$ time             : chr [1:1159] NA NA NA NA ...\n  .. ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  .. ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  .. ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  .. ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  .. ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  .. ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  .. ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  .. ..$ operational_role : chr [1:1159] NA NA NA NA ...\n  .. ..$ new_index        : int [1:1159] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ :List of 2\n  .. ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  .. ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n $ :&lt;environment: 0x000002294cb8f620&gt; \n - attr(*, \"active\")= chr \"nodes\""
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#exploratory-data-analysis-after-cleaning-wrangling",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#exploratory-data-analysis-after-cleaning-wrangling",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "Several of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1818)\n\n\n\nShows how many nodes are of type Entity, Event, or Relationship.\n\n\nCode\nmc3_nodes_final %&gt;%\n  count(type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(type, -n), y = n, fill = type)) +\n  geom_col() +\n  geom_text(aes(label = n), vjust = -0.3) +\n  labs(title = \"Node Type Distribution\", x = \"Type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggraph functions are used to create the whole graph.\n\n\nCode\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nFocuses on what kinds of actors are in the graph — Person, Vessel, Organization, etc.\n\n\nCode\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nTo understand what kinds of actions dominate — Communication, Monitoring, Assessment, etc.\n\n\nCode\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis finds all Entities that sent or received communication events — i.e., actors who participated in messaging.\n\n\nCode\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\n\n\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\nMessage Senders are arranged from most to the least number of messages sent.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nCode\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)"
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#task-1a-1b-daily-temporal-patterns-in-communications-over-the-two-weeks",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#task-1a-1b-daily-temporal-patterns-in-communications-over-the-two-weeks",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "VAST Challenge Task & Question 1a and 1b\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nDevelop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\nHow do these patterns shift over the two weeks of observations?\n\n\n\nObjective\n\nIdentify when communications happen most often during each day.\nDetect shifts in these patterns over the 2-week period.\nLater: Focus on a specific entity (e.g., Nadia Conti) and explore who influences them.\n\n\n\nExtract the Communication Timestamps from mc3_nodes_final and filter for communication events.\n\n# Filter for Communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n\nParse the Communication Timestamp into the format “dd/mm/yyy (ddd)” for ease of reference.\n\n# Communication events with parsed date and time\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n\n\n\n\n\n\n\n\nCode\n# Step 1: Prepare daily message volume data\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count &lt;- mean(daily_message_volume$message_count)\ntotal_msg_count &lt;- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %&gt;%\n  group_by(date, date_label) %&gt;%\n  summarise(message_count = n(), .groups = \"drop\") %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %&gt;% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n\n\n\n\n\n\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender–receiver–timestamp structure\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender–receiver–timestamp\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(sender_id = id, sender_label = label), by = \"sender_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, hour) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;⏰ Hour: \", sprintf(\"%02d:00\", hour),\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np &lt;- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\nWe will increase the resolution to half-hour time slots.\n\n\n\nThis heat map is interactive and you may choose to hover on the tile to display the date, time, and message count.\n\n\nCode\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event_id = from_id, receiver_id = to_id)  # ✅ fixed receiver_id\n\n# Step 2: Reconstruct sender–receiver–event linkage\ncomm_events_raw &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(event_id = id, timestamp) %&gt;%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links &lt;- comm_events_raw %&gt;%\n  left_join(comm_edges_sent, by = \"event_id\") %&gt;%\n  left_join(comm_edges_recv, by = \"event_id\") %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap &lt;- comm_links %&gt;%\n  group_by(date_label, time_bin, time_label) %&gt;%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    tooltip = paste0(\n      \"📅 Date: \", date_label,\n      \"&lt;br&gt;🕒 Time: \", time_label,\n      \"&lt;br&gt;📨 Messages: \", count,\n      \"&lt;br&gt;🔴 Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"&lt;br&gt;🟢 Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np &lt;- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\n\nThe faceted density plot that shows the distribution of communication events by time of day, broken down for each day in the dataset. It helps to visually detect temporal communication patterns, intensity, and consistency over multiple days.\n\nOverview of the 2 week periodDay 1 - 01/10/2040Day 2 - 02/10/2040Day 3 - 03/10/2040Day 4 - 04/10/2040Day 5 - 05/10/2040Day 6 - 06/10/2040Day 7 - 07/10/2040Day 8 - 08/10/2040Day 9 - 09/10/2040Day 10 - 10/10/2040Day 11 - 11/10/2040Day 12 - 12/10/2040Day 13 - 13/10/2040Day 14 - 14/10/2040\n\n\n\n\nCode\n# Step 1: Preprocess communication events\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute &lt; 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats &lt;- comm_events %&gt;%\n  group_by(date_label) %&gt;%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter for selected date\ndaily_data &lt;- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data &lt;- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ±10% of the maximum density\nmax_y &lt;- max(density_data$y)\npeak_threshold &lt;- 0.9 * max_y\n\nmajor_peaks &lt;- density_data %&gt;%\n  filter(y &gt;= peak_threshold) %&gt;%\n  group_by(grp = cumsum(c(1, diff(x) &gt; 0.5))) %&gt;%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count &lt;- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n📈 Insights This Visualization Offers\n\n\n\n\nBar Plot of combined hourly message volume over the 2 weeks period:\n\n\nCode\n# Prepare data\ncomm_hourly &lt;- comm_events %&gt;%\n  count(hour) %&gt;%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nBar Plot of combined half-hourly message volume in the 2 weeks period.\n\n\nCode\ncomm_events &lt;- mc3_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  mutate(timestamp = ymd_hms(timestamp)) %&gt;%\n  filter(!is.na(timestamp)) %&gt;%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute &lt; 30, 0, 30))\n  )\n\ncomm_halfhour &lt;- comm_events %&gt;%\n  count(time_bin) %&gt;%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1a. What are the identifiable daily temporal patterns in communications?\n\n\n\n\nThe daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)—a sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\nThe temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\nFor instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends—communication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n\n\n\n\n\n\n\n\n\n1b. How do these patterns shift over the two weeks of observations?\n\n\n\n\nOver the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of “surge” (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation—an analytical signal that warrants closer inspection of event logs or external triggers for those dates.\nAnother notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule—potentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures."
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#task-1c-focus-on-a-particular-entity---nadia-conti",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#task-1c-focus-on-a-particular-entity---nadia-conti",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "VAST Challenge Task & Question 1c\n\n\n\nClepper found that messages frequently came in at around the same time each day.\n\nFocus on a specific entity and use this information to determine who has influence over them.\n\n\n\n\n\nWe first extracted the relevant communication edges from the dataset, pairing “sent” and “received” communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\nCode\n# Extract sent and received communication event edges\nsent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\") %&gt;%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\") %&gt;%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges &lt;- sent_edges %&gt;%\n  inner_join(received_edges, by = \"event\") %&gt;%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges &lt;- sent_edges %&gt;%\n  select(from = source_entity, to = event)\nsingle_received_edges &lt;- received_edges %&gt;%\n  select(from = event, to = target_entity)\n\nall_edges &lt;- bind_rows(paired_edges, single_sent_edges, single_received_edges) %&gt;%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  pull(id) %&gt;% as.character()\n\nentity_edges &lt;- all_edges %&gt;%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %&gt;%\n  select(id, label, sub_type)\n\n\n\n\n\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node—PageRank, betweenness, and degree—quantifying the influence and connectivity of every entity in the overall network.\n\n\nCode\nlibrary(igraph)\n\ng &lt;- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank &lt;- page_rank(g)$vector\nV(g)$betweenness &lt;- betweenness(g)\nV(g)$degree &lt;- degree(g)\n\n\n\n\n\nFocusing on “Nadia Conti”, we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia’s immediate sphere of influence and the key players connected to her.\n\n\nCode\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\nego_graph &lt;- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n\n\n\n\n\nWe visualized Nadia’s ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti’s communication environment.\n\n\nCode\nnodes_df &lt;- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_graph)$label, \"&lt;/b&gt;&lt;br&gt;\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"&lt;br&gt;\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"&lt;br&gt;\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df &lt;- as_data_frame(ego_graph, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %&gt;%\n  visNodes(scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %&gt;%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal and Ego-Network Structure\n\n\n\nThe overview network visualization reveals that Nadia Conti is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia’s influence neighborhood.\n\n\n\n\n\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\nPageRank (overall influence),\nBetweenness (information brokerage/intermediary role), and\nDegree (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\nCode\n# PageRank table\npagerank_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %&gt;% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %&gt;% arrange(desc(betweenness))\n\n# Degree table\ndegree_df &lt;- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %&gt;% arrange(desc(degree))\n\n\n\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n\n\nPageRank Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\npagerank\n\n\n\n\nMako\nVessel\n0.0687\n\n\nOceanus City Council\nOrganization\n0.0530\n\n\nReef Guardian\nVessel\n0.0454\n\n\nNadia Conti\nPerson\n0.0432\n\n\nRemora\nVessel\n0.0409\n\n\nV. Miesel Shipping\nOrganization\n0.0394\n\n\nNeptune\nVessel\n0.0358\n\n\nHimark Harbor\nLocation\n0.0358\n\n\nLiam Thorne\nPerson\n0.0275\n\n\nBoss\nPerson\n0.0272\n\n\nSentinel\nVessel\n0.0250\n\n\nPaackland Harbor\nLocation\n0.0244\n\n\nDavis\nPerson\n0.0239\n\n\nMarlin\nVessel\n0.0235\n\n\nEcoVigil\nVessel\n0.0233\n\n\nGreen Guardians\nOrganization\n0.0224\n\n\nMrs. Money\nPerson\n0.0192\n\n\nSailor Shifts Team\nOrganization\n0.0186\n\n\nSeawatch\nVessel\n0.0186\n\n\nElise\nPerson\n0.0182\n\n\nSerenity\nVessel\n0.0170\n\n\nHorizon\nVessel\n0.0152\n\n\nThe Middleman\nPerson\n0.0142\n\n\nNorthern Light\nVessel\n0.0135\n\n\nRodriguez\nPerson\n0.0122\n\n\nSamantha Blake\nPerson\n0.0114\n\n\nHaacklee Harbor\nLocation\n0.0111\n\n\nOsprey\nVessel\n0.0088\n\n\nCity Officials\nGroup\n0.0066\n\n\nThe Lookout\nPerson\n0.0062\n\n\nKnowles\nVessel\n0.0051\n\n\nSmall Fry\nPerson\n0.0035\n\n\nGlitters Team\nOrganization\n0.0035\n\n\n\n\n\n\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n\n\nBetweenness Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\nbetweenness\n\n\n\n\nMako\nVessel\n368.50\n\n\nMrs. Money\nPerson\n167.18\n\n\nReef Guardian\nVessel\n139.69\n\n\nBoss\nPerson\n136.18\n\n\nV. Miesel Shipping\nOrganization\n118.70\n\n\nNadia Conti\nPerson\n117.87\n\n\nOceanus City Council\nOrganization\n116.11\n\n\nRemora\nVessel\n90.45\n\n\nNeptune\nVessel\n82.59\n\n\nThe Lookout\nPerson\n80.51\n\n\nHimark Harbor\nLocation\n52.61\n\n\nThe Middleman\nPerson\n50.78\n\n\nLiam Thorne\nPerson\n41.81\n\n\nHaacklee Harbor\nLocation\n41.30\n\n\nSentinel\nVessel\n34.54\n\n\nGreen Guardians\nOrganization\n27.51\n\n\nPaackland Harbor\nLocation\n27.08\n\n\nDavis\nPerson\n22.36\n\n\nEcoVigil\nVessel\n12.63\n\n\nRodriguez\nPerson\n11.75\n\n\nNorthern Light\nVessel\n9.76\n\n\nSailor Shifts Team\nOrganization\n7.34\n\n\nHorizon\nVessel\n6.72\n\n\nMarlin\nVessel\n6.23\n\n\nSeawatch\nVessel\n5.20\n\n\nElise\nPerson\n4.60\n\n\nSamantha Blake\nPerson\n4.49\n\n\nSerenity\nVessel\n0.81\n\n\nKnowles\nVessel\n0.50\n\n\nSmall Fry\nPerson\n0.00\n\n\nGlitters Team\nOrganization\n0.00\n\n\nOsprey\nVessel\n0.00\n\n\nCity Officials\nGroup\n0.00\n\n\n\n\n\n\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n\n\nDegree Centrality (Nadia’s Ego Network)\n\n\nlabel\nsub_type\ndegree\n\n\n\n\nMako\nVessel\n37\n\n\nOceanus City Council\nOrganization\n28\n\n\nReef Guardian\nVessel\n27\n\n\nRemora\nVessel\n21\n\n\nV. Miesel Shipping\nOrganization\n19\n\n\nNeptune\nVessel\n19\n\n\nNadia Conti\nPerson\n17\n\n\nGreen Guardians\nOrganization\n17\n\n\nHimark Harbor\nLocation\n17\n\n\nDavis\nPerson\n16\n\n\nSentinel\nVessel\n16\n\n\nBoss\nPerson\n13\n\n\nEcoVigil\nVessel\n13\n\n\nPaackland Harbor\nLocation\n13\n\n\nMrs. Money\nPerson\n12\n\n\nHorizon\nVessel\n12\n\n\nLiam Thorne\nPerson\n11\n\n\nRodriguez\nPerson\n10\n\n\nMarlin\nVessel\n10\n\n\nSeawatch\nVessel\n9\n\n\nThe Middleman\nPerson\n8\n\n\nSerenity\nVessel\n8\n\n\nNorthern Light\nVessel\n8\n\n\nHaacklee Harbor\nLocation\n8\n\n\nElise\nPerson\n7\n\n\nThe Lookout\nPerson\n7\n\n\nSailor Shifts Team\nOrganization\n7\n\n\nSamantha Blake\nPerson\n6\n\n\nGlitters Team\nOrganization\n4\n\n\nKnowles\nVessel\n4\n\n\nSmall Fry\nPerson\n3\n\n\nOsprey\nVessel\n3\n\n\nCity Officials\nGroup\n1\n\n\n\n\n\n\n\n\n\n\n\nCentrality Metrics and Direct & Indirect Influences\n\n\n\nBy calculating centrality metrics within Nadia’s two-hop ego network, we observe that the most influential nodes in her environment—by PageRank, betweenness, and degree—are Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia’s information flow and access to other parts of the network.\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n\n\n\n\n\n\nCode\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng &lt;- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label &lt;- \"Nadia Conti\"\ntarget_index &lt;- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 &lt;- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank &lt;- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df &lt;- as_data_frame(ego_1, what = \"edges\") %&gt;%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness &lt;- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 1. Compute Degree for the ego network\nV(ego_1)$degree &lt;- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree &lt;- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"&lt;b&gt;\", V(ego_1)$label, \"&lt;/b&gt;&lt;br&gt;Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %&gt;%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %&gt;%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %&gt;%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\n\n\n\n\n1c. With a focus on “Nadia Conti”, the visuals above could determine who has influence over this person.\n\n\n\n\nDegree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\nSeveral other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia’s network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that Nadia’s environment is both diverse and robust.\nDirect Connections\nThese direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti’s node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\nPeople: Elise, Liam Thorne, Davis, Rodriguez\nOrganization: V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\nVessel: Neptune, Marlin, Remora, Sentinel\nLocation: Haacklee Harbor\n\nInterpretation: The PageRank, Betweenness, and Degree centrality plots all consistently show Nadia Conti as a major hub, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\nNadia’s position suggests she is a key connector and influencer but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence—and be influenced—is amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia’s access to information, resources, and strategic decisions."
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#task-2-interactions-and-relationships-between-people-vessels",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#task-2-interactions-and-relationships-between-people-vessels",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "Question 2 Goals:\n\nUnderstand and explore interactions and relationships groups between people and vessels.\nIdentify closely associated groups and their thematic focus.\n\n\n\n\n\nEnsure we have a usable network graph:\n\n# Step 1: Convert directed tidygraph to igraph, then undirected\nigraph_undirected &lt;- as.undirected(as.igraph(mc3_graph), mode = \"collapse\")\n\n# Step 2: Convert back to tidygraph (tbl_graph)\nmc3_graph_undirected &lt;- as_tbl_graph(igraph_undirected)\n\n# Step 3: Apply Louvain community detection\nmc3_graph_undirected &lt;- mc3_graph_undirected %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\n\n# Extract node table from graph\npeople_vessels_comm &lt;- mc3_graph_undirected %&gt;%\n  as_tibble() %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(label, sub_type, community)\n\n# Quick look\nhead(people_vessels_comm)\n\n# A tibble: 6 × 3\n  label          sub_type community\n  &lt;chr&gt;          &lt;chr&gt;    &lt;fct&gt;    \n1 Sam            Person   9        \n2 Kelly          Person   9        \n3 Nadia Conti    Person   9        \n4 Elise          Person   9        \n5 Liam Thorne    Person   6        \n6 Samantha Blake Person   1        \n\n\n\n\n\n\n# Community composition\nlibrary(knitr)\n\ngroup_summary &lt;- people_vessels_comm %&gt;%\n  count(community, sub_type, sort = TRUE)\n\nkable(group_summary, caption = \"Distribution of People and Vessels Across Detected Communities\")\n\n\nDistribution of People and Vessels Across Detected Communities\n\n\ncommunity\nsub_type\nn\n\n\n\n\n5\nPerson\n6\n\n\n3\nVessel\n4\n\n\n9\nPerson\n4\n\n\n1\nPerson\n3\n\n\n4\nVessel\n3\n\n\n7\nVessel\n3\n\n\n1\nVessel\n2\n\n\n2\nVessel\n2\n\n\n8\nPerson\n2\n\n\n2\nPerson\n1\n\n\n6\nPerson\n1\n\n\n9\nVessel\n1\n\n\n10\nPerson\n1\n\n\n\n\n\n\n\n\n\nggraph(mc3_graph_undirected, layout = \"fr\") +\n  geom_edge_link(alpha = 0.1, colour = \"grey\") +\n  geom_node_point(aes(color = community, shape = sub_type), size = 3, alpha = 0.9) +\n  geom_node_text(aes(label = ifelse(sub_type %in% c(\"Person\", \"Vessel\"), label, NA_character_)), \n                 size = 2.3, repel = TRUE) +\n  labs(\n    title = \"Community Clusters of People and Vessels in Oceanus\",\n    subtitle = \"Identified using Louvain Algorithm on Undirected Graph\"\n  ) +\n  theme_graph() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nWe will assign themes to nodes and communities based on keywords in label or sub_type. For example:\n\nEntities with “Green” or “Guardian” → Environmental\nLabels with “Sailor Shift” or “Pop” → Sailor Shift\nAny node with sub_type == \"Vessel\" → Vessel\nAll others → Other\n\nCode: Assign Themes to Nodes\n\n# Tag each node in the undirected graph with a thematic label\nmc3_graph_undirected &lt;- mc3_graph_undirected %&gt;%\n  mutate(theme = case_when(\n    str_detect(label, regex(\"Green|Guardian\", ignore_case = TRUE)) ~ \"Environmental\",\n    str_detect(label, regex(\"Sailor Shift|Pop\", ignore_case = TRUE)) ~ \"Sailor Shift\",\n    sub_type == \"Vessel\" ~ \"Vessel\",\n    TRUE ~ \"Other\"\n  ))\n\nCode: Summarize Theme Composition\n\n# Theme breakdown per community\ntheme_summary &lt;- mc3_graph_undirected %&gt;%\n  as_tibble() %&gt;%\n  count(community, theme, sort = TRUE)\n\nknitr::kable(theme_summary, caption = \"Theme Breakdown per Community\")\n\n\nTheme Breakdown per Community\n\n\ncommunity\ntheme\nn\n\n\n\n\n1\nOther\n173\n\n\n2\nOther\n165\n\n\n3\nOther\n152\n\n\n4\nOther\n150\n\n\n5\nOther\n131\n\n\n6\nOther\n113\n\n\n7\nOther\n92\n\n\n8\nOther\n72\n\n\n9\nOther\n65\n\n\n10\nOther\n28\n\n\n3\nVessel\n3\n\n\n4\nVessel\n3\n\n\n7\nVessel\n3\n\n\n1\nSailor Shift\n2\n\n\n1\nVessel\n2\n\n\n2\nVessel\n2\n\n\n3\nEnvironmental\n1\n\n\n4\nEnvironmental\n1\n\n\n9\nVessel\n1\n\n\n\n\n\n\n\n\nWe will now plot faceted or color-coded networks to show how these communities and themes look visually.\n🔹 Option A: Color by Theme\n\nggraph(mc3_graph_undirected, layout = \"fr\") +\n  geom_edge_link(alpha = 0.1, colour = \"grey\") +\n  geom_node_point(aes(color = theme, shape = sub_type), size = 3, alpha = 0.9) +\n  geom_node_text(aes(label = ifelse(sub_type %in% c(\"Person\", \"Vessel\"), label, NA_character_)), \n                 size = 2.3, repel = TRUE) +\n  labs(\n    title = \"Network of People and Vessels in Oceanus\",\n    subtitle = \"Color-coded by Theme (Environmental, Sailor Shift, Vessel)\"\n  ) +\n  theme_graph() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n🔹 Option B: Facet by Theme\n\nggraph(mc3_graph_undirected, layout = \"fr\") +\n  geom_edge_link(alpha = 0.1, colour = \"grey\") +\n  geom_node_point(aes(color = community, shape = sub_type), size = 3, alpha = 0.9) +\n  geom_node_text(aes(label = ifelse(sub_type %in% c(\"Person\", \"Vessel\"), label, NA_character_)), \n                 size = 2.3, repel = TRUE) +\n  facet_nodes(~ theme) +\n  labs(\n    title = \"Community Clusters Faceted by Theme\",\n    subtitle = \"Facets: Environmental, Sailor Shift, Vessel, Other\"\n  ) +\n  theme_graph() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#strategy-for-question-2",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#strategy-for-question-2",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "Use edges that connect Entity → Event (Communication) and Event (Communication) → Entity.\nFocus only on Communication events and extract senders and receivers.\n\n\n# Extract Communication Events from nodes\ncommunication_events &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  select(id, label)\n\n# Extract sent edges: Entity → Communication Event\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% communication_events$id)\n\n# Extract received edges: Communication Event → Entity\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% communication_events$id)\n\n# Join both to get Sender → Communication → Receiver\ncomm_links &lt;- comm_sent_edges %&gt;%\n  select(comm_id = to_id, sender = from_id) %&gt;%\n  inner_join(\n    comm_received_edges %&gt;% select(comm_id = from_id, receiver = to_id),\n    by = \"comm_id\"\n  ) %&gt;%\n  filter(sender != receiver)\n\n\n\n\n\nFrom edges:\n\nSender (Entity) → Communication Event\nCommunication Event → Receiver (Entity)\n\nJoin both directions to link:\nEntity A → Communication Event → Entity B → derive Entity A → Entity B communication links.\n\n\n# Get people and vessel node IDs\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter comm links to include only person ↔ vessel or person ↔ person, etc.\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n\n\n\nNodes: People and Vessels only (from mc3_nodes_cleaned).\nEdges: Summarized links between these nodes based on co-involvement in the same communication event.\n\n\n# Edge weight (number of communications)\nedge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Create node list for graph\nnodes_df &lt;- people_vessels %&gt;%\n  filter(id %in% c(edge_df$sender, edge_df$receiver))\n\n# Build graph object\ncomm_graph &lt;- tbl_graph(nodes = nodes_df, edges = edge_df, directed = FALSE)\n\n\n\n\n\nUse igraph or tidygraph to detect communities.\nAnnotate communities for possible labels (e.g., Green Guardians, Sailor Shift fans) using node metadata.\n\n\ncomm_graph &lt;- comm_graph %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\n\nshape_map &lt;- c(\"Person\" = \"circle\", \"Vessel\" = \"triangle\")\n\ncolor_map &lt;- c(\n  \"Person\" = \"#fc8d62\",\n  \"Organization\" = \"#6baed6\",\n  \"Vessel\" = \"#66c2a2\",\n  \"Location\" = \"#c6dbef\",\n  \"Nadia Conti\" = \"#ffd92f\"\n)\n\nggraph(comm_graph, layout = \"fr\") +\n  geom_edge_link(aes(width = weight), alpha = 0.2, color = \"gray50\") +\n  geom_node_point(aes(color = group, shape = group), size = 4) +\n  geom_node_text(aes(label = label), repel = TRUE, size = 2.5) +\n  scale_shape_manual(values = shape_map) +\n  scale_color_manual(values = color_map) +\n  theme_graph() +\n  labs(title = \"Communication Clusters Between People and Vessels\",\n       subtitle = \"Communities detected using Louvain algorithm\")\n\n\n\n\n\n\n\n\n\n# Get only Person and Vessel nodes\npeople_vessels &lt;- mc3_nodes_cleaned %&gt;%\n  filter(sub_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  select(id, label, group = sub_type)\n\n# Filter communication links for person ↔ vessel/person only\ncomm_links_filtered &lt;- comm_links %&gt;%\n  filter(sender %in% people_vessels$id, receiver %in% people_vessels$id)\n\n\n# Count number of communications between each sender–receiver pair\ncomm_edge_df &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, name = \"weight\")\n\n# Build node dataframe from involved IDs only\ncomm_node_df &lt;- people_vessels %&gt;%\n  filter(id %in% unique(c(comm_edge_df$sender, comm_edge_df$receiver))) %&gt;%\n  mutate(\n    shape = case_when(\n      group == \"Person\" ~ \"dot\",\n      group == \"Vessel\" ~ \"triangle\"\n    ),\n    color = case_when(\n      group == \"Person\" ~ \"#fc8d62\",\n      group == \"Vessel\" ~ \"#66c2a2\",\n      label == \"Nadia Conti\" ~ \"#ffd92f\",\n      TRUE ~ \"#c6dbef\"\n    )\n  )\n\n# Format edges for visNetwork\ncomm_vis_edges &lt;- comm_edge_df %&gt;%\n  rename(from = sender, to = receiver) %&gt;%\n  mutate(width = weight)\n\n\nlibrary(igraph)\n\n# Create igraph object\ngraph_ig &lt;- graph_from_data_frame(comm_vis_edges, directed = FALSE, vertices = comm_node_df)\n\n# Apply Louvain clustering\nlouvain_groups &lt;- cluster_louvain(graph_ig)\ncomm_node_df$group_comm &lt;- as.factor(membership(louvain_groups))\n\n\nlibrary(visNetwork)\n\n# Title heading\ncat(\"### Interactive Network of Communication Between People and Vessels\")\n\n### Interactive Network of Communication Between People and Vessels\n\n# Final interactive visNetwork with consistent styling\nvisNetwork(\n  nodes = comm_node_df,\n  edges = comm_vis_edges\n) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -80,\n      centralGravity = 0.01,\n      springLength = 50,\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = list(\n      list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n      list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n    ),\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  )\n\n\n\n\n\n\n\nCode\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nCode\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nCode\nlibrary(scales)  # for rescale()\n\n# Step 1: Summarize sender–receiver communication volume\ncomm_edges_vis &lt;- comm_links_filtered %&gt;%\n  count(sender, receiver, sort = TRUE) %&gt;%\n  rename(from = sender, to = receiver, value = n)\n\n# Step 2: Compute messages sent per person\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare node attributes (label, shape, color, size)\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#fc8d62\",\n      sub_type == \"Vessel\" ~ \"#66c2a2\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define proper legend nodes (explicit list)\nlegend_nodes &lt;- list(\n  list(label = \"Person\", shape = \"dot\", color = \"#fc8d62\"),\n  list(label = \"Vessel\", shape = \"triangle\", color = \"#66c2a2\")\n)\n\n\n# Step 6: Render visNetwork with layout_on_sphere and custom legend\ncat(\"### Styled Communication Network (Scaled by Sent Messages)\")\n\n\n### Styled Communication Network (Scaled by Sent Messages)\n\n\nCode\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(size = nodes_vis$size) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = legend_nodes,\n    width = 0.1,\n    position = \"left\",\n    stepY = 80,\n    ncol = 1\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -50,   # Increase pull toward center\n      centralGravity = 0.005,        # Lower keeps outer nodes further\n      springLength = 100,            # Length between nodes\n      springConstant = 0.02\n    ),\n    stabilization = list(enabled = TRUE, iterations = 100)\n  ) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages by sender/receiver\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and label\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Bar plot\nggplot(comm_summary, aes(x = reorder(label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(ggtext)\n\n# Step 1: Filter only Communication edges\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\n# Step 2: Count messages sent and received\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 3: Join and format\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\") %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Create colored labels for x-axis\ncomm_summary &lt;- comm_summary %&gt;%\n  mutate(\n    x_label = paste0(\n      \"&lt;span style='color:\",\n      case_when(\n        sub_type == \"Vessel\" ~ \"#66c2a2\",\n        sub_type == \"Person\" ~ \"#fc8d62\",\n        TRUE ~ \"gray\"\n      ),\n      \"'&gt;\", label, \"&lt;/span&gt;\"\n    )\n  )\n\n# Step 5: Bar Plot with colored axis text\nggplot(comm_summary, aes(x = reorder(x_label, -count), y = count, fill = direction)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\")) +\n  labs(\n    title = \"Message Volume by Entity\",\n    x = \"Entity\",\n    y = \"Message Count\",\n    fill = \"Direction\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_markdown(angle = 45, hjust = 1),\n    plot.title = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotly)\nlibrary(DT)\n\n# Step 1: Compute message counts\ncomm_edges_all &lt;- mc3_edges_cleaned %&gt;%\n  filter(type %in% c(\"sent\", \"received\"))\n\nsent_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"sent\") %&gt;%\n  count(from_id, name = \"sent\")\n\nreceived_counts &lt;- comm_edges_all %&gt;%\n  filter(type == \"received\") %&gt;%\n  count(to_id, name = \"received\")\n\n# Step 2: Combine counts\ncomm_summary &lt;- full_join(sent_counts, received_counts, by = c(\"from_id\" = \"to_id\")) %&gt;%\n  rename(id = from_id) %&gt;%\n  replace_na(list(sent = 0, received = 0)) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, label, sub_type), by = \"id\")\n\n# Step 3: Reshape for plotly\ncomm_long &lt;- comm_summary %&gt;%\n  pivot_longer(cols = c(sent, received), names_to = \"direction\", values_to = \"count\")\n\n# Step 4: Plotly bar chart (interactive)\nplot_ly(\n  comm_long,\n  x = ~label,\n  y = ~count,\n  color = ~direction,\n  colors = c(\"sent\" = \"#2ca5ff\", \"received\" = \"#fb8072\"),\n  type = 'bar',\n  text = ~paste0(\"Entity: \", label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Count: \", count),\n  hoverinfo = 'text',\n  name = ~direction\n) %&gt;%\n  layout(\n    title = \"Interactive Message Volume by Entity\",\n    barmode = 'group',\n    xaxis = list(title = \"Entity\", tickangle = -45),\n    yaxis = list(title = \"Message Count\")\n  )\n\n\n\n\n\n\n\nCode\ndatatable(\n  comm_summary %&gt;% arrange(desc(sent + received)),\n  options = list(\n    pageLength = 10,\n    autoWidth = TRUE,\n    searchHighlight = TRUE\n  ),\n  colnames = c(\"ID\", \"Name\", \"Sent\", \"Received\", \"Type\")\n)"
  },
  {
    "objectID": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#strategy-to-tackle-q2b",
    "href": "Test_Folder/David_Q2/Take-Home_Ex02_MC3 - Q2.html#strategy-to-tackle-q2b",
    "title": "Take-Home Assignment 2",
    "section": "",
    "text": "Use igraph::cluster_louvain() on the communication network built in 2a (undirected).\nAssign a community ID to each node (nodes_vis$community).\n\n\n\n\n\nSummarize the composition of each community by:\n\nNumber of persons/vessels\nTop labels in each group\nKnown keywords (e.g., “Green Guardians”, “Sailor Shift”, vessel names like “Aurora” or “Bluefin”)\n\n\n\n\n\n\nAssign a distinct color to each detected community.\nRetain shape encoding (dot = Person, triangle = Vessel).\n\n\n\n\n\nUse visNetwork to display the full communication network:\n\nColor nodes by community\nTooltip includes label, type, community\nLegend for each detected community\n\n\n\nlibrary(igraph)\nlibrary(visNetwork)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Create igraph from person-vessel edges\ng_comm &lt;- graph_from_data_frame(edges_vis, directed = FALSE, vertices = nodes_vis)\n\n# Louvain detection\nlouvain_clusters &lt;- cluster_louvain(g_comm)\nnodes_vis$louvain_comm &lt;- as.factor(membership(louvain_clusters))\n\n# Walktrap detection\nwalktrap_clusters &lt;- cluster_walktrap(g_comm)\nnodes_vis$walktrap_comm &lt;- as.factor(membership(walktrap_clusters))\n\n# Create color palettes\nmax_comm &lt;- max(as.numeric(nodes_vis$louvain_comm), as.numeric(nodes_vis$walktrap_comm))\ncomm_colors &lt;- brewer.pal(n = min(max_comm, 8), name = \"Set2\")\n\n# Assign community color for each method\nnodes_louvain &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(louvain_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Louvain: \", louvain_comm)\n  )\n\nnodes_walktrap &lt;- nodes_vis %&gt;%\n  mutate(\n    color = comm_colors[as.numeric(walktrap_comm)],\n    title = paste0(label, \"&lt;br&gt;Type: \", sub_type, \"&lt;br&gt;Walktrap: \", walktrap_comm)\n  )\n\n\n# Define consistent edge formatting\nedges_format &lt;- edges_vis %&gt;%\n  mutate(arrows = \"to\", width = width)\n\n# Louvain network\nlouvain_net &lt;- visNetwork(nodes_louvain, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Louvain Communities\"), useGroups = FALSE)\n\n# Walktrap network\nwalktrap_net &lt;- visNetwork(nodes_walktrap, edges_format, height = \"700px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(stabilization = TRUE) %&gt;%\n  visLayout(randomSeed = 42) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(main = list(text = \"Walktrap Communities\"), useGroups = FALSE)\n\n📌 Louvain Community Network\n\n\nCode\n# Generate cluster legend for Louvain\nlouvain_legend &lt;- unique(nodes_louvain$louvain_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_louvain$color[nodes_louvain$louvain_comm == comm_id])[1]\n    )\n  })\n\n# Render Louvain network\ncat(\"## Louvain Community Detection Network\")\n\n\n## Louvain Community Detection Network\n\n\nCode\nvisNetwork(nodes_louvain, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_louvain$shape, size = nodes_louvain$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = louvain_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )\n\n\n\n\n\n\n📌 Walktrap Community Network\n\n\nCode\n# Generate cluster legend for Walktrap\nwalktrap_legend &lt;- unique(nodes_walktrap$walktrap_comm) %&gt;%\n  sort() %&gt;%\n  purrr::map(function(comm_id) {\n    list(\n      label = paste(\"Cluster\", comm_id),\n      shape = \"dot\",\n      color = unique(nodes_walktrap$color[nodes_walktrap$walktrap_comm == comm_id])[1]\n    )\n  })\n\n# Render Walktrap network\ncat(\"## Walktrap Community Detection Network\")\n\n\n## Walktrap Community Detection Network\n\n\nCode\nvisNetwork(nodes_walktrap, edges_format, width = \"100%\", height = \"750px\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visPhysics(\n    solver = \"forceAtlas2Based\",\n    forceAtlas2Based = list(\n      gravitationalConstant = -30,\n      centralGravity = 0.001,\n      springLength = 150,\n      springConstant = 0.03\n    ),\n    stabilization = list(enabled = TRUE, iterations = 200)\n  ) %&gt;%\n  visLayout(randomSeed = 42, improvedLayout = TRUE) %&gt;%\n  visNodes(shape = nodes_walktrap$shape, size = nodes_walktrap$size) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visLegend(\n    useGroups = FALSE,\n    addNodes = walktrap_legend,\n    position = \"left\",\n    width = 0.075,\n    stepY = 70,\n    ncol = 1\n  ) %&gt;%\n  visInteraction(\n    dragNodes = TRUE,\n    navigationButtons = TRUE\n  )"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "",
    "text": "This take home exercise is based on the VAST Challenge Mini Case 3\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jessen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation.\nYour task is to develop new and novel visualizations and visual analytics approaches to help Clepper get to the bottom of this story"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html#initial-eda",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html#initial-eda",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "3.1 Initial EDA",
    "text": "3.1 Initial EDA\n\n\nShow code\nExpCatViz(data=mc3_nodes,\n          col=\"pink\")\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html#relationship-between-entities-and-events",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html#relationship-between-entities-and-events",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.1 Relationship between entities and events",
    "text": "6.1 Relationship between entities and events\n\n\nShow code\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 2) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html#entity-distribution",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html#entity-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.2 Entity distribution",
    "text": "6.2 Entity distribution\n\n\nShow code\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html#event-type-distribution",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html#event-type-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.3 Event type distribution",
    "text": "6.3 Event type distribution\n\n\nShow code\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html#list-of-communication-participants",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html#list-of-communication-participants",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4 List of communication participants",
    "text": "6.4 List of communication participants\n\n\nShow code\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html#visualization-of-communication-participants-network",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html#visualization-of-communication-participants-network",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4.1 Visualization of communication participants network",
    "text": "6.4.1 Visualization of communication participants network\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\n# === Load libraries ===\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidygraph)\nlibrary(purrr)\n\n# === Step 1: Load from MC3_graph.json ===\nq2_json &lt;- read_json(\"MC3_graph.json\", simplifyVector = TRUE)\n\n# Convert the nodes correctly (flat list → data frame)\nq2_nodes_raw &lt;- as_tibble(q2_json$nodes)  # Already flattened\n\n# Clean nodes\nq2_nodes_cleaned &lt;- q2_nodes_raw %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n# Edges: all types\nq2_edges_raw &lt;- bind_rows(\n  q2_json$edges$`Entity-&gt;Event`,\n  q2_json$edges$`Event-&gt;Entity`,\n  q2_json$edges$`Entity-&gt;Relationship`,\n  q2_json$edges$`Relationship-&gt;Entity`,\n  q2_json$edges$`Event-&gt;Event`,\n  q2_json$edges$`Event-&gt;Relationship`\n)\n\n# === Step 2: Clean Nodes ===\nq2_edges_raw &lt;- as_tibble(q2_json$edges)\n\nq2_edges_cleaned &lt;- q2_edges_raw %&gt;%\n  rename(from_id = source, to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), as.character)) %&gt;%\n  filter(from_id %in% q2_nodes_cleaned$id,\n         to_id %in% q2_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n# === Step 3: Clean Edges ===\nq2_edges_cleaned &lt;- q2_edges_raw %&gt;%\n  rename(from_id = source, to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), as.character)) %&gt;%\n  filter(from_id %in% q2_nodes_cleaned$id,\n         to_id %in% q2_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n# === Step 4: Build index lookup ===\nq2_node_index &lt;- q2_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n# === Step 5: Join edge IDs to node index ===\nq2_edges_indexed &lt;- q2_edges_cleaned %&gt;%\n  left_join(q2_node_index, by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(q2_node_index, by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# === Step 6: Subset nodes that are used in edges ===\nq2_used_node_ids &lt;- sort(unique(c(q2_edges_indexed$from, q2_edges_indexed$to)))\n\nq2_nodes_final &lt;- q2_nodes_cleaned %&gt;%\n  slice(q2_used_node_ids) %&gt;%\n  mutate(new_index = row_number())\n\n# === Step 7: Remap old indices in edges to new ones ===\nq2_index_remap &lt;- tibble(\n  old_index = q2_used_node_ids,\n  new_index = seq_along(q2_used_node_ids)\n)\n\nq2_edges_final &lt;- q2_edges_indexed %&gt;%\n  left_join(q2_index_remap, by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(q2_index_remap, by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, is_inferred, type)\n\n# === Step 8: Build tidygraph ===\nq2_graph &lt;- tbl_graph(\n  nodes = q2_nodes_final,\n  edges = q2_edges_final,\n  directed = TRUE\n)\n\n\n\nFiltering Communication Events\nTo begin our analysis of interaction patterns, we first isolate only the communication-related events from the full knowledge graph. These are represented in the dataset as nodes where type is \"Event\" and the sub_type is \"Communication\". These nodes correspond to actual radio or verbal exchanges logged in the system.\nThis filtering step ensures that we focus solely on the core transmission of information between entities — ignoring unrelated events such as movements, assessments, or reporting.\nThe resulting subset comm_events_q2 serves as the foundation for identifying who communicated with whom in the subsequent steps of our analysis.\n\n\nShow code\ncomm_events_q2 &lt;- q2_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\")\n\n\n\n\nExtracting Essential Communication Fields\nWith our subset of communication events (comm_events_q2) identified, we now extract only the essential fields required for downstream analysis:\n\nid: The unique identifier of each communication event node\ntimestamp: The time the message was logged\ncontent: The body of the message, which may contain names, vessel references, or pseudonyms\n\nThis produces a concise working table focused on the core attributes needed to trace interactions and perform text-based analysis. The content column, in particular, will play a critical role in revealing pseudonymous references and frequently co-mentioned entities, which are key to uncovering influence patterns and answering Question 2b and 3a.\nIn the next step, we will standardize the timestamp for use in time-based charts and aggregations.\n\n\nShow code\ncomm_events_q2 &lt;- comm_events_q2 %&gt;%\n  select(id, timestamp = timestamp, content = content)\n\n\n\n\nConverting Timestamps to Datetime Format\nThe timestamp field in our comm_events_q2 table was originally stored as a character string. To support time-based analysis such as daily trends, hourly grouping, or temporal filtering, we convert the timestamp into a proper datetime object using the ymd_hms() function from the lubridate package.\nThis transformation standardizes all timestamps into POSIXct format, making them compatible with datetime-based operations in ggplot2, dplyr, and ggraph.\nWith properly formatted timestamps, we can now begin linking these communication records to their sender and receiver nodes — using the knowledge graph’s edge table.\n\n\nShow code\nlibrary(lubridate)\n\ncomm_events_q2 &lt;- comm_events_q2 %&gt;%\n  mutate(timestamp = ymd_hms(timestamp))\n\n\n\n\nFiltering Edges for Sender and Receiver Links\nTo map who sent and received each communication, we filter the edge list to retain only those records where type is either \"sent\" or \"received\". These denote directional communication connections between entities and events.\nIn this structure: - source refers to the initiating entity (e.g., a person or vessel) - target refers to the communication event (a node of type Event) - type indicates whether the action was a message being sent or received\nThis refined subset, comm_edges_q2, will allow us to join communication event nodes to their participants. In the next step, we will reshape this edge list into a format where each communication row includes both the sender and receiver — an essential structure for downstream interaction visualizations and pseudonym detection.\n\n\nShow code\ncomm_edges_q2 &lt;- q2_edges_raw %&gt;%\n  filter(type %in% c(\"sent\", \"received\")) %&gt;%\n  select(source, target, type)\n\n\n\n\nSeparating Senders and Receivers\nWe now divide the directional communication edges into two distinct subsets — one representing message senders, and the other message receivers. This separation is based on the type of the edge (\"sent\" or \"received\"):\n\nIn the senders_q2 table, the source node is the entity who sent the message, and the target is the message node.\nIn the receivers_q2 table, the target node is the entity who received the message, and the source is the message node.\n\nBy renaming the shared message node to a common field (message_id), we create a consistent schema across both tables. This setup enables us to perform a join in the next step, reconstructing complete sender–receiver paths for each communication.\nThis representation is crucial for: - Mapping direct communication flows (Q2a) - Identifying alias usage and common message pathways (Q3a)\n\n\nShow code\n# Separate senders\nsenders_q2 &lt;- comm_edges_q2 %&gt;%\n  filter(type == \"sent\") %&gt;%\n  rename(sender = source, message_id = target)\n\n# Separate receivers\nreceivers_q2 &lt;- comm_edges_q2 %&gt;%\n  filter(type == \"received\") %&gt;%\n  rename(receiver = target, message_id = source)\n\n\n\n\nCreating Sender–Receiver Pairs\nNow that we have separated sender and receiver records, we join them using the common message_id. This produces a structure where each row represents one complete communication:\n\nsender: the entity that initiated the message\nreceiver: the entity that received it\nmessage_id: the identifier of the communication event\n\nThis comm_pairs_q2 table becomes the core person-to-person interaction dataset, enabling us to build networks, identify frequent message paths, and trace potential alias usage.\nIn the next step, we enrich this with timestamp and message content to fully contextualize each interaction.\n\n\nShow code\n# Join on message_id\ncomm_pairs_q2 &lt;- inner_join(senders_q2, receivers_q2, by = \"message_id\")\n\n\n\n\nAdding Message Content and Timing\nTo complete our interaction data, we join the sender–receiver pairs with the original communication event records. This adds two critical fields:\n\ntimestamp: when the message occurred (in POSIXct datetime format)\ncontent: the actual text or subject of the message\n\nThis full dataset, comm_full_q2, allows us to: - Trace who messaged whom, when, and what was said - Detect clusters or frequently interacting groups (Q2b) - Identify pseudonym usage or name overlaps (Q3a)\nIt also prepares us to build structured network visualizations and perform deeper temporal or semantic analysis.\n\n\nShow code\n# Combine with content and timestamp\ncomm_full_q2 &lt;- comm_pairs_q2 %&gt;%\n  left_join(comm_events_q2, by = c(\"message_id\" = \"id\"))\n\n\n\n\nResolving Official Labels for Senders and Receivers\nTo ensure clarity in our visualizations and pseudonym analysis, we join readable labels and subtypes to both the sender and receiver entities. We create a lookup table, entity_labels_q2, that contains:\n\nid: unique identifier\nlabel: human-readable name (e.g., “Kelly”, “Sailor Shift”)\nsub_type: whether the entity is a Person, Vessel, Organization, etc.\n\nThis join is critical to: - Accurately label nodes in network plots - Normalize ambiguous or reused IDs - Track patterns of alias reuse across different messages\n\n\nShow code\nentity_labels_q2 &lt;- q2_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  select(id, label, sub_type)\n\n\n\n\nEnriching with Entity Labels and Preparing for Network Construction\nTo finalize the communication dataset, we join readable label and sub_type attributes for both senders and receivers. This eliminates ambiguity around entity IDs and provides a human-readable structure that includes:\n\nsender_label and receiver_label (e.g., “Nadia Conti”, “The Intern”)\nsender_type and receiver_type (e.g., Person, Vessel)\nMessage content and timestamp\n\nThis enriched table, comm_full_q2, now forms the basis for constructing our communication network and detecting social clusters — all without the need to export to CSV. The dataset remains in memory and feeds directly into the interactive visualization engine.\n\n\nShow code\n# Join readable labels and subtypes\ncomm_full_q2 &lt;- comm_full_q2 %&gt;%\n  left_join(entity_labels_q2, by = c(\"sender\" = \"id\")) %&gt;%\n  rename(sender_label = label, sender_type = sub_type) %&gt;%\n  left_join(entity_labels_q2, by = c(\"receiver\" = \"id\")) %&gt;%\n  rename(receiver_label = label, receiver_type = sub_type)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC2.html#question-2-communication-network-group-detection",
    "href": "main_project_qmd/main_project_qmd/main_DC2.html#question-2-communication-network-group-detection",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Question 2 – Communication Network & Group Detection",
    "text": "Question 2 – Communication Network & Group Detection\nTo analyze the structure of intercepted messages, we construct an interactive network where nodes represent individuals and vessels, and edges represent direct communication. Each directed edge indicates a message from a sender to a receiver, derived from parsed radio transmissions.\n\nKey Features of the Network Visualization\n\nNode Labels: Names and aliases are displayed directly, enabling entity recognition at a glance.\nEdge Direction: Arrows show message flow (who talked to whom).\nNode Size: Reflects message volume (total sent + received).\nTooltip: Shows exact count of messages sent and received per entity.\nColoring & Grouping: Louvain clustering reveals distinct communication groups — possibly corresponding to factions like Green Guardians, Sailor Shift’s entourage, or suspicious vessels.\nFiltering Controls: Users can interactively isolate individuals or entire communities.\nNavigation UI: Built-in zoom, pan, and full-view support helps explore dense areas.\n\nThis visualization directly addresses: - Q2a: Mapping who communicates with whom - Q2b: Detecting distinct communication groups\nThe structure suggests coordinated behavior among subsets of individuals, likely reflecting underlying roles, affiliations, or orchestrated activity. These clusters warrant deeper investigation in the context of known suspects and potential pseudonym usage.\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\n\n# Step 0: Filter person ↔ vessel/entity messages\nedge_list_q2 &lt;- comm_full_q2 %&gt;%\n  filter(sender_type %in% c(\"Person\", \"Vessel\"),\n         receiver_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  filter(!is.na(sender_label) & !is.na(receiver_label)) %&gt;%\n  count(sender_label, receiver_label, name = \"weight\")\n\n# Step 1: igraph object\ngraph_comm_q2 &lt;- graph_from_data_frame(edge_list_q2, directed = TRUE)\n\n# Step 2: Convert to undirected before Louvain\ngraph_comm_q2_undirected &lt;- as.undirected(graph_comm_q2, mode = \"collapse\")\nclusters_q2 &lt;- cluster_louvain(graph_comm_q2_undirected)\n\n# Step 3: Node degrees\ndeg_out_q2 &lt;- degree(graph_comm_q2, mode = \"out\")\ndeg_in_q2  &lt;- degree(graph_comm_q2, mode = \"in\")\n\n# Step 4: Nodes with cluster and interactivity\nnodes_q2 &lt;- data.frame(\n  id    = V(graph_comm_q2)$name,\n  label = V(graph_comm_q2)$name,\n  title = paste0(\"📤 Sent: \", deg_out_q2, \"&lt;br&gt;📥 Received: \", deg_in_q2),\n  group = paste(\"Cluster\", clusters_q2$membership),\n  value = deg_out_q2 + deg_in_q2\n)\n\n# Step 5: Edges with arrows\nedges_q2 &lt;- data.frame(\n  from   = as_edgelist(graph_comm_q2)[, 1],\n  to     = as_edgelist(graph_comm_q2)[, 2],\n  arrows = \"to\"\n)\n\n# Step 6: Render interactive network\nvisNetwork(nodes_q2, edges_q2, height = \"700px\", width = \"100%\") %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    selectedBy = list(variable = \"group\", multiple = FALSE, main = \"Select by cluster\"),\n    nodesIdSelection = list(enabled = TRUE, main = \"Select by entity\")\n  ) %&gt;%\n  visLegend() %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\", stabilization = TRUE) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLayout(randomSeed = 42)\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(tidytext)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(stringr)\n\n# Step 1: Get Louvain membership for each node\nnode_cluster_q2 &lt;- data.frame(\n  label   = V(graph_comm_q2)$name,\n  cluster = clusters_q2$membership\n)\n\n# Step 2: Add sender/receiver cluster membership\ncomm_with_cluster_q2 &lt;- comm_full_q2 %&gt;%\n  filter(sender_type %in% c(\"Person\", \"Vessel\"),\n         receiver_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  left_join(node_cluster_q2, by = c(\"sender_label\" = \"label\")) %&gt;%\n  rename(sender_cluster = cluster) %&gt;%\n  left_join(node_cluster_q2, by = c(\"receiver_label\" = \"label\")) %&gt;%\n  rename(receiver_cluster = cluster)\n\n# Step 3: Pivot to long format\ncomm_long_q2 &lt;- comm_with_cluster_q2 %&gt;%\n  select(content, sender_cluster, receiver_cluster) %&gt;%\n  rename(message_content = content) %&gt;%\n  pivot_longer(cols = c(sender_cluster, receiver_cluster),\n               names_to = \"role\", values_to = \"cluster\") %&gt;%\n  filter(!is.na(cluster), !is.na(message_content))\n\n# Step 4: Tokenize and remove stopwords\ndata(\"stop_words\")\n\ntokens_by_cluster_q2 &lt;- comm_long_q2 %&gt;%\n  unnest_tokens(word, message_content) %&gt;%\n  filter(!word %in% stop_words$word, str_detect(word, \"[a-z]\")) %&gt;%\n  count(cluster, word, sort = TRUE)\n\n# Step 5: Top 20 keywords per cluster\ntop_keywords_q2 &lt;- tokens_by_cluster_q2 %&gt;%\n  group_by(cluster) %&gt;%\n  slice_max(n, n = 20, with_ties = FALSE) %&gt;%\n  arrange(cluster, desc(n)) %&gt;%\n  ungroup()\n\n# Optional: Structure into list by cluster\nkeyword_lists_q2 &lt;- top_keywords_q2 %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster_\", sort(unique(top_keywords_q2$cluster)))\n\n\n\n\nShow code\n# Option A: Print tables for Cluster 1 to Cluster 4\nlibrary(knitr)   # For kable\nlibrary(kableExtra)\n\n# Show tables side-by-side (if you want in columns)\nfor (i in 1:4) {\n  cluster_df &lt;- keyword_lists_q2[[i]]\n  cluster_label &lt;- names(keyword_lists_q2)[i]\n\n  cat(paste0(\"### 🔹 \", cluster_label, \"\\n\\n\"))  # Section header\n  cluster_df %&gt;%\n    select(Word = word, Frequency = n) %&gt;%\n    kable(\"html\", caption = paste(\"Top Keywords for\", cluster_label)) %&gt;%\n    kable_styling(full_width = FALSE)\n}\n\n\n### 🔹 Cluster_1\n\n### 🔹 Cluster_2\n\n### 🔹 Cluster_3\n\n### 🔹 Cluster_4\n\n\n\n\n\n\nShow code\nlibrary(gt)\n\n# Define color per cluster\ncluster_colors &lt;- c(\n  \"Cluster_1\" = \"#1f77b4\",  # blue\n  \"Cluster_2\" = \"#d62728\",  # red\n  \"Cluster_3\" = \"#2ca02c\",  # green\n  \"Cluster_4\" = \"#9467bd\"   # purple\n)\n\n# Generate one gt table per cluster\nfor (i in 1:4) {\n  cluster_df &lt;- keyword_lists_q2[[i]]\n  cluster_name &lt;- names(keyword_lists_q2)[i]\n  \n  cluster_df %&gt;%\n    select(Word = word, Frequency = n) %&gt;%\n    gt() %&gt;%\n    tab_header(\n      title = md(paste0(\"**Top 20 Keywords – \", cluster_name, \"**\"))\n    ) %&gt;%\n    tab_options(\n      table.width = pct(60),\n      heading.background.color = cluster_colors[cluster_name],\n      heading.align = \"left\"\n    ) %&gt;%\n    cols_label(\n      Word = \"Keyword\",\n      Frequency = \"Mentions\"\n    ) %&gt;%\n    data_color(\n      columns = vars(Frequency),\n      colors = scales::col_numeric(\n        palette = c(\"white\", cluster_colors[cluster_name]),\n        domain = NULL\n      )\n    ) %&gt;%\n    print()  # In Quarto, this auto-renders under each cluster\n}\n\n\n&lt;div id=\"ajdnxyiwtn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#ajdnxyiwtn table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#ajdnxyiwtn thead, #ajdnxyiwtn tbody, #ajdnxyiwtn tfoot, #ajdnxyiwtn tr, #ajdnxyiwtn td, #ajdnxyiwtn th {\n  border-style: none;\n}\n\n#ajdnxyiwtn p {\n  margin: 0;\n  padding: 0;\n}\n\n#ajdnxyiwtn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: 60%;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#ajdnxyiwtn .gt_title {\n  color: #FFFFFF;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ajdnxyiwtn .gt_subtitle {\n  color: #FFFFFF;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ajdnxyiwtn .gt_heading {\n  background-color: #1F77B4;\n  text-align: left;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ajdnxyiwtn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ajdnxyiwtn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ajdnxyiwtn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ajdnxyiwtn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ajdnxyiwtn .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#ajdnxyiwtn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#ajdnxyiwtn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ajdnxyiwtn .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#ajdnxyiwtn .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#ajdnxyiwtn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ajdnxyiwtn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ajdnxyiwtn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#ajdnxyiwtn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#ajdnxyiwtn .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#ajdnxyiwtn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ajdnxyiwtn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#ajdnxyiwtn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ajdnxyiwtn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ajdnxyiwtn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ajdnxyiwtn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ajdnxyiwtn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ajdnxyiwtn .gt_left {\n  text-align: left;\n}\n\n#ajdnxyiwtn .gt_center {\n  text-align: center;\n}\n\n#ajdnxyiwtn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ajdnxyiwtn .gt_font_normal {\n  font-weight: normal;\n}\n\n#ajdnxyiwtn .gt_font_bold {\n  font-weight: bold;\n}\n\n#ajdnxyiwtn .gt_font_italic {\n  font-style: italic;\n}\n\n#ajdnxyiwtn .gt_super {\n  font-size: 65%;\n}\n\n#ajdnxyiwtn .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#ajdnxyiwtn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#ajdnxyiwtn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#ajdnxyiwtn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#ajdnxyiwtn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#ajdnxyiwtn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#ajdnxyiwtn .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#ajdnxyiwtn .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#ajdnxyiwtn div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_heading\"&gt;\n      &lt;td colspan=\"2\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style&gt;&lt;span data-qmd-base64=\"KipUb3AgMjAgS2V5d29yZHMg4oCTIENsdXN0ZXJfMSoq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Top 20 Keywords – Cluster_1&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n    \n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Word\"&gt;Keyword&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Frequency\"&gt;Mentions&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;reef&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #1F77B4; color: #FFFFFF;\"&gt;131&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;nemo&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #4584BC; color: #FFFFFF;\"&gt;120&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;money&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #84A7D0; color: #000000;\"&gt;91&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;intern&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #86A9D1; color: #000000;\"&gt;90&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;meeting&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #88AAD1; color: #000000;\"&gt;89&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;lookout&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #8AABD2; color: #000000;\"&gt;88&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;conservation&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #9FB9DA; color: #000000;\"&gt;77&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;tomorrow&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #B7CAE3; color: #000000;\"&gt;64&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;boss&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #C1D2E7; color: #000000;\"&gt;58&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;middleman&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #D0DCED; color: #000000;\"&gt;50&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;birdwatching&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #DEE7F2; color: #000000;\"&gt;42&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;bring&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #DEE7F2; color: #000000;\"&gt;42&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;vessels&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #E0E8F3; color: #000000;\"&gt;41&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;equipment&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #EBF0F7; color: #000000;\"&gt;35&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;council&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F2F5FA; color: #000000;\"&gt;31&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;underwater&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F8FAFC; color: #000000;\"&gt;28&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;spotted&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FBFCFE; color: #000000;\"&gt;26&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;activity&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;24&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;harbor&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;24&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;hey&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;24&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  \n  \n&lt;/table&gt;\n&lt;/div&gt;\n\n\n&lt;div id=\"fivmrfaexf\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#fivmrfaexf table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#fivmrfaexf thead, #fivmrfaexf tbody, #fivmrfaexf tfoot, #fivmrfaexf tr, #fivmrfaexf td, #fivmrfaexf th {\n  border-style: none;\n}\n\n#fivmrfaexf p {\n  margin: 0;\n  padding: 0;\n}\n\n#fivmrfaexf .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: 60%;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#fivmrfaexf .gt_title {\n  color: #FFFFFF;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#fivmrfaexf .gt_subtitle {\n  color: #FFFFFF;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#fivmrfaexf .gt_heading {\n  background-color: #D62728;\n  text-align: left;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#fivmrfaexf .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#fivmrfaexf .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#fivmrfaexf .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#fivmrfaexf .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#fivmrfaexf .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#fivmrfaexf .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#fivmrfaexf .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fivmrfaexf .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#fivmrfaexf .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#fivmrfaexf .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#fivmrfaexf .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fivmrfaexf .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#fivmrfaexf .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#fivmrfaexf .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#fivmrfaexf .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fivmrfaexf .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#fivmrfaexf .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fivmrfaexf .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#fivmrfaexf .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fivmrfaexf .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fivmrfaexf .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fivmrfaexf .gt_left {\n  text-align: left;\n}\n\n#fivmrfaexf .gt_center {\n  text-align: center;\n}\n\n#fivmrfaexf .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#fivmrfaexf .gt_font_normal {\n  font-weight: normal;\n}\n\n#fivmrfaexf .gt_font_bold {\n  font-weight: bold;\n}\n\n#fivmrfaexf .gt_font_italic {\n  font-style: italic;\n}\n\n#fivmrfaexf .gt_super {\n  font-size: 65%;\n}\n\n#fivmrfaexf .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#fivmrfaexf .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#fivmrfaexf .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#fivmrfaexf .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#fivmrfaexf .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#fivmrfaexf .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#fivmrfaexf .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#fivmrfaexf .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#fivmrfaexf div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_heading\"&gt;\n      &lt;td colspan=\"2\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style&gt;&lt;span data-qmd-base64=\"KipUb3AgMjAgS2V5d29yZHMg4oCTIENsdXN0ZXJfMioq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Top 20 Keywords – Cluster_2&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n    \n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Word\"&gt;Keyword&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Frequency\"&gt;Mentions&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;miranda&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #D62728; color: #FFFFFF;\"&gt;76&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;equipment&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F9A394; color: #000000;\"&gt;42&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;clepper&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FBA99B; color: #000000;\"&gt;40&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;jensen&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FDB5A9; color: #000000;\"&gt;36&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;environmental&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFCEC5; color: #000000;\"&gt;28&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;vessels&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFCEC5; color: #000000;\"&gt;28&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;conservation&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFE0DA; color: #000000;\"&gt;22&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;documents&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFE6E2; color: #000000;\"&gt;20&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;rodriguez&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFE6E2; color: #000000;\"&gt;20&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;document&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFECE9; color: #000000;\"&gt;18&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;harbor&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFECE9; color: #000000;\"&gt;18&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;security&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFECE9; color: #000000;\"&gt;18&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;vessel&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFECE9; color: #000000;\"&gt;18&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;council&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFF3F0; color: #000000;\"&gt;16&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;reef&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFF3F0; color: #000000;\"&gt;16&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;nemo&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFF9F8; color: #000000;\"&gt;14&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;knowles&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;12&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;meeting&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;12&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;miesel&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;12&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;officials&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;12&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  \n  \n&lt;/table&gt;\n&lt;/div&gt;\n\n\n&lt;div id=\"jblsbooqxr\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#jblsbooqxr table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#jblsbooqxr thead, #jblsbooqxr tbody, #jblsbooqxr tfoot, #jblsbooqxr tr, #jblsbooqxr td, #jblsbooqxr th {\n  border-style: none;\n}\n\n#jblsbooqxr p {\n  margin: 0;\n  padding: 0;\n}\n\n#jblsbooqxr .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: 60%;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#jblsbooqxr .gt_title {\n  color: #FFFFFF;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#jblsbooqxr .gt_subtitle {\n  color: #FFFFFF;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#jblsbooqxr .gt_heading {\n  background-color: #2CA02C;\n  text-align: left;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#jblsbooqxr .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#jblsbooqxr .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#jblsbooqxr .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#jblsbooqxr .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#jblsbooqxr .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#jblsbooqxr .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#jblsbooqxr .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jblsbooqxr .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#jblsbooqxr .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#jblsbooqxr .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#jblsbooqxr .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jblsbooqxr .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#jblsbooqxr .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#jblsbooqxr .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#jblsbooqxr .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jblsbooqxr .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#jblsbooqxr .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jblsbooqxr .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#jblsbooqxr .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jblsbooqxr .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jblsbooqxr .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jblsbooqxr .gt_left {\n  text-align: left;\n}\n\n#jblsbooqxr .gt_center {\n  text-align: center;\n}\n\n#jblsbooqxr .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#jblsbooqxr .gt_font_normal {\n  font-weight: normal;\n}\n\n#jblsbooqxr .gt_font_bold {\n  font-weight: bold;\n}\n\n#jblsbooqxr .gt_font_italic {\n  font-style: italic;\n}\n\n#jblsbooqxr .gt_super {\n  font-size: 65%;\n}\n\n#jblsbooqxr .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#jblsbooqxr .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#jblsbooqxr .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#jblsbooqxr .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#jblsbooqxr .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#jblsbooqxr .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#jblsbooqxr .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#jblsbooqxr .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#jblsbooqxr div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_heading\"&gt;\n      &lt;td colspan=\"2\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style&gt;&lt;span data-qmd-base64=\"KipUb3AgMjAgS2V5d29yZHMg4oCTIENsdXN0ZXJfMyoq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Top 20 Keywords – Cluster_3&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n    \n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Word\"&gt;Keyword&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Frequency\"&gt;Mentions&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;mako&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #2CA02C; color: #FFFFFF;\"&gt;168&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;reef&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #73BB67; color: #000000;\"&gt;132&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;equipment&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #76BC6B; color: #000000;\"&gt;130&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;nemo&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #96CC8C; color: #000000;\"&gt;109&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;remora&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #9BCE90; color: #000000;\"&gt;106&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;neptune&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #BADDB2; color: #000000;\"&gt;85&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;davis&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #C2E1BA; color: #000000;\"&gt;80&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;team&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #D3EACD; color: #000000;\"&gt;68&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;tomorrow&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #D3EACD; color: #000000;\"&gt;68&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;protocols&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #E3F1DF; color: #000000;\"&gt;57&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;harbor&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #E5F2E1; color: #000000;\"&gt;56&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;operation&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #EBF5E8; color: #000000;\"&gt;52&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;security&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #EEF6EB; color: #000000;\"&gt;50&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;nadia&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #EFF7ED; color: #000000;\"&gt;49&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;maintain&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F3F9F2; color: #000000;\"&gt;46&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;operations&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F5FAF3; color: #000000;\"&gt;45&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;meeting&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FBFDFA; color: #000000;\"&gt;41&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;route&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FEFEFD; color: #000000;\"&gt;39&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;transfer&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FEFEFD; color: #000000;\"&gt;39&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;confirmed&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;38&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  \n  \n&lt;/table&gt;\n&lt;/div&gt;\n\n\n&lt;div id=\"ayhlakgtox\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"&gt;\n  &lt;style&gt;#ayhlakgtox table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#ayhlakgtox thead, #ayhlakgtox tbody, #ayhlakgtox tfoot, #ayhlakgtox tr, #ayhlakgtox td, #ayhlakgtox th {\n  border-style: none;\n}\n\n#ayhlakgtox p {\n  margin: 0;\n  padding: 0;\n}\n\n#ayhlakgtox .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: 60%;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#ayhlakgtox .gt_title {\n  color: #FFFFFF;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ayhlakgtox .gt_subtitle {\n  color: #FFFFFF;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ayhlakgtox .gt_heading {\n  background-color: #9467BD;\n  text-align: left;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ayhlakgtox .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ayhlakgtox .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ayhlakgtox .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ayhlakgtox .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ayhlakgtox .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#ayhlakgtox .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#ayhlakgtox .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ayhlakgtox .gt_from_md &gt; :first-child {\n  margin-top: 0;\n}\n\n#ayhlakgtox .gt_from_md &gt; :last-child {\n  margin-bottom: 0;\n}\n\n#ayhlakgtox .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ayhlakgtox .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ayhlakgtox .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#ayhlakgtox .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#ayhlakgtox .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#ayhlakgtox .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ayhlakgtox .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#ayhlakgtox .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ayhlakgtox .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ayhlakgtox .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ayhlakgtox .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ayhlakgtox .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ayhlakgtox .gt_left {\n  text-align: left;\n}\n\n#ayhlakgtox .gt_center {\n  text-align: center;\n}\n\n#ayhlakgtox .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ayhlakgtox .gt_font_normal {\n  font-weight: normal;\n}\n\n#ayhlakgtox .gt_font_bold {\n  font-weight: bold;\n}\n\n#ayhlakgtox .gt_font_italic {\n  font-style: italic;\n}\n\n#ayhlakgtox .gt_super {\n  font-size: 65%;\n}\n\n#ayhlakgtox .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#ayhlakgtox .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#ayhlakgtox .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#ayhlakgtox .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#ayhlakgtox .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#ayhlakgtox .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#ayhlakgtox .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#ayhlakgtox .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#ayhlakgtox div.Reactable &gt; div.rt-table &gt; div.rt-thead &gt; div.rt-tr.rt-tr-group-header &gt; div.rt-th-group:after {\n  height: 0px !important;\n}\n&lt;/style&gt;\n  &lt;table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"&gt;\n  &lt;thead&gt;\n    &lt;tr class=\"gt_heading\"&gt;\n      &lt;td colspan=\"2\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style&gt;&lt;span data-qmd-base64=\"KipUb3AgMjAgS2V5d29yZHMg4oCTIENsdXN0ZXJfNCoq\"&gt;&lt;span class='gt_from_md'&gt;&lt;strong&gt;Top 20 Keywords – Cluster_4&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;\n    &lt;/tr&gt;\n    \n    &lt;tr class=\"gt_col_headings\"&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Word\"&gt;Keyword&lt;/th&gt;\n      &lt;th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Frequency\"&gt;Mentions&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody class=\"gt_table_body\"&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;reef&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #9467BD; color: #FFFFFF;\"&gt;167&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;nemo&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #CEB6E1; color: #000000;\"&gt;89&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;guardian&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #D4BFE4; color: #000000;\"&gt;81&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;equipment&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #D7C3E6; color: #000000;\"&gt;77&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;sentinel&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #E8DCF1; color: #000000;\"&gt;53&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;vessels&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #E8DCF1; color: #000000;\"&gt;53&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;horizon&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #E9DEF1; color: #000000;\"&gt;52&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;ecovigil&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F2EBF7; color: #000000;\"&gt;39&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;activity&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F8F4FB; color: #000000;\"&gt;31&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;eastern&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F9F5FB; color: #000000;\"&gt;30&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;position&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #F9F6FB; color: #000000;\"&gt;29&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;quadrant&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FBF8FC; color: #000000;\"&gt;27&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;boundary&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FBFAFD; color: #000000;\"&gt;26&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;mako&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FBFAFD; color: #000000;\"&gt;26&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;tourism&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FBFAFD; color: #000000;\"&gt;26&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;appears&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FCFBFD; color: #000000;\"&gt;25&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;activities&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FDFCFE; color: #000000;\"&gt;24&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;vessel&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FEFDFE; color: #000000;\"&gt;23&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;closure&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;21&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td headers=\"Word\" class=\"gt_row gt_left\"&gt;documentation&lt;/td&gt;\n&lt;td headers=\"Frequency\" class=\"gt_row gt_right\" style=\"background-color: #FFFFFF; color: #000000;\"&gt;21&lt;/td&gt;&lt;/tr&gt;\n  &lt;/tbody&gt;\n  \n  \n&lt;/table&gt;\n&lt;/div&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# Load libraries\nlibrary(visNetwork)\n\n# Prepare visNetwork nodes\nq2_vis_nodes &lt;- q2_nodes_final %&gt;%\n  mutate(id = row_number(),\n         label = ifelse(is.na(name), id, name),\n         group = sub_type,\n         title = paste0(\"&lt;b&gt;\", label, \"&lt;/b&gt;&lt;br&gt;Type: \", type, \"&lt;br&gt;Subtype: \", sub_type),\n         color = case_when(\n           sub_type == \"Person\"        ~ \"#fc8d62\",\n           sub_type == \"Organization\"  ~ \"#6baed6\",\n           sub_type == \"Vessel\"        ~ \"#66c2a2\",\n           sub_type == \"Location\"      ~ \"#c6dbef\",\n           sub_type == \"Unknown\"       ~ \"#7f7f7f\",\n           TRUE                        ~ \"#9467bd\"\n         ))\n\n# Prepare visNetwork edges\nq2_vis_edges &lt;- q2_edges_final %&gt;%\n  mutate(\n    title = paste(\"Type:\", type, \"&lt;br&gt;Inferred:\", is_inferred),\n    arrows = \"to\",\n    width = 1,\n    color = ifelse(is_inferred, \"gray\", \"#636363\")\n  )\n\n# Create visNetwork graph\nvisNetwork(q2_vis_nodes, q2_vis_edges, height = \"700px\", width = \"100%\") %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visLegend(useGroups = TRUE) %&gt;%\n  visLayout(randomSeed = 42)\n\n\n\n\n\n\n\n\nShow code\nlibrary(tidygraph)\n\n# Convert to undirected for community detection\nq2_graph_comm &lt;- q2_graph %&gt;%\n  convert(to_undirected) %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n\nShow code\nlibrary(visNetwork)\nlibrary(dplyr)\n\n# Prepare nodes\nnodes_q2a &lt;- q2_graph_comm %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    id = row_number(),\n    title = paste0(\"&lt;b&gt;\", label, \"&lt;/b&gt;&lt;br&gt;\", sub_type),\n    group = sub_type,       # use for coloring\n    community = community   # for optional filter\n  )\n\n# Prepare edges\nedges_q2a &lt;- q2_edges_final %&gt;%\n  rename(from = from, to = to) %&gt;%\n  mutate(width = 1)  # optional: set edge width\n\n# Optional color palette (reuse from prior file or define)\nsubtype_colors &lt;- c(\n  \"Person\" = \"#fbb4ae\",\n  \"Vessel\" = \"#b3cde3\",\n  \"Organization\" = \"#ccebc5\",\n  \"Location\" = \"#decbe4\",\n  \"Unknown\" = \"#f2f2f2\"\n)\n\n\n\n\nShow code\nvisNetwork(nodes_q2a, edges_q2a, height = \"700px\", width = \"100%\") %&gt;%\n  visNodes(\n    shape = \"dot\",\n    color = list(\n      background = subtype_colors[nodes_q2a$group],\n      border = \"#333333\",\n      highlight = \"#ffcc00\"\n    )\n  ) %&gt;%\n  visEdges(\n    color = list(color = \"#cccccc\", highlight = \"#ff9900\"),\n    arrows = \"to\"\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    selectedBy = \"community\"\n  ) %&gt;%\n  visLayout(randomSeed = 42)\n\n\n\n\n\n\n\n\nShow code\nlibrary(tidygraph)\nlibrary(visNetwork)\nlibrary(dplyr)\n\n# Convert to undirected for community detection\nq2_graph_comm &lt;- q2_graph %&gt;%\n  convert(to_undirected) %&gt;%\n  mutate(community = as.factor(group_louvain()))\n\n\n\n# Prepare nodes\nnodes_q2a &lt;- q2_graph_comm %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    id = row_number(),\n    title = paste0(\"&lt;b&gt;\", label, \"&lt;/b&gt;&lt;br&gt;\", sub_type),\n    group = sub_type,       # use for coloring\n    community = community   # for optional filter\n  )\n\n# Prepare edges\nedges_q2a &lt;- q2_edges_final %&gt;%\n  rename(from = from, to = to) %&gt;%\n  mutate(width = 1)  # optional: set edge width\n\n# Optional color palette (reuse from prior file or define)\nsubtype_colors &lt;- c(\n  \"Person\" = \"#fbb4ae\",\n  \"Vessel\" = \"#b3cde3\",\n  \"Organization\" = \"#ccebc5\",\n  \"Location\" = \"#decbe4\",\n  \"Unknown\" = \"#f2f2f2\"\n)\n\nvisNetwork(nodes_q2a, edges_q2a, height = \"700px\", width = \"100%\") %&gt;%\n  visNodes(\n    shape = \"dot\",\n    color = list(\n      background = subtype_colors[nodes_q2a$group],\n      border = \"#333333\",\n      highlight = \"#ffcc00\"\n    )\n  ) %&gt;%\n  visEdges(\n    color = list(color = \"#cccccc\", highlight = \"#ff9900\"),\n    arrows = \"to\"\n  ) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    selectedBy = \"community\"\n  ) %&gt;%\n  visLayout(randomSeed = 42)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "",
    "text": "This take home exercise is based on the VAST Challenge Mini Case 3\nOver the past decade, the community of Oceanus has faced numerous transformations and challenges evolving from its fishing-centric origins. Following major crackdowns on illegal fishing activities, suspects have shifted investments into more regulated sectors such as the ocean tourism industry, resulting in growing tensions. This increased tourism has recently attracted the likes of international pop star Sailor Shift, who announced plans to film a music video on the island.\nClepper Jessen, a former analyst at FishEye and now a seasoned journalist for the Hacklee Herald, has been keenly observing these rising tensions. Recently, he turned his attention towards the temporary closure of Nemo Reef. By listening to radio communications and utilizing his investigative tools, Clepper uncovered a complex web of expedited approvals and secretive logistics. These efforts revealed a story involving high-level Oceanus officials, Sailor Shift’s team, local influential families, and local conservationist group The Green Guardians, pointing towards a story of corruption and manipulation.\nYour task is to develop new and novel visualizations and visual analytics approaches to help Clepper get to the bottom of this story"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html#initial-eda",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html#initial-eda",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "3.1 Initial EDA",
    "text": "3.1 Initial EDA\n\n\nShow code\n#ExpCatViz(data=mc3_nodes,\n#          col=\"pink\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html#relationship-between-entities-and-events",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html#relationship-between-entities-and-events",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.1 Relationship between entities and events",
    "text": "6.1 Relationship between entities and events\n\n\nShow code\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 2) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html#entity-distribution",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html#entity-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.2 Entity distribution",
    "text": "6.2 Entity distribution\n\n\nShow code\n# Define color mapping\nsubtype_colors &lt;- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html#event-type-distribution",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html#event-type-distribution",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.3 Event type distribution",
    "text": "6.3 Event type distribution\n\n\nShow code\nmc3_nodes_final %&gt;%\n  filter(type == \"Event\") %&gt;%\n  count(sub_type, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html#list-of-communication-participants",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html#list-of-communication-participants",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4 List of communication participants",
    "text": "6.4 List of communication participants\n\n\nShow code\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids &lt;- mc3_nodes_cleaned %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\") %&gt;%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %&gt;%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges &lt;- mc3_edges_cleaned %&gt;%\n  filter(type == \"received\", from_id %in% comm_event_ids) %&gt;%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs &lt;- comm_sent_edges %&gt;%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named &lt;- comm_pairs %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %&gt;%\n  left_join(mc3_nodes_cleaned %&gt;% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender–receiver pairs\nparticipants_named %&gt;%\n  count(sender_label, receiver_label, sort = TRUE) %&gt;%\n  datatable(\n    caption = \"Top Communication Pairs (Sender → Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html#visualization-of-communication-participants-network",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html#visualization-of-communication-participants-network",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "6.4.1 Visualization of communication participants network",
    "text": "6.4.1 Visualization of communication participants network\nThis code creates an interactive communication network graph using visNetwork, where:\n\nEach node represents a person or entity, node size is based on total messages sent by that participant.\nEach edge (arrow) represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\nVer 1: Layout_in_circle\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %&gt;%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_in_circle\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\nVer 2: Layout_on_sphere\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\nShow code\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis &lt;- participants_named %&gt;%\n  count(sender_id, receiver_id, sort = TRUE) %&gt;%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts &lt;- comm_edges_vis %&gt;%\n  group_by(from) %&gt;%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis &lt;- mc3_nodes_cleaned %&gt;%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %&gt;%\n  select(id, label, sub_type) %&gt;%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %&gt;%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"&lt;br&gt;Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"&lt;br&gt;Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis &lt;- comm_edges_vis %&gt;%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes &lt;- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %&gt;%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %&gt;%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %&gt;%\n  visEdges(smooth = FALSE) %&gt;%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %&gt;%\n  visIgraphLayout(layout = \"layout_on_sphere\") %&gt;%\n  visPhysics(enabled = FALSE) %&gt;%\n  visLayout(randomSeed = 1818)\n\n\n\n\n\n\n\n\nShow code\n# === Load libraries ===\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidygraph)\nlibrary(purrr)\n\n# === Step 1: Load from MC3_graph.json ===\nq2_json &lt;- read_json(\"MC3_graph.json\", simplifyVector = TRUE)\n\n# Convert the nodes correctly (flat list → data frame)\nq2_nodes_raw &lt;- as_tibble(q2_json$nodes)  # Already flattened\n\n# Clean nodes\nq2_nodes_cleaned &lt;- q2_nodes_raw %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n# Edges: all types\nq2_edges_raw &lt;- bind_rows(\n  q2_json$edges$`Entity-&gt;Event`,\n  q2_json$edges$`Event-&gt;Entity`,\n  q2_json$edges$`Entity-&gt;Relationship`,\n  q2_json$edges$`Relationship-&gt;Entity`,\n  q2_json$edges$`Event-&gt;Event`,\n  q2_json$edges$`Event-&gt;Relationship`\n)\n\n# === Step 2: Clean Nodes ===\nq2_edges_raw &lt;- as_tibble(q2_json$edges)\n\nq2_edges_cleaned &lt;- q2_edges_raw %&gt;%\n  rename(from_id = source, to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), as.character)) %&gt;%\n  filter(from_id %in% q2_nodes_cleaned$id,\n         to_id %in% q2_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n# === Step 3: Clean Edges ===\nq2_edges_cleaned &lt;- q2_edges_raw %&gt;%\n  rename(from_id = source, to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), as.character)) %&gt;%\n  filter(from_id %in% q2_nodes_cleaned$id,\n         to_id %in% q2_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n# === Step 4: Build index lookup ===\nq2_node_index &lt;- q2_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n# === Step 5: Join edge IDs to node index ===\nq2_edges_indexed &lt;- q2_edges_cleaned %&gt;%\n  left_join(q2_node_index, by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(q2_node_index, by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# === Step 6: Subset nodes that are used in edges ===\nq2_used_node_ids &lt;- sort(unique(c(q2_edges_indexed$from, q2_edges_indexed$to)))\n\nq2_nodes_final &lt;- q2_nodes_cleaned %&gt;%\n  slice(q2_used_node_ids) %&gt;%\n  mutate(new_index = row_number())\n\n# === Step 7: Remap old indices in edges to new ones ===\nq2_index_remap &lt;- tibble(\n  old_index = q2_used_node_ids,\n  new_index = seq_along(q2_used_node_ids)\n)\n\nq2_edges_final &lt;- q2_edges_indexed %&gt;%\n  left_join(q2_index_remap, by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(q2_index_remap, by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, is_inferred, type)\n\n# === Step 8: Build tidygraph ===\nq2_graph &lt;- tbl_graph(\n  nodes = q2_nodes_final,\n  edges = q2_edges_final,\n  directed = TRUE\n)\n\n\n\nFiltering Communication Events\nTo begin our analysis of interaction patterns, we first isolate only the communication-related events from the full knowledge graph. These are represented in the dataset as nodes where type is \"Event\" and the sub_type is \"Communication\". These nodes correspond to actual radio or verbal exchanges logged in the system.\nThis filtering step ensures that we focus solely on the core transmission of information between entities — ignoring unrelated events such as movements, assessments, or reporting.\nThe resulting subset comm_events_q2 serves as the foundation for identifying who communicated with whom in the subsequent steps of our analysis.\n\n\nShow code\ncomm_events_q2 &lt;- q2_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\")\n\n\n\n\nExtracting Essential Communication Fields\nWith our subset of communication events (comm_events_q2) identified, we now extract only the essential fields required for downstream analysis:\n\nid: The unique identifier of each communication event node\ntimestamp: The time the message was logged\ncontent: The body of the message, which may contain names, vessel references, or pseudonyms\n\nThis produces a concise working table focused on the core attributes needed to trace interactions and perform text-based analysis. The content column, in particular, will play a critical role in revealing pseudonymous references and frequently co-mentioned entities, which are key to uncovering influence patterns and answering Question 2b and 3a.\nIn the next step, we will standardize the timestamp for use in time-based charts and aggregations.\n\n\nShow code\ncomm_events_q2 &lt;- comm_events_q2 %&gt;%\n  select(id, timestamp = timestamp, content = content)\n\n\n\n\nConverting Timestamps to Datetime Format\nThe timestamp field in our comm_events_q2 table was originally stored as a character string. To support time-based analysis such as daily trends, hourly grouping, or temporal filtering, we convert the timestamp into a proper datetime object using the ymd_hms() function from the lubridate package.\nThis transformation standardizes all timestamps into POSIXct format, making them compatible with datetime-based operations in ggplot2, dplyr, and ggraph.\nWith properly formatted timestamps, we can now begin linking these communication records to their sender and receiver nodes — using the knowledge graph’s edge table.\n\n\nShow code\nlibrary(lubridate)\n\ncomm_events_q2 &lt;- comm_events_q2 %&gt;%\n  mutate(timestamp = ymd_hms(timestamp))\n\n\n\n\nFiltering Edges for Sender and Receiver Links\nTo map who sent and received each communication, we filter the edge list to retain only those records where type is either \"sent\" or \"received\". These denote directional communication connections between entities and events.\nIn this structure: - source refers to the initiating entity (e.g., a person or vessel) - target refers to the communication event (a node of type Event) - type indicates whether the action was a message being sent or received\nThis refined subset, comm_edges_q2, will allow us to join communication event nodes to their participants. In the next step, we will reshape this edge list into a format where each communication row includes both the sender and receiver — an essential structure for downstream interaction visualizations and pseudonym detection.\n\n\nShow code\ncomm_edges_q2 &lt;- q2_edges_raw %&gt;%\n  filter(type %in% c(\"sent\", \"received\")) %&gt;%\n  select(source, target, type)\n\n\n\n\nSeparating Senders and Receivers\nWe now divide the directional communication edges into two distinct subsets — one representing message senders, and the other message receivers. This separation is based on the type of the edge (\"sent\" or \"received\"):\n\nIn the senders_q2 table, the source node is the entity who sent the message, and the target is the message node.\nIn the receivers_q2 table, the target node is the entity who received the message, and the source is the message node.\n\nBy renaming the shared message node to a common field (message_id), we create a consistent schema across both tables. This setup enables us to perform a join in the next step, reconstructing complete sender–receiver paths for each communication.\nThis representation is crucial for: - Mapping direct communication flows (Q2a) - Identifying alias usage and common message pathways (Q3a)\n\n\nShow code\n# Separate senders\nsenders_q2 &lt;- comm_edges_q2 %&gt;%\n  filter(type == \"sent\") %&gt;%\n  rename(sender = source, message_id = target)\n\n# Separate receivers\nreceivers_q2 &lt;- comm_edges_q2 %&gt;%\n  filter(type == \"received\") %&gt;%\n  rename(receiver = target, message_id = source)\n\n\n\n\nCreating Sender–Receiver Pairs\nNow that we have separated sender and receiver records, we join them using the common message_id. This produces a structure where each row represents one complete communication:\n\nsender: the entity that initiated the message\nreceiver: the entity that received it\nmessage_id: the identifier of the communication event\n\nThis comm_pairs_q2 table becomes the core person-to-person interaction dataset, enabling us to build networks, identify frequent message paths, and trace potential alias usage.\nIn the next step, we enrich this with timestamp and message content to fully contextualize each interaction.\n\n\nShow code\n# Join on message_id\ncomm_pairs_q2 &lt;- inner_join(senders_q2, receivers_q2, by = \"message_id\")\n\n\n\n\nAdding Message Content and Timing\nTo complete our interaction data, we join the sender–receiver pairs with the original communication event records. This adds two critical fields:\n\ntimestamp: when the message occurred (in POSIXct datetime format)\ncontent: the actual text or subject of the message\n\nThis full dataset, comm_full_q2, allows us to: - Trace who messaged whom, when, and what was said - Detect clusters or frequently interacting groups (Q2b) - Identify pseudonym usage or name overlaps (Q3a)\nIt also prepares us to build structured network visualizations and perform deeper temporal or semantic analysis.\n\n\nShow code\n# Combine with content and timestamp\ncomm_full_q2 &lt;- comm_pairs_q2 %&gt;%\n  left_join(comm_events_q2, by = c(\"message_id\" = \"id\"))\n\n\n\n\nResolving Official Labels for Senders and Receivers\nTo ensure clarity in our visualizations and pseudonym analysis, we join readable labels and subtypes to both the sender and receiver entities. We create a lookup table, entity_labels_q2, that contains:\n\nid: unique identifier\nlabel: human-readable name (e.g., “Kelly”, “Sailor Shift”)\nsub_type: whether the entity is a Person, Vessel, Organization, etc.\n\nThis join is critical to: - Accurately label nodes in network plots - Normalize ambiguous or reused IDs - Track patterns of alias reuse across different messages\n\n\nShow code\nentity_labels_q2 &lt;- q2_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  select(id, label, sub_type)\n\n\n\n\nEnriching with Entity Labels and Preparing for Network Construction\nTo finalize the communication dataset, we join readable label and sub_type attributes for both senders and receivers. This eliminates ambiguity around entity IDs and provides a human-readable structure that includes:\n\nsender_label and receiver_label (e.g., “Nadia Conti”, “The Intern”)\nsender_type and receiver_type (e.g., Person, Vessel)\nMessage content and timestamp\n\nThis enriched table, comm_full_q2, now forms the basis for constructing our communication network and detecting social clusters — all without the need to export to CSV. The dataset remains in memory and feeds directly into the interactive visualization engine.\n\n\nShow code\n# Join readable labels and subtypes\ncomm_full_q2 &lt;- comm_full_q2 %&gt;%\n  left_join(entity_labels_q2, by = c(\"sender\" = \"id\")) %&gt;%\n  rename(sender_label = label, sender_type = sub_type) %&gt;%\n  left_join(entity_labels_q2, by = c(\"receiver\" = \"id\")) %&gt;%\n  rename(receiver_label = label, receiver_type = sub_type)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main_DC3.html#question-2-communication-network-group-detection",
    "href": "main_project_qmd/main_project_qmd/main_DC3.html#question-2-communication-network-group-detection",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Question 2 – Communication Network & Group Detection",
    "text": "Question 2 – Communication Network & Group Detection\nTo analyze the structure of intercepted messages, we construct an interactive network where nodes represent individuals and vessels, and edges represent direct communication. Each directed edge indicates a message from a sender to a receiver, derived from parsed radio transmissions.\n\nKey Features of the Network Visualization\n\nNode Labels: Names and aliases are displayed directly, enabling entity recognition at a glance.\nEdge Direction: Arrows show message flow (who talked to whom).\nNode Size: Reflects message volume (total sent + received).\nTooltip: Shows exact count of messages sent and received per entity.\nColoring & Grouping: Louvain clustering reveals distinct communication groups — possibly corresponding to factions like Green Guardians, Sailor Shift’s entourage, or suspicious vessels.\nFiltering Controls: Users can interactively isolate individuals or entire communities.\nNavigation UI: Built-in zoom, pan, and full-view support helps explore dense areas.\n\nThis visualization directly addresses: - Q2a: Mapping who communicates with whom - Q2b: Detecting distinct communication groups\nThe structure suggests coordinated behavior among subsets of individuals, likely reflecting underlying roles, affiliations, or orchestrated activity. These clusters warrant deeper investigation in the context of known suspects and potential pseudonym usage.\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\n\n# Step 0: Filter person ↔ vessel/entity messages\nedge_list_q2 &lt;- comm_full_q2 %&gt;%\n  filter(sender_type %in% c(\"Person\", \"Vessel\"),\n         receiver_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  filter(!is.na(sender_label) & !is.na(receiver_label)) %&gt;%\n  count(sender_label, receiver_label, name = \"weight\")\n\n# Step 1: igraph object\ngraph_comm_q2 &lt;- graph_from_data_frame(edge_list_q2, directed = TRUE)\n\n# Step 2: Convert to undirected before Louvain\ngraph_comm_q2_undirected &lt;- as.undirected(graph_comm_q2, mode = \"collapse\")\nclusters_q2 &lt;- cluster_louvain(graph_comm_q2_undirected)\n\n# Step 3: Node degrees\ndeg_out_q2 &lt;- degree(graph_comm_q2, mode = \"out\")\ndeg_in_q2  &lt;- degree(graph_comm_q2, mode = \"in\")\n\n# Step 4: Nodes with cluster and interactivity\nnodes_q2 &lt;- data.frame(\n  id    = V(graph_comm_q2)$name,\n  label = V(graph_comm_q2)$name,\n  title = paste0(\"📤 Sent: \", deg_out_q2, \"&lt;br&gt;📥 Received: \", deg_in_q2),\n  group = paste(\"Cluster\", clusters_q2$membership),\n  value = deg_out_q2 + deg_in_q2\n)\n\n# Step 5: Edges with arrows\nedges_q2 &lt;- data.frame(\n  from   = as_edgelist(graph_comm_q2)[, 1],\n  to     = as_edgelist(graph_comm_q2)[, 2],\n  arrows = \"to\"\n)\n\n# Step 6: Render interactive network\nvisNetwork(nodes_q2, edges_q2, height = \"700px\", width = \"100%\") %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    selectedBy = list(variable = \"group\", multiple = FALSE, main = \"Select by cluster\"),\n    nodesIdSelection = list(enabled = TRUE, main = \"Select by entity\")\n  ) %&gt;%\n  visLegend() %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\", stabilization = TRUE) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLayout(randomSeed = 42)\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(tidytext)\nlibrary(dplyr)\nlibrary(stringr)\n\n# Step 1: Node-to-cluster mapping (based on your earlier setup)\nnode_cluster_q2 &lt;- data.frame(\n  label = V(graph_comm_q2)$name,\n  cluster = clusters_q2$membership\n)\n\n# Step 2: Merge sender/receiver cluster info into message dataset\ncomm_with_cluster_q2 &lt;- comm_full_q2 %&gt;%\n  filter(sender_type %in% c(\"Person\", \"Vessel\"),\n         receiver_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  left_join(node_cluster_q2, by = c(\"sender_label\" = \"label\")) %&gt;%\n  rename(sender_cluster = cluster) %&gt;%\n  left_join(node_cluster_q2, by = c(\"receiver_label\" = \"label\")) %&gt;%\n  rename(receiver_cluster = cluster)\n\n# Step 3: Pivot to long format for clustering analysis\ncomm_long_q2 &lt;- comm_with_cluster_q2 %&gt;%\n  select(content, sender_cluster, receiver_cluster) %&gt;%\n  rename(message_content = content) %&gt;%\n  pivot_longer(cols = c(sender_cluster, receiver_cluster),\n               names_to = \"role\", values_to = \"cluster\") %&gt;%\n  filter(!is.na(cluster), !is.na(message_content))\n\n# Step 4: Tokenize words and remove stopwords\ndata(\"stop_words\")\n\ntokens_by_cluster_q2 &lt;- comm_long_q2 %&gt;%\n  unnest_tokens(word, message_content) %&gt;%\n  filter(!word %in% stop_words$word, str_detect(word, \"[a-z]\")) %&gt;%\n  count(cluster, word, sort = TRUE)\n\n# Step 5: Get top 25 keywords per cluster\ntop_keywords_q2 &lt;- tokens_by_cluster_q2 %&gt;%\n  group_by(cluster) %&gt;%\n  slice_max(n, n = 25, with_ties = FALSE) %&gt;%\n  ungroup()\n\n\n\n\n\n\nShow code\nlibrary(ggplot2)\nlibrary(forcats)\n\n# Optional: Clean label for display\ntop_keywords_q2$word &lt;- str_to_title(top_keywords_q2$word)\n\n# Plot\nggplot(top_keywords_q2, aes(x = fct_reorder(word, n), y = n, fill = factor(cluster))) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  facet_wrap(~ cluster, scales = \"free_y\", ncol = 2) +\n  labs(\n    title = \"Top 25 Keywords by Communication Cluster\",\n    x = \"Keyword\", y = \"Frequency\"\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Cluster-Filtered Keyword Table\nUse the dropdown filter at the top of the table to isolate individual communication clusters. The table presents the top 20 most used keywords per cluster based on message content, helping identify dominant language themes in each group’s exchanges.\n\n\nShow code\nlibrary(DT)\nlibrary(dplyr)\nlibrary(stringr)\n\n# Prepare interactive table\ntop_keywords_q2 %&gt;%\n  mutate(\n    Cluster = factor(paste0(\"Cluster \", cluster)),  # 🔽 Dropdown-friendly\n    Keyword = str_to_title(word),\n    Frequency = n\n  ) %&gt;%\n  select(Cluster, Keyword, Frequency) %&gt;%\n  datatable(\n    caption = htmltools::tags$caption(\n      style = 'caption-side: top; text-align: left; font-size: 18px; font-weight: bold;',\n      \"Top Keywords by Communication Cluster\"\n    ),\n    filter = \"top\",  # 🔽 Enables dropdown on top for factors\n    rownames = FALSE,\n    class = \"compact stripe hover\",\n    options = list(\n      pageLength = 10,\n      autoWidth = TRUE,\n      dom = 'Bfrtip',\n      buttons = c('copy', 'csv', 'excel'),\n      order = list(list(2, 'desc'))  # Default sort by Frequency\n    )\n  )\n\n\n\n\n\n\n\nCluster 1Cluster 2Cluster 3Cluster 4Code Chunk\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[1]]\n\n\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[2]]\n\n\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[3]]\n\n\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[4]]\n\n\n\n\n\n\n\n\n\n\nShow code\n#|echo: True\n#|code-fold: FALSE\n#|eval: False\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[3]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.7 Interactive Cluster-Filtered Keyword Table\nUse the dropdown filter at the top of the table to isolate individual communication clusters. The table presents the top 20 most used keywords per cluster based on message content, helping identify dominant language themes in each group’s exchanges.\n\n\nShow code\nlibrary(DT)\n\n# Prepare table with readable cluster labels and formatted keywords\ntop_keywords_q2 %&gt;%\n  mutate(\n    Cluster  = paste0(\"Cluster \", cluster),\n    Keyword  = str_to_title(word),\n    Frequency = n\n  ) %&gt;%\n  select(Cluster, Keyword, Frequency) %&gt;%\n  datatable(\n    caption = htmltools::tags$caption(\n      style = 'caption-side: top; text-align: left; font-size: 18px; font-weight: bold;',\n      \"Top Keywords by Communication Cluster\"\n    ),\n    options = list(\n      pageLength = 10,\n      autoWidth = TRUE,\n      dom = 'Bfrtip',  # Search box, filter, table, pagination\n      buttons = c('copy', 'csv', 'excel'),\n      order = list(list(0, 'asc'), list(2, 'desc'))\n    ),\n    filter = \"top\",\n    rownames = FALSE,\n    class = \"compact stripe hover\"\n  )\n\n\n\n\n\n\n\n\nShow code\nlibrary(DT)\nlibrary(dplyr)\nlibrary(stringr)\n\n# Prepare interactive table\ntop_keywords_q2 %&gt;%\n  mutate(\n    Cluster = factor(paste0(\"Cluster \", cluster)),  # 🔽 Dropdown-friendly\n    Keyword = str_to_title(word),\n    Frequency = n\n  ) %&gt;%\n  select(Cluster, Keyword, Frequency) %&gt;%\n  datatable(\n    caption = htmltools::tags$caption(\n      style = 'caption-side: top; text-align: left; font-size: 18px; font-weight: bold;',\n      \"Top Keywords by Communication Cluster\"\n    ),\n    filter = \"top\",  # 🔽 Enables dropdown on top for factors\n    rownames = FALSE,\n    class = \"compact stripe hover\",\n    options = list(\n      pageLength = 10,\n      autoWidth = TRUE,\n      dom = 'Bfrtip',\n      buttons = c('copy', 'csv', 'excel'),\n      order = list(list(2, 'desc'))  # Default sort by Frequency\n    )\n  )\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\n# Example: Render the first plot (Cluster 1)\ninteractive_plots_q2[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(purrr)\n\n# Prepare and clean data\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)\n  )\n\n# Split into list of data frames by cluster\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Name each list element (for use in titles)\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# Function to plot for one cluster\nplot_cluster_keywords &lt;- function(data, cluster_name) {\n  ggplot(data, aes(x = fct_reorder(word, n), y = n, fill = cluster)) +\n    geom_col(show.legend = FALSE) +\n    coord_flip() +\n    labs(\n      title = paste(\"Top Keywords in\", cluster_name),\n      x = \"Keyword\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n}\n\n# Apply plotting function to each cluster\nplots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords)\n\nplots_q2[[1]]\n\n\n\n\n\n\n\n\n\nShow code\nplots_q2[[2]]\n\n\n\n\n\n\n\n\n\nShow code\nplots_q2[[3]]\n\n\n\n\n\n\n\n\n\nShow code\nplots_q2[[4]]\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Frequency: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +\n    coord_flip() +\n    labs(\n      title = paste(\"Top Keywords in\", cluster_name),\n      x = \"Keyword\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly\n  ggplotly(p, tooltip = \"text\")\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\n# Example: Render the first plot (Cluster 1)\ninteractive_plots_q2[[1]]\n\n\n\n\n\n\nShow code\n# To view all:\n for (p in interactive_plots_q2) print(p)\n\n\n\n\n\n\nShow code\nlibrary(ggplot2)\nlibrary(forcats)\n\n# Format & order\ntop_keywords_q2 &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    word = str_to_title(word),\n    cluster = as.factor(cluster)\n  )\n\nggplot(top_keywords_q2, aes(x = fct_reorder2(word, cluster, n), y = n, fill = cluster)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  facet_wrap(~ cluster, scales = \"free_y\", ncol = 2) +\n  labs(\n    title = \"Top 25 Keywords by Communication Cluster\",\n    x = \"Keyword\", y = \"Frequency\"\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal(base_size = 12)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#data-cleaning-and-wrangling-1",
    "href": "main_project_qmd/main_project_qmd/main.html#data-cleaning-and-wrangling-1",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Data Cleaning and Wrangling",
    "text": "Data Cleaning and Wrangling\nTo analyze interaction & relationships, recognize groups, and identify pseudonym usage, we perform a series of data cleaning and wrangling steps. These steps will allow us to isolate communication events, trace sender–receiver interactions, and prepare a clean dataset for visual exploration.\nThe main data preparation steps include:\n\nExtracting communication events with timestamps\nCleaning and formatting timestamp data\nIdentifying sender and receiver relationships\nJoining sender-receiver pairs to their respective names\nMerging all relevant fields into a single tidy dataframe for analysis\nSaving the cleaned dataset for reuse in subsequent sections\n\n\n\nShow code\n# === Load libraries ===\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidygraph)\nlibrary(purrr)\n\n# === Step 1: Load from MC3_graph.json ===\nq2_json &lt;- read_json(\"MC3_graph.json\", simplifyVector = TRUE)\n\n# Convert the nodes correctly (flat list → data frame)\nq2_nodes_raw &lt;- as_tibble(q2_json$nodes)  # Already flattened\n\n# Clean nodes\nq2_nodes_cleaned &lt;- q2_nodes_raw %&gt;%\n  mutate(id = as.character(id)) %&gt;%\n  filter(!is.na(id)) %&gt;%\n  distinct(id, .keep_all = TRUE) %&gt;%\n  select(-thing_collected)\n\n# Edges: all types\nq2_edges_raw &lt;- bind_rows(\n  q2_json$edges$`Entity-&gt;Event`,\n  q2_json$edges$`Event-&gt;Entity`,\n  q2_json$edges$`Entity-&gt;Relationship`,\n  q2_json$edges$`Relationship-&gt;Entity`,\n  q2_json$edges$`Event-&gt;Event`,\n  q2_json$edges$`Event-&gt;Relationship`\n)\n\n# === Step 2: Clean Nodes ===\nq2_edges_raw &lt;- as_tibble(q2_json$edges)\n\nq2_edges_cleaned &lt;- q2_edges_raw %&gt;%\n  rename(from_id = source, to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), as.character)) %&gt;%\n  filter(from_id %in% q2_nodes_cleaned$id,\n         to_id %in% q2_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n# === Step 3: Clean Edges ===\nq2_edges_cleaned &lt;- q2_edges_raw %&gt;%\n  rename(from_id = source, to_id = target) %&gt;%\n  mutate(across(c(from_id, to_id), as.character)) %&gt;%\n  filter(from_id %in% q2_nodes_cleaned$id,\n         to_id %in% q2_nodes_cleaned$id) %&gt;%\n  filter(!is.na(from_id), !is.na(to_id))\n\n# === Step 4: Build index lookup ===\nq2_node_index &lt;- q2_nodes_cleaned %&gt;%\n  mutate(.row_id = row_number()) %&gt;%\n  select(id, .row_id)\n\n# === Step 5: Join edge IDs to node index ===\nq2_edges_indexed &lt;- q2_edges_cleaned %&gt;%\n  left_join(q2_node_index, by = c(\"from_id\" = \"id\")) %&gt;%\n  rename(from = .row_id) %&gt;%\n  left_join(q2_node_index, by = c(\"to_id\" = \"id\")) %&gt;%\n  rename(to = .row_id) %&gt;%\n  select(from, to, is_inferred, type) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# === Step 6: Subset nodes that are used in edges ===\nq2_used_node_ids &lt;- sort(unique(c(q2_edges_indexed$from, q2_edges_indexed$to)))\n\nq2_nodes_final &lt;- q2_nodes_cleaned %&gt;%\n  slice(q2_used_node_ids) %&gt;%\n  mutate(new_index = row_number())\n\n# === Step 7: Remap old indices in edges to new ones ===\nq2_index_remap &lt;- tibble(\n  old_index = q2_used_node_ids,\n  new_index = seq_along(q2_used_node_ids)\n)\n\nq2_edges_final &lt;- q2_edges_indexed %&gt;%\n  left_join(q2_index_remap, by = c(\"from\" = \"old_index\")) %&gt;%\n  rename(from_new = new_index) %&gt;%\n  left_join(q2_index_remap, by = c(\"to\" = \"old_index\")) %&gt;%\n  rename(to_new = new_index) %&gt;%\n  select(from = from_new, to = to_new, is_inferred, type)\n\n# === Step 8: Build tidygraph ===\nq2_graph &lt;- tbl_graph(\n  nodes = q2_nodes_final,\n  edges = q2_edges_final,\n  directed = TRUE\n)\n\n\n\nFiltering Communication Events\nTo begin our analysis of interaction patterns, we first isolate only the communication-related events from the full knowledge graph. These are represented in the dataset as nodes where type is \"Event\" and the sub_type is \"Communication\". These nodes correspond to actual radio or verbal exchanges logged in the system.\nThis filtering step ensures that we focus solely on the core transmission of information between entities — ignoring unrelated events such as movements, assessments, or reporting.\nThe resulting subset comm_events_q2 serves as the foundation for identifying who communicated with whom in the subsequent steps of our analysis.\n\n\nShow code\ncomm_events_q2 &lt;- q2_nodes_final %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\")\n\n\n\n\nExtracting Essential Communication Fields\nWith our subset of communication events (comm_events_q2) identified, we now extract only the essential fields required for downstream analysis:\n\nid: The unique identifier of each communication event node\ntimestamp: The time the message was logged\ncontent: The body of the message, which may contain names, vessel references, or pseudonyms\n\nThis produces a concise working table focused on the core attributes needed to trace interactions and perform text-based analysis. The content column, in particular, will play a critical role in revealing pseudonymous references and frequently co-mentioned entities, which are key to uncovering influence patterns and answering Question 2b and 3a.\nIn the next step, we will standardize the timestamp for use in time-based charts and aggregations.\n\n\nShow code\ncomm_events_q2 &lt;- comm_events_q2 %&gt;%\n  select(id, timestamp = timestamp, content = content)\n\n\n\n\nConverting Timestamps to Datetime Format\nThe timestamp field in our comm_events_q2 table was originally stored as a character string. To support time-based analysis such as daily trends, hourly grouping, or temporal filtering, we convert the timestamp into a proper datetime object using the ymd_hms() function from the lubridate package.\nThis transformation standardizes all timestamps into POSIXct format, making them compatible with datetime-based operations in ggplot2, dplyr, and ggraph.\nWith properly formatted timestamps, we can now begin linking these communication records to their sender and receiver nodes — using the knowledge graph’s edge table.\n\n\nShow code\ncomm_events_q2 &lt;- comm_events_q2 %&gt;%\n  mutate(timestamp = ymd_hms(timestamp))\n\n\n\n\nFiltering Edges for Sender and Receiver Links\nTo map who sent and received each communication, we filter the edge list to retain only those records where type is either \"sent\" or \"received\". These denote directional communication connections between entities and events.\nIn this structure: - source refers to the initiating entity (e.g., a person or vessel) - target refers to the communication event (a node of type Event) - type indicates whether the action was a message being sent or received\nThis refined subset, comm_edges_q2, will allow us to join communication event nodes to their participants. In the next step, we will reshape this edge list into a format where each communication row includes both the sender and receiver — an essential structure for downstream interaction visualizations and pseudonym detection.\n\n\nShow code\ncomm_edges_q2 &lt;- q2_edges_raw %&gt;%\n  filter(type %in% c(\"sent\", \"received\")) %&gt;%\n  select(source, target, type)\n\n\n\n\nSeparating Senders and Receivers\nWe now divide the directional communication edges into two distinct subsets — one representing message senders, and the other message receivers. This separation is based on the type of the edge (\"sent\" or \"received\"):\n\nIn the senders_q2 table, the source node is the entity who sent the message, and the target is the message node.\nIn the receivers_q2 table, the target node is the entity who received the message, and the source is the message node.\n\nBy renaming the shared message node to a common field (message_id), we create a consistent schema across both tables. This setup enables us to perform a join in the next step, reconstructing complete sender–receiver paths for each communication.\nThis representation is crucial for: - Mapping direct communication flows (Q2a) - Identifying alias usage and common message pathways (Q3a)\n\n\nShow code\n# Separate senders\nsenders_q2 &lt;- comm_edges_q2 %&gt;%\n  filter(type == \"sent\") %&gt;%\n  rename(sender = source, message_id = target)\n\n# Separate receivers\nreceivers_q2 &lt;- comm_edges_q2 %&gt;%\n  filter(type == \"received\") %&gt;%\n  rename(receiver = target, message_id = source)\n\n\n\n\nCreating Sender–Receiver Pairs\nNow that we have separated sender and receiver records, we join them using the common message_id. This produces a structure where each row represents one complete communication:\n\nsender: the entity that initiated the message\nreceiver: the entity that received it\nmessage_id: the identifier of the communication event\n\nThis comm_pairs_q2 table becomes the core person-to-person interaction dataset, enabling us to build networks, identify frequent message paths, and trace potential alias usage.\nIn the next step, we enrich this with timestamp and message content to fully contextualize each interaction.\n\n\nShow code\n# Join on message_id\ncomm_pairs_q2 &lt;- inner_join(senders_q2, receivers_q2, by = \"message_id\")\n\n\n\n\nAdding Message Content and Timing\nTo complete our interaction data, we join the sender–receiver pairs with the original communication event records. This adds two critical fields:\n\ntimestamp: when the message occurred (in POSIXct datetime format)\ncontent: the actual text or subject of the message\n\nThis full dataset, comm_full_q2, allows us to: - Trace who messaged whom, when, and what was said - Detect clusters or frequently interacting groups (Q2b) - Identify pseudonym usage or name overlaps (Q3a)\nIt also prepares us to build structured network visualizations and perform deeper temporal or semantic analysis.\n\n\nShow code\n# Combine with content and timestamp\ncomm_full_q2 &lt;- comm_pairs_q2 %&gt;%\n  left_join(comm_events_q2, by = c(\"message_id\" = \"id\"))\n\n\n\n\nResolving Official Labels for Senders and Receivers\nTo ensure clarity in our visualizations and pseudonym analysis, we join readable labels and subtypes to both the sender and receiver entities. We create a lookup table, entity_labels_q2, that contains:\n\nid: unique identifier\nlabel: human-readable name (e.g., “Kelly”, “Sailor Shift”)\nsub_type: whether the entity is a Person, Vessel, Organization, etc.\n\nThis join is critical to: - Accurately label nodes in network plots - Normalize ambiguous or reused IDs - Track patterns of alias reuse across different messages\n\n\nShow code\nentity_labels_q2 &lt;- q2_nodes_final %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  select(id, label, sub_type)\n\n\n\n\nEnriching with Entity Labels and Preparing for Network Construction\nTo finalize the communication dataset, we join readable label and sub_type attributes for both senders and receivers. This eliminates ambiguity around entity IDs and provides a human-readable structure that includes:\n\nsender_label and receiver_label (e.g., “Nadia Conti”, “The Intern”)\nsender_type and receiver_type (e.g., Person, Vessel)\nMessage content and timestamp\n\nThis enriched table, comm_full_q2, now forms the basis for constructing our communication network and detecting social clusters. The dataset remains in memory and feeds directly into the interactive visualization engine.\n\n\nShow code\n# Join readable labels and subtypes\ncomm_full_q2 &lt;- comm_full_q2 %&gt;%\n  left_join(entity_labels_q2, by = c(\"sender\" = \"id\")) %&gt;%\n  rename(sender_label = label, sender_type = sub_type) %&gt;%\n  left_join(entity_labels_q2, by = c(\"receiver\" = \"id\")) %&gt;%\n  rename(receiver_label = label, receiver_type = sub_type)"
  },
  {
    "objectID": "main_project_qmd/main_project_qmd/main.html#question-2-communication-network-group-detection",
    "href": "main_project_qmd/main_project_qmd/main.html#question-2-communication-network-group-detection",
    "title": "VAST Challenge 2025 - Mini-Challenge 3",
    "section": "Question 2 – Communication Network & Group Detection",
    "text": "Question 2 – Communication Network & Group Detection\nTo analyze the structure of intercepted messages, we construct an interactive network where nodes represent individuals and vessels, and edges represent direct communication. Each directed edge indicates a message from a sender to a receiver, derived from parsed radio transmissions.\n\nKey Features of the Network Visualization\n\nNode Labels: Names and aliases are displayed directly, enabling entity recognition at a glance.\nEdge Direction: Arrows show message flow (who talked to whom).\nNode Size: Reflects message volume (total sent + received).\nTooltip: Shows exact count of messages sent and received per entity.\nColoring & Grouping: Louvain clustering reveals distinct communication groups — possibly corresponding to factions like Green Guardians, Sailor Shift’s entourage, or suspicious vessels.\nFiltering Controls: Users can interactively isolate individuals or entire communities.\nNavigation UI: Built-in zoom, pan, and full-view support helps explore dense areas.\n\nThis visualization directly addresses: - Q2a: Mapping who communicates with whom - Q2b: Detecting distinct communication groups\nThe structure suggests coordinated behavior among subsets of individuals, likely reflecting underlying roles, affiliations, or orchestrated activity. These clusters warrant deeper investigation in the context of known suspects and potential pseudonym usage.\n\n\nShow code\nlibrary(igraph)\nlibrary(visNetwork)\n\n# Step 0: Filter person ↔ vessel/entity messages\nedge_list_q2 &lt;- comm_full_q2 %&gt;%\n  filter(sender_type %in% c(\"Person\", \"Vessel\"),\n         receiver_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  filter(!is.na(sender_label) & !is.na(receiver_label)) %&gt;%\n  count(sender_label, receiver_label, name = \"weight\")\n\n# Step 1: igraph object\ngraph_comm_q2 &lt;- graph_from_data_frame(edge_list_q2, directed = TRUE)\n\n# Step 2: Convert to undirected before Louvain\ngraph_comm_q2_undirected &lt;- as.undirected(graph_comm_q2, mode = \"collapse\")\nclusters_q2 &lt;- cluster_louvain(graph_comm_q2_undirected)\n\n# Step 3: Node degrees\ndeg_out_q2 &lt;- degree(graph_comm_q2, mode = \"out\")\ndeg_in_q2  &lt;- degree(graph_comm_q2, mode = \"in\")\n\n# Step 4: Nodes with cluster and interactivity\nnodes_q2 &lt;- data.frame(\n  id    = V(graph_comm_q2)$name,\n  label = V(graph_comm_q2)$name,\n  title = paste0(\"📤 Sent: \", deg_out_q2, \"&lt;br&gt;📥 Received: \", deg_in_q2),\n  group = paste(\"Cluster\", clusters_q2$membership),\n  value = deg_out_q2 + deg_in_q2\n)\n\n# Step 5: Edges with arrows\nedges_q2 &lt;- data.frame(\n  from   = as_edgelist(graph_comm_q2)[, 1],\n  to     = as_edgelist(graph_comm_q2)[, 2],\n  arrows = \"to\"\n)\n\n# Step 6: Render interactive network\nvisNetwork(nodes_q2, edges_q2, height = \"700px\", width = \"100%\") %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    selectedBy = list(variable = \"group\", multiple = FALSE, main = \"Select by cluster\"),\n    nodesIdSelection = list(enabled = TRUE, main = \"Select by entity\")\n  ) %&gt;%\n  visLegend() %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\", stabilization = TRUE) %&gt;%\n  visInteraction(navigationButtons = TRUE) %&gt;%\n  visLayout(randomSeed = 42)\n\n\n\n\n\n\nConsolidated plot to see the Top 25 Keywords\n\n\nShow code\nlibrary(tidytext)\nlibrary(dplyr)\nlibrary(stringr)\n\n# Step 1: Node-to-cluster mapping (based on your earlier setup)\nnode_cluster_q2 &lt;- data.frame(\n  label = V(graph_comm_q2)$name,\n  cluster = clusters_q2$membership\n)\n\n# Step 2: Merge sender/receiver cluster info into message dataset\ncomm_with_cluster_q2 &lt;- comm_full_q2 %&gt;%\n  filter(sender_type %in% c(\"Person\", \"Vessel\"),\n         receiver_type %in% c(\"Person\", \"Vessel\")) %&gt;%\n  left_join(node_cluster_q2, by = c(\"sender_label\" = \"label\")) %&gt;%\n  rename(sender_cluster = cluster) %&gt;%\n  left_join(node_cluster_q2, by = c(\"receiver_label\" = \"label\")) %&gt;%\n  rename(receiver_cluster = cluster)\n\n# Step 3: Pivot to long format for clustering analysis\ncomm_long_q2 &lt;- comm_with_cluster_q2 %&gt;%\n  select(content, sender_cluster, receiver_cluster) %&gt;%\n  rename(message_content = content) %&gt;%\n  pivot_longer(cols = c(sender_cluster, receiver_cluster),\n               names_to = \"role\", values_to = \"cluster\") %&gt;%\n  filter(!is.na(cluster), !is.na(message_content))\n\n# Step 4: Tokenize words and remove stopwords\ndata(\"stop_words\")\n\ntokens_by_cluster_q2 &lt;- comm_long_q2 %&gt;%\n  unnest_tokens(word, message_content) %&gt;%\n  filter(!word %in% stop_words$word, str_detect(word, \"[a-z]\")) %&gt;%\n  count(cluster, word, sort = TRUE)\n\n# Step 5: Get top 25 keywords per cluster\ntop_keywords_q2 &lt;- tokens_by_cluster_q2 %&gt;%\n  group_by(cluster) %&gt;%\n  slice_max(n, n = 25, with_ties = FALSE) %&gt;%\n  ungroup()\n\n# Optional: Clean label for display\ntop_keywords_q2$word &lt;- str_to_title(top_keywords_q2$word)\n\n# Plot\nggplot(top_keywords_q2, aes(x = fct_reorder(word, n), y = n, fill = factor(cluster))) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  facet_wrap(~ cluster, scales = \"free_y\", ncol = 2) +\n  labs(\n    title = \"Top 25 Keywords by Communication Cluster\",\n    x = \"Keyword\", y = \"Frequency\"\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\nInteractive Cluster-Filtered Keyword Table\nUse the dropdown filter at the top of the table to isolate individual communication clusters. The table presents the top 25 most used keywords per cluster based on message content, helping identify dominant language themes in each group’s exchanges.\n\n\nShow code\nlibrary(DT)\nlibrary(dplyr)\nlibrary(stringr)\n\n# Prepare interactive table\ntop_keywords_q2 %&gt;%\n  mutate(\n    Cluster = factor(paste0(\"Cluster \", cluster)),  # 🔽 Dropdown-friendly\n    Keyword = str_to_title(word),\n    Frequency = n\n  ) %&gt;%\n  select(Cluster, Keyword, Frequency) %&gt;%\n  datatable(\n    caption = htmltools::tags$caption(\n      style = 'caption-side: top; text-align: left; font-size: 18px; font-weight: bold;',\n      \"Top Keywords by Communication Cluster\"\n    ),\n    filter = \"top\",  # 🔽 Enables dropdown on top for factors\n    rownames = FALSE,\n    class = \"compact stripe hover\",\n    options = list(\n      pageLength = 10,\n      autoWidth = TRUE,\n      dom = 'Bfrtip',\n      buttons = c('copy', 'csv', 'excel'),\n      order = list(list(2, 'desc'))  # Default sort by Frequency\n    )\n  )\n\n\n\n\n\n\n\n\nInteractive Top 25 Keywords by Cluster\nThe following charts show the top 25 keywords used in communications by members of each cluster. Hover over each bar to see annotations for the keyword, frequency, and its cluster group. These visualizations help identify each group’s focus and language patterns.\n\nCluster 1Cluster 2Cluster 3Cluster 4\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[1]]\n\n\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[2]]\n\n\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[3]]\n\n\n\n\n\n\n\n\n\n\nShow code\n# --- Load Required Libraries ---\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(purrr)\nlibrary(tidytext)\n\n# --- Step 1: Clean and Prepare the Keyword Data ---\ntop_keywords_q2_cleaned &lt;- top_keywords_q2 %&gt;%\n  mutate(\n    cluster = as.factor(cluster),\n    word = str_to_title(word)  # Capitalize for display\n  )\n\n# --- Step 2: Split into Cluster-specific Data Frames ---\nkeyword_lists_q2 &lt;- top_keywords_q2_cleaned %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# Label each list with Cluster name\nnames(keyword_lists_q2) &lt;- paste0(\"Cluster \", levels(top_keywords_q2_cleaned$cluster))\n\n# --- Step 3: Define Function to Create Interactive Plot ---\nplot_cluster_keywords_interactive &lt;- function(data, cluster_name) {\n  p &lt;- ggplot(data, aes(\n    x = fct_reorder(word, n), \n    y = n,\n    fill = cluster,\n    text = paste0(\n      \"📌 Keyword: \", word,\n      \"&lt;br&gt;📊 Count: \", n\n    )\n  )) +\n    geom_col(show.legend = FALSE) +  # Hide ggplot2 legend\n    coord_flip() +\n    labs(\n      title = paste(\"Top 25 Keywords in\", cluster_name),\n      x = \"\", y = \"Frequency\"\n    ) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme_minimal(base_size = 12)\n  \n  # Convert to plotly and hide legend again\n  ggplotly(p, tooltip = \"text\") %&gt;%\n    layout(showlegend = FALSE)  # &lt;- hides plotly legend\n}\n\n# --- Step 4: Generate All Interactive Plots in a List ---\ninteractive_plots_q2 &lt;- map2(keyword_lists_q2, names(keyword_lists_q2), plot_cluster_keywords_interactive)\n\n# --- Step 5: View or Output ---\ninteractive_plots_q2[[4]]"
  }
]